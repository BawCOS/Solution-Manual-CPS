% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Solutions for Computational Probability and Statistics},
  pdfauthor={Ken Horton; Kris Pruitt; Bradley Warner},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{multicol}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Solutions for Computational Probability and Statistics}
\author{Ken Horton \and Kris Pruitt \and Bradley Warner}
\date{2021-03-11}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}
\addcontentsline{toc}{chapter}{Preface}

\includegraphics[width=19.58in]{./figures/CoverSol2}

Contained in this volume are the solutions to homework problems in the Computational Probability and Statistics book.

\hypertarget{book-structure-and-how-to-use-it}{%
\section{Book Structure and How to Use It}\label{book-structure-and-how-to-use-it}}

This solution manual is setup to match the structure of the accompanying book.

The learning outcomes for this course are to use computational and mathematical statistical/probabilistic concepts for:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Developing probabilistic models
\item
  Developing statistical models for inference and description
\item
  Advancing practical and theoretical analytic experience and skills
\end{enumerate}

\hypertarget{packages}{%
\section{Packages}\label{packages}}

These notes make use of the following packages in R \textbf{knitr} \citep{R-knitr}, \textbf{rmarkdown} \citep{R-rmarkdown}, \textbf{mosaic} \citep{R-mosaic}, \textbf{mosaicCalc} \citep{R-mosaicCalc}, \textbf{tidyverse} \citep{R-tidyverse}, \textbf{ISLR} \citep{R-ISLR}, \textbf{vcd} \citep{R-vcd}, \textbf{ggplot2} \citep{R-ggplot2}, \textbf{MASS} \citep{R-MASS}, \textbf{openintro} \citep{R-openintro}, \textbf{broom} \citep{R-broom}, \textbf{infer} \citep{R-infer}, \textbf{ISLR} \citep{R-ISLR}, \textbf{kableExtra} \citep{R-kableExtra}, \textbf{DT} \citep{R-DT}.

\includegraphics[width=1.22in]{./figures/by-nc-sa}

This book is licensed under the \href{http://creativecommons.org/licenses/by-nc-sa/4.0/}{Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License}.

\hypertarget{file-creation-information}{%
\section{File Creation Information}\label{file-creation-information}}

\begin{itemize}
\tightlist
\item
  File creation date: 2021-03-11
\item
  Windows version: Windows 10 x64 (build 18362)
\item
  R version 3.6.3 (2020-02-29)
\end{itemize}

\hypertarget{part-descriptive-statistical-modeling}{%
\part{Descriptive Statistical Modeling}\label{part-descriptive-statistical-modeling}}

\hypertarget{CS1}{%
\chapter{Case Study}\label{CS1}}

\hypertarget{objectives}{%
\section{Objectives}\label{objectives}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Use R for basic analysis and visualization.\\
\item
  Compile a report using \texttt{knitr}.
\end{enumerate}

\hypertarget{homework}{%
\section{Homework}\label{homework}}

Load \texttt{tidyverse},\texttt{mosaic}, and \texttt{knitr} packages.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(mosaic)}
\KeywordTok{library}\NormalTok{(knitr)}
\end{Highlighting}
\end{Shaded}

\hypertarget{problem-1}{%
\subsection{Problem 1}\label{problem-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Stent study continued}. Complete a similar analysis for the stent data but this time for the one year data. In particular
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Read the data into your working directory.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stent_study <-}\KeywordTok{read_csv}\NormalTok{(}\StringTok{'data/stent_study.csv'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Complete similar steps as in the class notes.\\
  i. Use \texttt{inspect} on the data.
  ii. Create a table of \texttt{outcome365} and \texttt{group}. Comment on the results.
  iii. Create a barchart of the data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(stent_study)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: `data_frame()` is deprecated as of tibble 1.1.0.
## Please use `tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.
\end{verbatim}

\begin{verbatim}
## 
## categorical variables:  
##         name     class levels   n missing
## 1      group character      2 451       0
## 2  outcome30 character      2 451       0
## 3 outcome365 character      2 451       0
##                                    distribution
## 1 control (50.3%), trmt (49.7%)                
## 2 no_event (89.8%), stroke (10.2%)             
## 3 no_event (83.8%), stroke (16.2%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(outcome365}\OperatorTok{~}\NormalTok{group,}\DataTypeTok{data=}\NormalTok{stent_study,}\DataTypeTok{format=}\StringTok{"proportion"}\NormalTok{,}\DataTypeTok{margins =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           group
## outcome365   control      trmt
##   no_event 0.8766520 0.7991071
##   stroke   0.1233480 0.2008929
##   Total    1.0000000 1.0000000
\end{verbatim}

Patients in the treatment group had a higher proportion of strokes than those in the control group after one year. The treatment does not appear to help the rate of strokes and in fact may hurt it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stent_study }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_props}\NormalTok{(}\OperatorTok{~}\NormalTok{group,}\DataTypeTok{fill=}\OperatorTok{~}\NormalTok{outcome365,}\DataTypeTok{position=}\StringTok{'fill'}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Impact of Stents of Stroke"}\NormalTok{,}
  \DataTypeTok{subtitle=}\StringTok{'Experiment with 451 Patients'}\NormalTok{,}
  \DataTypeTok{x=}\StringTok{"Experimental Group"}\NormalTok{,}
  \DataTypeTok{y=}\StringTok{"Number of Events"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{01-Data-Case-Study-Solutions_files/figure-latex/unnamed-chunk-6-1.pdf}

\hypertarget{problem-2}{%
\subsection{Problem 2}\label{problem-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Migraine and acupuncture}. A migraine is a particularly painful type of headache, which patients sometimes wish to treat with acupuncture. To determine whether acupuncture relieves migraine pain, researchers conducted a randomized controlled study where 89 females diagnosed with migraine headaches were randomly assigned to one of two groups: treatment or control. 43 patients in the treatment group received acupuncture that is specifically designed to treat migraines. 46 patients in the control group received placebo acupuncture (needle insertion at nonacupoint locations). 24 hours after patients received acupuncture, they were asked if they were pain free.\footnote{G. Allais et al.~\href{http://www.ncbi.nlm.nih.gov/pubmed/21533739}{``Ear acupuncture in the treatment of migraine attacks: a randomized trial on the efficacy of appropriate versus inappropriate acupoints''.} In: Neurological Sci. 32.1 (2011), pp.~173--175.}
\end{enumerate}

The data is in the file \texttt{migraine\_study.csv} in the folder \texttt{data}.

Complete the following work:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Read the data an object called \texttt{migraine\_study}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{migraine_study <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/migraine_study.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(migraine_study)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   group     pain_free
##   <chr>     <chr>    
## 1 treatment yes      
## 2 treatment yes      
## 3 treatment yes      
## 4 treatment yes      
## 5 treatment yes      
## 6 treatment yes
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a table of the data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(pain_free}\OperatorTok{~}\NormalTok{group,}\DataTypeTok{data=}\NormalTok{migraine_study,}\DataTypeTok{format=}\StringTok{"proportion"}\NormalTok{,}\DataTypeTok{margin=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          group
## pain_free    control  treatment
##     no    0.95652174 0.76744186
##     yes   0.04347826 0.23255814
##     Total 1.00000000 1.00000000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Report the percent of patients in the treatment group who were pain free 24 hours after receiving acupuncture.
\end{enumerate}

There are 23.2\% of the treatment group pain free.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Repeat for the control group.
\end{enumerate}

There are only 4.3\% of the control group pain free.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  At first glance, does acupuncture appear to be an effective treatment for migraines? Explain your reasoning.
\end{enumerate}

Yes, a substantial increase in the percentage of patients pain free after acupuncture versus those with no acupuncture, so it appears to be effective.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Do the data provide convincing evidence that there is a real pain reduction for those patients in the treatment group? Or do you think that the observed difference might just be due to chance?
\end{enumerate}

Either of these is acceptable:
i. We could get slightly different group estimates even if there is no real difference. Though the difference is big, I'm skeptical the results show a real difference and think this might be due to chance.\\
ii. The difference in these rates looks pretty big, and so I suspect acupuncture is having a positive impact on pain.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Compile, \texttt{knit}, this report into a pdf.
\end{enumerate}

Complete on your computer or server.

\hypertarget{DB}{%
\chapter{Data Basics}\label{DB}}

\hypertarget{objectives-1}{%
\section{Objectives}\label{objectives-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and use properly in context all new terminology to include but not limited to case, observational unit, variables, data frame, associated variables, independent, and discrete and continuous variables.\\
\item
  Identify and define the different types of variables.\\
\item
  From reading a study, explain the research question.\\
\item
  Create a scatterplot in \texttt{R} and determine the association of two numerical variables from the plot.
\end{enumerate}

\hypertarget{homework-1}{%
\section{Homework}\label{homework-1}}

\textbf{Identify study components}

Identify (i) the cases, (ii) the variables and their types, and (iii) the main research question in the studies described below.

\hypertarget{problem-1-1}{%
\subsection{Problem 1}\label{problem-1-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Researchers collected data to examine the relationship between pollutants and preterm births in Southern California. During the study air pollution levels were measured by air quality monitoring stations. Specifically, levels of carbon monoxide were recorded in parts per million, nitrogen dioxide and ozone in parts per hundred million, and coarse particulate matter (PM\(_{10}\)) in \(\mu g/m^3\). Length of gestation data were collected on 143,196 births between the years 1989 and 1993, and air pollution exposure during gestation was calculated for each birth. The analysis suggested that increased ambient PM\(_{10}\) and, to a lesser degree, CO concentrations may be associated with the occurrence of preterm births.\footnote{B. Ritz et al.~\href{http://journals.lww.com/epidem/Abstract/2000/09000/Effect_of_Air_Pollution_on_Preterm_Birth_Among.4.aspx}{``Effect of air pollution on preterm birth among children born in Southern California
    between 1989 and 1993''}. In: Epidemiology 11.5 (2000), pp.~502--511.}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\item
  The cases are 143,196 eligible study subjects who were born in Southern California
  between 1989 and 1993.
\item
  The variables are measurements of carbon monoxide (CO), nitrogen dioxide, ozone, and particulate matter less than 10\(\mu m\) (PM10) collected at air-quality-monitoring stations as well as length of gestation. All of these variables are continuous numerical variables.
\item
  The research question was \textbf{Is there an association between air pollution exposure and preterm births?}
\end{enumerate}

\hypertarget{problem-2-1}{%
\subsection{Problem 2}\label{problem-2-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The Buteyko method is a shallow breathing technique developed by Konstantin Buteyko, a Russian doctor, in 1952. Anecdotal evidence suggests that the Buteyko method can reduce asthma symptoms and improve quality of life. In a scientific study to determine the effectiveness of this method, researchers recruited 600 asthma patients aged 18-69 who relied on medication for asthma treatment. These patients were split into two research groups: one practiced the Buteyko method and the other did not. Patients were scored on quality of life, activity, asthma symptoms, and medication reduction on a scale from 0 to 10. On average, the participants in the Buteyko group experienced a significant reduction in asthma symptoms and an improvement in quality of life.\footnote{J. McGowan. ``Health Education: Does the Buteyko Institute Method make a difference?'' In: Thorax 58 (2003).}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  The cases are 600 adult patients aged 18-69 years diagnosed and currently treated for asthma.\\
\item
  The variables were whether or not the patient practiced the Buteyko method (categorical) and measures of quality of life, activity, asthma symptoms and medication reduction of the patients (categorical, ordinal). It may also be reasonable to treat the ratings on a scale of 1 to 10 as discrete numerical variables.\\
\item
  The research question was \textbf{Do asthmatic patients who practice the Buteyko method experience improvement in their condition?}
\end{enumerate}

\hypertarget{ODCP}{%
\chapter{Overview of Data Collection Principles}\label{ODCP}}

\hypertarget{objectives-2}{%
\section{Objectives}\label{objectives-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and use properly in context all new terminology.\\
\item
  From a description of a research project, at a minimum be able to describe the population of interest, the generalizability of the study, the response and predictor variables, differentiate whether it is observational or experimental, and determine the type of sample.
\end{enumerate}

\hypertarget{homework-2}{%
\section{Homework}\label{homework-2}}

\hypertarget{problem-1-2}{%
\subsection{Problem 1}\label{problem-1-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Generalizability and causality}. Identify the population of interest and the sample in the studies described below, these are the same studies from the prevous lesson. Also comment on whether or not the results of the study can be generalized to the population and if the findings of the study can be used to establish causal relationships.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Researchers collected data to examine the relationship between pollutants and preterm births in Southern California. During the study air pollution levels were measured by air quality monitoring stations. Specifically, levels of carbon monoxide were recorded in parts per million, nitrogen dioxide and ozone in parts per hundred million, and coarse particulate matter (PM\(_{10}\)) in \(\mu g/m^3\). Length of gestation data were collected on 143,196 births between the years 1989 and 1993, and air pollution exposure during gestation was calculated for each birth. The analysis suggested that increased ambient PM\(_{10}\) and, to a lesser degree, CO concentrations may be associated with the occurrence of preterm births.\footnote{B. Ritz et al.~\href{http://journals.lww.com/epidem/Abstract/2000/09000/Effect_of_Air_Pollution_on_Preterm_Birth_Among.4.aspx}{``Effect of air pollution on preterm birth among children born in Southern California
    between 1989 and 1993''}. In: Epidemiology 11.5 (2000), pp.~502--511.}
\end{enumerate}

\begin{quote}
The population of interest is all births. The sample consists of the 143,196 births between 1989 and 1993 in Southern California. If births in this time span at the geography can be considered to be representative of all births, then the results are generalizable to the population of Southern California. However, since the study is observational the findings cannot be used to establish causal relationships.
\end{quote}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The Buteyko method is a shallow breathing technique developed by Konstantin Buteyko, a Russian doctor, in 1952. Anecdotal evidence suggests that the Buteyko method can reduce asthma symptoms and improve quality of life. In a scientific study to determine the effectiveness of this method, researchers recruited 600 asthma patients aged 18-69 who relied on medication for asthma treatment. These patients were split into two research groups: one practiced the Buteyko method and the other did not. Patients were scored on quality of life, activity, asthma symptoms, and medication reduction on a scale from 0 to 10. On average, the participants in the Buteyko group experienced a significant reduction in asthma symptoms and an improvement in quality of life.\footnote{J. McGowan. ``Health Education: Does the Buteyko Institute Method make a difference?'' In: Thorax 58 (2003).}
\end{enumerate}

\begin{quote}
The population is all 18-69 year olds diagnosed and currently treated for asthma. The sample is the 600 adult patients aged 18-69 years diagnosed and currently treated for asthma. Since the sample is not random (voluntary) the results cannot be generalized to the population at large. However, since the study is an experiment, the findings can
be used to establish causal relationships.
\end{quote}

\pagebreak

\hypertarget{problem-2-2}{%
\subsection{Problem 2}\label{problem-2-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{GPA and study time}. A survey was conducted on 55 undergraduates from Duke University who took an introductory statistics course in Spring 2012. Among many other questions, this survey asked them about their GPA and the number of hours they spent studying per week. The scatterplot below displays the relationship between these two variables.
\end{enumerate}

\includegraphics{03-Overview-of-Data-Collection-Principles-Solutions_files/figure-latex/unnamed-chunk-1-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What is the explanatory variable and what is the response variable?
\item
  Describe the relationship between the two variables. Make sure to discuss unusual observations, if any.
\item
  Is this an experiment or an observational study?
\item
  Can we conclude that studying longer hours leads to higher GPAs?
\end{enumerate}

\begin{quote}
Solutions
\end{quote}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  The explanatory variable is the number of study hours per week, and the response variable is GPA.
\item
  There is a somewhat weak positive relationship between the two variables, though the data become more sparse as the number of study hours increases. One responded reported a GPA above 4.0, which is clearly a data error. Also, there are a few respondents who reported unusually high study hours (60 and 70 hours/week). It should also be
  noted that the variability in GPA is much higher for students who study less than those who study more, also might be due to the fact that there aren't many respondents who reported studying higher hours.
\item
  This is an observational study.
\item
  Since this is an observational study, we cannot conclude that there is a causal relationship between the two variables even though there appears to be an association.
\end{enumerate}

\pagebreak

\hypertarget{problem-3}{%
\subsection{Problem 3}\label{problem-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Income and education} The scatterplot below shows the relationship between per capita income (in thousands of dollars) and percent of population with a bachelor's degree in 3,143 counties in the US in 2010.
\end{enumerate}

\includegraphics{03-Overview-of-Data-Collection-Principles-Solutions_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What are the explanatory and response variables?
\item
  Describe the relationship between the two variables. Make sure to discuss unusual observations, if any.
\item
  Can we conclude that having a bachelor's degree increases one's income?
\end{enumerate}

\begin{quote}
Solutions
\end{quote}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  The explanatory variable is percent of population with a bachelor's degree and the response variable is per capita income (in thousands).
\item
  There is a strong positive linear relationship between the two variables. As the percentage of population with a bachelor's degree increases the per capita income increases as well. There are very few counties where more than 60\% of the population have a bachelor's degree and very few countries that have a more than \$50,000 in per capita income.
\item
  This is an observational study so we cannot make a causal statement based on the results. However, we can say that having a higher percentage of population with bachelor's degree is associated with a higher per capita income.
\end{enumerate}

\hypertarget{STUDY}{%
\chapter{Studies}\label{STUDY}}

\hypertarget{objectives-3}{%
\section{Objectives}\label{objectives-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and use properly in context all new terminology.\\
\item
  Given a study description, be able to identify and explain the study using correct terms.\\
\item
  Given a scenario, describe flaws in reasoning and propose study and sampling designs.
\end{enumerate}

\hypertarget{homework-3}{%
\section{Homework}\label{homework-3}}

\hypertarget{problem-1-3}{%
\subsection{Problem 1}\label{problem-1-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Propose a sampling strategy}. A large college class has 160 students. All 160 students attend the lectures together, but the students are divided into 4 groups, each of 40 students, for lab sections administered by different teaching assistants. The professor wants to conduct a survey about how satisfied the students are with the course, and he believes that the lab section a student is in might affect the student's overall satisfaction with the course.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What type of study is this? Observational study.
\item
  Suggest a sampling strategy for carrying out this study. Stratified sample, sample randomly within each section.
\end{enumerate}

\hypertarget{problem-2-3}{%
\subsection{Problem 2}\label{problem-2-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Flawed reasoning}. Identify the flaw in reasoning in the following scenarios. Explain what the individuals in the study should have done differently if they wanted to make such strong conclusions.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Students at an elementary school are given a questionnaire that they are required to return after their parents have completed it. One of the questions asked is, \emph{Do you find that your work schedule makes it difficult for you to spend time with your kids after school?} Of the parents who replied, 85\% said \emph{no}. Based on these results, the school officials conclude that a great majority of the parents have no difficulty spending time with their kids after school.
\end{enumerate}

\begin{quote}
Solution\\
Non-responders may have a different response to this question. The parents who returned the surveys are probably those who do not have difficulty spending time with their kids after school. Parents who work might not have returned the surveys since they probably have a busier schedule.
\end{quote}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  A survey is conducted on a simple random sample of 1,000 women who recently gave birth, asking them about whether or not they smoked during pregnancy. A follow-up survey asking if the children have respiratory problems is conducted 3 years later, however, only 567 of these women are reached at the same address. The researcher reports that these 567 women are representative of all mothers.
\end{enumerate}

\begin{quote}
Solution\\
It is unlikely that the women who were reached at the same address 3 years later are a random sample. These missing responders are probably renters (as opposed to homeowners) which means that they might be in a lower socio-economic status than the respondents.
\end{quote}

\pagebreak

\hypertarget{problem-3-1}{%
\subsection{Problem 3}\label{problem-3-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Sampling strategies}. A Math 377 student who is curious about the relationship between the amount of time students spend on social networking sites and their performance at school decides to conduct a survey. Four research strategies for collecting data are described below. In each, name the sampling method proposed and any bias you might expect.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  He randomly samples 40 students from the study's population, gives them the survey, asks them to fill it out and bring it back the next day.\\
\item
  He gives out the survey only to his friends, and makes sure each one of them fills out the survey.\\
\item
  He posts a link to an online survey on his Facebook wall and asks his friends to fill out the survey.\\
\item
  He stands outside the QRC and asks every third person that walks out the door to fill out the survey.
\end{enumerate}

\begin{quote}
Solution\\
a. Simple random sample. Non-response bias, if only those people who have strong opinions about the survey responds his sample may not be representative of the population.\\
b. Convenience sample. Under coverage bias, his sample may not be representative of the population since it consists only of his friends. It is also possible that the study will have non-response bias if some choose to not bring back the survey.\\
c.~Convenience sample. This will have a similar issues to handing out surveys to friends.\\
d.~Convenience sample. Same.
\end{quote}

\pagebreak

\hypertarget{problem-4}{%
\subsection{Problem 4}\label{problem-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Vitamin supplements}. In order to assess the effectiveness of taking large doses of vitamin C in reducing the duration of the common cold, researchers recruited 400 healthy volunteers from staff and students at a university. A quarter of the patients were assigned a placebo, and the rest were evenly divided between 1g Vitamin C, 3g Vitamin C, or 3g Vitamin C plus additives to be taken at onset of a cold for the following two days. All tablets had identical appearance and packaging. The nurses who handed the prescribed pills to the patients knew which patient received which treatment, but the researchers assessing the patients when they were sick did not. No significant differences were observed in any measure of cold duration or severity between the four medication groups, and the placebo group had the shortest duration of symptoms.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Was this an experiment or an observational study? Why?\\
\item
  What are the explanatory and response variables in this study?\\
\item
  Were the patients blinded to their treatment?\\
\item
  Was this study double-blind?\\
\item
  Participants are ultimately able to choose whether or not to use the pills prescribed to them. We might expect that not all of them will adhere and take their pills. Does this introduce a confounding variable to the study? Explain your reasoning.
\end{enumerate}

\begin{quote}
Solution\\
a. Experiment, since the researchers randomly assigned different treatments to the participants.\\
b. Response variable: Duration of the cold.\\
Explanatory variable: Treatment, with 4 levels; placebo, 1g, 3g, 3g with additives.\\
c.~The patients were blinded as they did not know which treatment they received.\\
d.~The study was double-blind with respect to the researchers evaluating the patients, but the nurses who briely interacted with patients during the distribution of the medication were not blinded. (It was partially double-blind.)\\
e. Since the patients were randomly assigned to the treatment groups and they are blinded we would expect about an equal number of patients in each group to not adhere to the treatment. While this means that final results of the study will be based on fewer number of participants, non-adherence does not introduce a confounding variable to
the study.
\end{quote}

\hypertarget{problem-5}{%
\subsection{Problem 5}\label{problem-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  \textbf{Exercise and mental health}. A researcher is interested in the effects of exercise on mental health and she proposes the following study: Use stratified random sampling to ensure representative proportions of 18-30, 31-40 and 41-55 year olds from the population. Next, randomly assign half the subjects from each age group to exercise twice a week, and instruct the rest not to exercise. Conduct a mental health exam at the beginning and at the end of the study, and compare the results.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What type of study is this?\\
\item
  What are the treatment and control groups in this study?\\
\item
  Does this study make use of blocking? If so, what is the blocking variable?\\
\item
  Does this study make use of blinding?\\
\item
  Comment on whether or not the results of the study can be used to establish a causal relationship between exercise and mental health, and indicate whether or not the conclusions can be generalized to the population at large.\\
\item
  Suppose you are given the task of determining if this proposed study should get funding. Would you have any reservations about the study proposal?
\end{enumerate}

\begin{quote}
Solution\\
a. This is an experiment since we assigned subjects to the exercise program.\\
b. The treatment is exercise twice a week and control is no exercise.\\
c, Yes, the blocking variable is age.\\
d.~No, the study is not blinded since the patients will know whether or not they are exercising.\\
e. Since this is an experiment, we can make a causal statement. Since the sample is random, the causal statement can be generalized to the population at large. However, we should be cautious about making a causal statement because of a possible placebo effect.\\
f.~It would be very difficult, if not impossible, to successfully conduct this study since randomly sampled people cannot be required to participate in a clinical trial.
\end{quote}

\hypertarget{NUMDATA}{%
\chapter{Numerical Data}\label{NUMDATA}}

\hypertarget{objectives-4}{%
\section{Objectives}\label{objectives-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and use properly in context all new terminology.\\
\item
  Generate in \texttt{R} summary statistics for a numeric variable including breaking down by cases.\\
\item
  Generate in \texttt{R} appropriate graphical summaries of numerical variables.\\
\item
  Be able to interpret and explain output both graphically and numerically.
\end{enumerate}

\hypertarget{homework-4}{%
\section{Homework}\label{homework-4}}

\hypertarget{problem-1-4}{%
\subsection{Problem 1}\label{problem-1-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Mammals exploratory}
\end{enumerate}

Data were collected on 39 species of mammals distributed over 13 orders. The data is in the \texttt{openintro} package as \texttt{mammals}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Using help, report the units for the variable \texttt{BrainWt}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?mammals}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Using \texttt{inspect} how many variables are numeric?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(mammals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## categorical variables:  
##      name  class levels  n missing
## 1 species factor     62 62       0
##                                    distribution
## 1 Africanelephant (1.6%) ...                   
## 
## quantitative variables:  
##               name   class    min     Q1  median       Q3    max       mean
## ...1       body_wt numeric  0.005  0.600  3.3425  48.2025 6654.0 198.789984
## ...2      brain_wt numeric  0.140  4.250 17.2500 166.0000 5712.0 283.134194
## ...3  non_dreaming numeric  2.100  6.250  8.3500  11.0000   17.9   8.672917
## ...4      dreaming numeric  0.000  0.900  1.8000   2.5500    6.6   1.972000
## ...5   total_sleep numeric  2.600  8.050 10.4500  13.2000   19.9  10.532759
## ...6     life_span numeric  2.000  6.625 15.1000  27.7500  100.0  19.877586
## ...7     gestation numeric 12.000 35.750 79.0000 207.5000  645.0 142.353448
## ...8     predation integer  1.000  2.000  3.0000   4.0000    5.0   2.870968
## ...9      exposure integer  1.000  1.000  2.0000   4.0000    5.0   2.419355
## ...10       danger integer  1.000  1.000  2.0000   4.0000    5.0   2.612903
##               sd  n missing
## ...1  899.158011 62       0
## ...2  930.278942 62       0
## ...3    3.666452 48      14
## ...4    1.442651 50      12
## ...5    4.606760 58       4
## ...6   18.206255 58       4
## ...7  146.805039 58       4
## ...8    1.476414 62       0
## ...9    1.604792 62       0
## ...10   1.441252 62       0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What type of variable is \texttt{danger}?
\end{enumerate}

Categorical

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Create a histogram of \texttt{total\_sleep} and describe the distribution.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{total_sleep,}\DataTypeTok{data=}\NormalTok{mammals,}\DataTypeTok{binwidth =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-3-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dens}\NormalTok{(}\OperatorTok{~}\NormalTok{total_sleep,}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-4-1.pdf}

The distribution is unimodal and skewed to the right. It appears it is centered around the value of 11.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Create a boxplot of \texttt{life\_span} and describe the distribution.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_boxplot}\NormalTok{(}\OperatorTok{~}\NormalTok{life_span,}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Report the mean and median life span of a mammal.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(}\OperatorTok{~}\NormalTok{life_span,}\DataTypeTok{data=}\NormalTok{mammals,}\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 19.87759
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{median}\NormalTok{(}\OperatorTok{~}\NormalTok{life_span,}\DataTypeTok{data=}\NormalTok{mammals,}\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.1
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Calculate the summary statistics for \texttt{LifeSpan} broken down by \texttt{Danger}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(life_span}\OperatorTok{~}\NormalTok{danger,}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   danger  min     Q1 median     Q3   max     mean       sd  n missing
## 1      1  3.0  7.700  17.60 32.500 100.0 24.20556 23.53829 18       1
## 2      2  2.3  4.500  10.40 13.000  50.0 12.92308 13.15948 13       1
## 3      3  2.0  4.175   5.35  7.875  38.6  9.43750 11.99559  8       2
## 4      4  2.6  9.775  22.10 27.000  69.0 23.11000 18.75482 10       0
## 5      5 17.0 20.000  23.60 30.000  46.0 26.95556 10.18910  9       0
\end{verbatim}

\hypertarget{problem-2-4}{%
\subsection{Problem 2}\label{problem-2-4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Mammals life spans}
\end{enumerate}

Continue using the \texttt{mammals} data set.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Create side-by-side boxplots for \texttt{life\_span} broken down by \texttt{exposure}. Note: you will have to change \texttt{exposure} to a \texttt{factor()}. Report on any findings.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mammals }\OperatorTok{%>%}
\KeywordTok{gf_boxplot}\NormalTok{(life_span}\OperatorTok{~}\KeywordTok{factor}\NormalTok{(exposure))}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What happened to the median and third quartile in exposure group 4?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(life_span}\OperatorTok{~}\KeywordTok{factor}\NormalTok{(exposure),}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   factor(exposure)  min    Q1 median     Q3   max     mean       sd  n missing
## 1                1  2.0  4.35   7.25 14.550 100.0 14.55000 20.98594 24       3
## 2                2  2.3  6.00  11.20 17.275  50.0 15.39167 14.55819 12       1
## 3                3  7.6 19.90  26.50 32.000  41.0 25.40000 13.84582  4       0
## 4                4  7.0 20.20  27.00 27.000  39.3 24.10000 11.78431  5       0
## 5                5 16.3 20.00  28.00 38.600  69.0 30.53077 14.98084 13       0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Create faceted histograms. What are the shortcomings of this plot?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{life_span,}\DataTypeTok{color=}\OperatorTok{~}\KeywordTok{factor}\NormalTok{(exposure),}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-11-1.pdf}

This is awful.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{life_span}\OperatorTok{|}\KeywordTok{factor}\NormalTok{(exposure),}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-12-1.pdf}

Not enough data for each histogram; some of the histograms provide little to no information. Let's do denisty plots.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dens}\NormalTok{(}\OperatorTok{~}\NormalTok{life_span,}\DataTypeTok{color=}\OperatorTok{~}\KeywordTok{factor}\NormalTok{(exposure),}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-13-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dens}\NormalTok{(}\OperatorTok{~}\NormalTok{life_span}\OperatorTok{|}\KeywordTok{factor}\NormalTok{(exposure),}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-14-1.pdf}

Which do you think is the best graph?

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Create a new variable \texttt{exposed} that is a factor with level \texttt{Low} if exposure is \texttt{1} or \texttt{2} and \texttt{High} otherwise.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mammals <-}\StringTok{ }\NormalTok{mammals }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{exposed=}\KeywordTok{factor}\NormalTok{(}\KeywordTok{ifelse}\NormalTok{((exposure}\OperatorTok{==}\DecValTok{1}\NormalTok{)}\OperatorTok{|}\NormalTok{(exposure}\OperatorTok{==}\DecValTok{2}\NormalTok{),}\StringTok{"Low"}\NormalTok{,}\StringTok{"High"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(mammals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## categorical variables:  
##      name  class levels  n missing
## 1 species factor     62 62       0
## 2 exposed factor      2 62       0
##                                    distribution
## 1 Africanelephant (1.6%) ...                   
## 2 Low (64.5%), High (35.5%)                    
## 
## quantitative variables:  
##               name   class    min     Q1  median       Q3    max       mean
## ...1       body_wt numeric  0.005  0.600  3.3425  48.2025 6654.0 198.789984
## ...2      brain_wt numeric  0.140  4.250 17.2500 166.0000 5712.0 283.134194
## ...3  non_dreaming numeric  2.100  6.250  8.3500  11.0000   17.9   8.672917
## ...4      dreaming numeric  0.000  0.900  1.8000   2.5500    6.6   1.972000
## ...5   total_sleep numeric  2.600  8.050 10.4500  13.2000   19.9  10.532759
## ...6     life_span numeric  2.000  6.625 15.1000  27.7500  100.0  19.877586
## ...7     gestation numeric 12.000 35.750 79.0000 207.5000  645.0 142.353448
## ...8     predation integer  1.000  2.000  3.0000   4.0000    5.0   2.870968
## ...9      exposure integer  1.000  1.000  2.0000   4.0000    5.0   2.419355
## ...10       danger integer  1.000  1.000  2.0000   4.0000    5.0   2.612903
##               sd  n missing
## ...1  899.158011 62       0
## ...2  930.278942 62       0
## ...3    3.666452 48      14
## ...4    1.442651 50      12
## ...5    4.606760 58       4
## ...6   18.206255 58       4
## ...7  146.805039 58       4
## ...8    1.476414 62       0
## ...9    1.604792 62       0
## ...10   1.441252 62       0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Repeat part c with the new variable.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dens}\NormalTok{(}\OperatorTok{~}\NormalTok{life_span,}\DataTypeTok{color=}\OperatorTok{~}\NormalTok{exposed,}\DataTypeTok{data=}\NormalTok{mammals)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-17-1.pdf}

\hypertarget{problem-3-2}{%
\subsection{Problem 3}\label{problem-3-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Mammals life spans continued}
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Create a scatterplot of life span versus length of gestation.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mammals }\OperatorTok{%>%}
\KeywordTok{gf_point}\NormalTok{(life_span}\OperatorTok{~}\NormalTok{gestation)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-18-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What type of an association is apparent between life span and length of gestation?
\end{enumerate}

It is a weak positive association.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What type of an association would you expect to see if the axes of the plot were reversed, i.e.~if we plotted length of gestation versus life span?
\end{enumerate}

The same as this is observational data there is no reason to beliee is a causal relationship just by looking at the data. Switching the axis will preserve the association.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Create the new scatterplot suggested in c.~
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mammals }\OperatorTok{%>%}
\KeywordTok{gf_point}\NormalTok{(gestation}\OperatorTok{~}\NormalTok{life_span)}
\end{Highlighting}
\end{Shaded}

\includegraphics{05-Numerical-Data-Solutions_files/figure-latex/unnamed-chunk-19-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Are life span and length of gestation independent? Explain your reasoning.
\end{enumerate}

No there is an association and it appears to be linear. If the plot looked like a ``shotgun'' blast, we would consider the variables to be independent. However, remember there may be confounding variables that could impact the association between these variables.

\hypertarget{CATDATA}{%
\chapter{Categorical Data}\label{CATDATA}}

\hypertarget{objectives-5}{%
\section{Objectives}\label{objectives-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and use properly in context all new terminology.
\item
  Generate in \texttt{R} tables for categorical variable(s).\\
\item
  Generate in \texttt{R} appropriate graphical summaries of categorical and numerical variables.\\
\item
  Be able to interpret and explain output both graphically and numerically.
\end{enumerate}

\hypertarget{homework-5}{%
\section{Homework}\label{homework-5}}

Make sure your plots have a title and the axes are labeled.

\hypertarget{problem-1-5}{%
\subsection{Problem 1}\label{problem-1-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Views on immigration}
\end{enumerate}

910 randomly sampled registered voters from Tampa, FL were asked if they thought workers who have illegally entered the US should be (i) allowed to keep their jobs and apply for US citizenship, (ii) allowed to keep their jobs as temporary guest workers but not allowed to apply for US citizenship, or (iii) lose their jobs and have to leave the country.

The data is in the \texttt{openintro} package in the \texttt{immigration} data object.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  How many levels of \emph{political} are there?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{levels}\NormalTok{(immigration}\OperatorTok{$}\NormalTok{political)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "conservative" "liberal"      "moderate"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(immigration)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## categorical variables:  
##        name  class levels   n missing
## 1  response factor      4 910       0
## 2 political factor      3 910       0
##                                    distribution
## 1 Leave the country (38.5%) ...                
## 2 conservative (40.9%), moderate (39.9%) ...
\end{verbatim}

There are three levels for \texttt{political} and they are conservative, liberal, and moderate.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a table using \texttt{tally}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(}\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{response}\OperatorTok{+}\NormalTok{political,}\DataTypeTok{data=}\NormalTok{immigration,}\DataTypeTok{format=}\StringTok{"percent"}\NormalTok{,}\DataTypeTok{margins =} \OtherTok{TRUE}\NormalTok{),}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                        political
## response                conservative liberal moderate  Total
##   Apply for citizenship         6.26   11.10    13.19  30.55
##   Guest worker                 13.30    3.08    12.42  28.79
##   Leave the country            19.67    4.95    13.85  38.46
##   Not sure                      1.65    0.11     0.44   2.20
##   Total                        40.88   19.23    39.89 100.00
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What percent of these Tampa, FL voters identify themselves as conservatives?
\end{enumerate}

From the table, 40.88\% of voters identified themselves as conservatives.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  What percent of these Tampa, FL voters are in favor of the citizenship option?
\end{enumerate}

Again, from the table 30.55\% of the voters favor the citizenship option.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  What percent of these Tampa, FL voters identify themselves as conservatives and are in favor of the citizenship option?
\end{enumerate}

From the table, 6.26\% of the voters are conservative and favor the citizenship option.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  What percent of these Tampa, FL voters who identify themselves as conservatives are also in favor of the citizenship option? What percent of moderates and liberal share this view?
\end{enumerate}

We need a different table for this question.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(}\KeywordTok{tally}\NormalTok{(response}\OperatorTok{~}\NormalTok{political,}\DataTypeTok{data=}\NormalTok{immigration,}\DataTypeTok{format=}\StringTok{"percent"}\NormalTok{,}\DataTypeTok{margins =} \OtherTok{TRUE}\NormalTok{),}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                        political
## response                conservative liberal moderate
##   Apply for citizenship        15.32   57.71    33.06
##   Guest worker                 32.53   16.00    31.13
##   Leave the country            48.12   25.71    34.71
##   Not sure                      4.03    0.57     1.10
##   Total                       100.00  100.00   100.00
\end{verbatim}

Of the conservative voters, 15.32\% are in favor of the citizenship option. The numbers are 57.71\% for liberals and 33.06\% for moderates.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Create a stacked bar chart.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{immigration }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_props}\NormalTok{(}\OperatorTok{~}\NormalTok{political,}\DataTypeTok{fill=}\OperatorTok{~}\NormalTok{response,}\DataTypeTok{position=}\StringTok{"fill"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Tampa Florida Voter Views on Illegal Immigrant Workers"}\NormalTok{,}
          \DataTypeTok{subtitle=}\StringTok{"Broken down by political views"}\NormalTok{,}\DataTypeTok{x=}\StringTok{"Political View"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Proportion"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-Categorical-Data-Solutions_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Using your plot, do political ideology and views on immigration appear to be independent? Explain your reasoning.
\end{enumerate}

The percentages of Tampa, FL conservatives, moderates, and liberals who are in favor of illegal immigrants working in the US staying and applying for citizenship are quite different from one another. Therefore, the two variables appear to be dependent.

\pagebreak

\hypertarget{problem-2-5}{%
\subsection{Problem 2}\label{problem-2-5}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Views on the DREAM Act} The same survey from Exercise 1 also asked respondents if they support the DREAM Act, a proposed law which would provide a path to citizenship for people brought illegally to the US as children.
\end{enumerate}

The data is in the \texttt{openintro} package in the \texttt{dream} data object.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Create a \textbf{mosaic} plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mosaic}\NormalTok{(stance}\OperatorTok{~}\NormalTok{ideology,}\DataTypeTok{data=}\NormalTok{dream,}\DataTypeTok{sub=}\StringTok{"Voter views on illegal worker status"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-Categorical-Data-Solutions_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Based on the mosaic plot, are views on the DREAM Act and political ideology independent?
\end{enumerate}

The vertical locations at which the ideological groups break into the Yes, No, and Not Sure categories differ, which indicates the variables are dependent.

\pagebreak

\hypertarget{problem-3-3}{%
\subsection{Problem 3}\label{problem-3-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Heart transplants}
\end{enumerate}

The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was designated an official heart transplant candidate, meaning that he was gravely ill and would most likely benefit from a new heart. Some patients got a transplant and some did not. The variable \emph{transplant} indicates which group the patients were in; patients in the treatment group got a transplant and those in the control group did not. Another variable called \emph{survived} was used to indicate whether or not the patient was alive at the end of the study.

The data is in the \texttt{openintro} package and is called \texttt{heart\_transplant}.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Create a \textbf{mosaic} plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mosaic}\NormalTok{(survived}\OperatorTok{~}\NormalTok{transplant,}\DataTypeTok{data=}\NormalTok{heart_transplant)}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-Categorical-Data-Solutions_files/figure-latex/unnamed-chunk-8-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Based on the mosaic plot, is survival independent of whether or not the patient got a transplant? Explain your reasoning.
\end{enumerate}

Proportion of patients who are alive at the end of the study is higher in the treatment group than in the control group. These data suggest that survival is not independent of whether or not the patient got a transplant.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Using \emph{survtime} create side-by-side boxplots for the control and treatment groups.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heart_transplant }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(survtime}\OperatorTok{~}\NormalTok{transplant) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Survival times for tranplant experiment"}\NormalTok{,}
          \DataTypeTok{sub=}\StringTok{"Treatment group had the transplant"}\NormalTok{,}\DataTypeTok{x=}\StringTok{"Tranplant"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Survival time in days"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{06-Categorical-Data-Solutions_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  What do the box plots suggest about the efficacy (effectiveness) of transplants?
\end{enumerate}

The shape of the distribution of survival times in both groups is right skewed with one very clear outlier for the control group and other possible outliers in both groups on the high end. The median survival time for the control group is much lower than the median survival time for the treatment group; patients who got a transplant typically lived longer. Tying this together with the much lower variability in the control group, evident by a much smaller IQR than the treatment group (about 50 days versus 500 days), and we can see that patients who did not get a heart transplant tended to consistently die quite early relative to those who did have a transplant. Overall, very few patients without transplants made it beyond a year while nearly half of the transplant patients survived at least one year. It should also be noted that while the first and third quartiles of the treatment group is higher than those for the control group, the IQR for the treatment group is much bigger, indicating that there is more variability in survival times in the treatment group.

\hypertarget{part-probability-modeling}{%
\part{Probability Modeling}\label{part-probability-modeling}}

\hypertarget{CS2}{%
\chapter{Case Study}\label{CS2}}

\hypertarget{objectives-6}{%
\section{Objectives}\label{objectives-6}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Use R to simulate a probabilistic model.\\
\item
  Use basic counting methods.
\end{enumerate}

\hypertarget{homework-6}{%
\section{Homework}\label{homework-6}}

\hypertarget{problem-1-6}{%
\subsection{Problem 1}\label{problem-1-6}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Exactly 2 people with the same birthday - Simulation}. Complete a similar analysis for case where exactly 2 people in a room of 23 people have the same birthday. In this exercise you will use a computational simulation.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Create a new R Markdown file and create a report. Yes, we know you could use this file but we want you to practice generating your own report.
\item
  Simulate having 23 people in the class with each day of the year equally likely. Find the cases where exactly 2 people have the same birthday, you will have to alter the code from the Notes more than changing 18 to 23.
\item
  Plot the frequency of occurrences as a bar chart.
\item
  Estimate the probability of exactly two people having the same birthday.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(}\KeywordTok{sample}\NormalTok{(days,}\DataTypeTok{size=}\DecValTok{23}\NormalTok{,}\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{match=}\KeywordTok{if_else}\NormalTok{(length}\OperatorTok{==}\DecValTok{22}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{prob=}\KeywordTok{mean}\NormalTok{(match))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    prob
## 1 0.362
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(}\KeywordTok{sample}\NormalTok{(days,}\DataTypeTok{size=}\DecValTok{23}\NormalTok{,}\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_bar}\NormalTok{(}\OperatorTok{~}\NormalTok{length)}
\end{Highlighting}
\end{Shaded}

\includegraphics{07-Probability-Case-Study-Solution_files/figure-latex/unnamed-chunk-3-1.pdf}

\hypertarget{problem-2-6}{%
\subsection{Problem 2}\label{problem-2-6}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Exactly 2 people with the same birthday - Mathematical}. Repeat problem 1 but do it mathematically. As a big hint, you will need to use the \texttt{choose()} function. The idea is that with 23 people we need to choose 2 of them to match. We thus need to multiply, the multiplication rule again, by \texttt{choose(23,2)}. If you are having trouble, work with a total of 3 people in the room first.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Find a formula to determine the exact probability of exactly 2 people in a room of 23 having the same birthday.
\item
  Generalize your solution to any number \texttt{n} people in the room and create a function.
\item
  Vectorize the function.
\item
  Plot the probability of exactly 2 people having the same birthday versus number of people in the room.
\item
  Comment on the shape of the curve and explain it.
\item
  \texttt{knit} and compile your report.
\end{enumerate}

For two people we have

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{choose}\NormalTok{(}\DecValTok{23}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\KeywordTok{prod}\NormalTok{(}\DecValTok{365}\OperatorTok{:}\DecValTok{344}\NormalTok{)}\OperatorTok{/}\DecValTok{365}\OperatorTok{^}\DecValTok{23}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3634222
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exactly_two <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n)\{}
  \KeywordTok{choose}\NormalTok{(n,}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\KeywordTok{prod}\NormalTok{(}\DecValTok{365}\OperatorTok{:}\NormalTok{(}\DecValTok{365}\OperatorTok{-}\NormalTok{(n}\DecValTok{-2}\NormalTok{)))}\OperatorTok{/}\DecValTok{365}\OperatorTok{^}\NormalTok{n}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{exactly_two}\NormalTok{(}\DecValTok{23}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3634222
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exactly_two <-}\StringTok{ }\KeywordTok{Vectorize}\NormalTok{(exactly_two)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_line}\NormalTok{(}\KeywordTok{exactly_two}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{100}\NormalTok{)}\OperatorTok{~}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{100}\NormalTok{),}
        \DataTypeTok{xlab=}\StringTok{"Number of People"}\NormalTok{,}
        \DataTypeTok{ylab=}\StringTok{"Probability of Match"}\NormalTok{,}
        \DataTypeTok{title=}\StringTok{"Probability of exactly least 2 people with matching birthdays"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{07-Probability-Case-Study-Solution_files/figure-latex/unnamed-chunk-8-1.pdf}

By the way, exactly three matches in simulation is hard. We have to table the data

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\NormalTok{temp <-}\StringTok{ }\KeywordTok{table}\NormalTok{(}\KeywordTok{sample}\NormalTok{(days,}\DataTypeTok{size=}\DecValTok{23}\NormalTok{,}\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{))}
\NormalTok{temp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  13  24  50  72  92 110 137 143 154 155 211 231 263 271 285 330 338 342 344 351 
##   1   1   1   1   1   1   1   1   1   1   1   1   1   1   2   2   1   1   1   1 
## 365 
##   1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{sum}\NormalTok{(temp}\OperatorTok{==}\DecValTok{2}\NormalTok{) }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{)}\OperatorTok{+}\DecValTok{0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\NormalTok{((}\KeywordTok{sum}\NormalTok{(}\KeywordTok{table}\NormalTok{(}\KeywordTok{sample}\NormalTok{(days,}\DataTypeTok{size=}\DecValTok{23}\NormalTok{,}\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{==}\StringTok{ }\DecValTok{3}\NormalTok{)}\OperatorTok{==}\DecValTok{1}\NormalTok{)}\OperatorTok{+}\DecValTok{0}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{prob=}\KeywordTok{mean}\NormalTok{(result))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     prob
## 1 0.0117
\end{verbatim}

Two sets that have same but different birthday

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\NormalTok{((}\KeywordTok{sum}\NormalTok{(}\KeywordTok{table}\NormalTok{(}\KeywordTok{sample}\NormalTok{(days,}\DataTypeTok{size=}\DecValTok{23}\NormalTok{,}\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{)}\OperatorTok{==}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\DecValTok{0}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{prob=}\KeywordTok{mean}\NormalTok{(result))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     prob
## 1 0.1139
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(}\KeywordTok{sample}\NormalTok{(days,}\DataTypeTok{size=}\DecValTok{23}\NormalTok{,}\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{match=}\KeywordTok{if_else}\NormalTok{(length}\OperatorTok{==}\DecValTok{21}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{prob=}\KeywordTok{mean}\NormalTok{(match))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     prob
## 1 0.1187
\end{verbatim}

Mathematically exactly 3 is easy. Simulation seems to be off a little or the math formula is off.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{choose}\NormalTok{(}\DecValTok{23}\NormalTok{,}\DecValTok{3}\NormalTok{)}\OperatorTok{*}\KeywordTok{prod}\NormalTok{(}\DecValTok{365}\OperatorTok{:}\DecValTok{345}\NormalTok{)}\OperatorTok{/}\DecValTok{365}\OperatorTok{^}\DecValTok{23}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.007395218
\end{verbatim}

\hypertarget{PROBRULES}{%
\chapter{Probability Rules}\label{PROBRULES}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}

\hypertarget{objectives-7}{%
\section{Objectives}\label{objectives-7}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and use properly in context all new terminology related to probability to include but not limited to: outcome, event, sample space, probability.\\
\item
  Apply basic probability and counting rules to find probabilities.\\
\item
  Describe the basic axioms of probability.\\
\item
  Use \texttt{R} to calculate and simulate probabilities of events.
\end{enumerate}

\hypertarget{homework-7}{%
\section{Homework}\label{homework-7}}

\hypertarget{problem-1-7}{%
\subsection{Problem 1}\label{problem-1-7}}

\indent 1. Let \(A\), \(B\) and \(C\) be events such that \(\mbox{P}(A)=0.5\), \(\mbox{P}(B)=0.3\), and \(\mbox{P}(C)=0.4\). Also, we know that \(\mbox{P}(A \cap B)=0.2\), \(\mbox{P}(B \cap C)=0.12\), \(\mbox{P}(A \cap C)=0.1\), and \(\mbox{P}(A \cap B \cap C)=0.05\). Find the following:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \(\mbox{P}(A\cup B)\)
  \[
  \mbox{P}(A\cup B) = \mbox{P}(A)+\mbox{P}(B)-\mbox{P}(A\cap B)= 0.5+0.3-0.2 = 0.6
  \]
\item
  \(\mbox{P}(A\cup B \cup C)\)
  \[
  \mbox{P}(A\cup B \cup C) = \mbox{P}(A)+\mbox{P}(B)+\mbox{P}(C)-\mbox{P}(A\cap B)-\mbox{P}(A\cap C)-\mbox{P}(B\cap C)+\mbox{P}(A\cap B \cap C)
  \]
  \[
  = 0.5+0.3+0.4-0.2-0.12-0.1+0.05 = 0.83
  \]
\item
  \(\mbox{P}(B'\cap C')\)
  \[
  \mbox{P}(B'\cap C')=\mbox{P}((B\cup C)') = 1-\mbox{P}(B\cup C) = 1-[\mbox{P}(B)+\mbox{P}(C)-\mbox{P}(B\cap C)]
  \]
  \[
  = 1-(0.3+0.4-0.12) = 0.42
  \]
\item
  \(\mbox{P}(A\cup (B\cap C))\)
  \[
  \mbox{P}(A\cup (B\cap C)) = \mbox{P}(A)+\mbox{P}(B\cap C) -\mbox{P}(A\cap B \cap C) = 0.5+0.12-0.05 = 0.57
  \]
\item
  \(\mbox{P}((A\cup B \cup C)\cap (A\cap B \cap C)')\)
  \[
  \mbox{P}((A\cup B \cup C)\cap (A\cap B \cap C)')=\mbox{P}(A\cup B \cup C)-\mbox{P}(A\cap B \cap C) = 0.83-0.05 = 0.78
  \]
\end{enumerate}

\hypertarget{problem-2-7}{%
\subsection{Problem 2}\label{problem-2-7}}

\indent 2. Consider the example of the family in the reading. What is the probability that the family has at least one boy?\\
\[
\mbox{P}(\mbox{at least one boy})=1-\mbox{P}(\mbox{no boys})=1-\mbox{P}(\mbox{GGG})=1-\frac{1}{8} = 0.875
\]

\hypertarget{problem-3-4}{%
\subsection{Problem 3}\label{problem-3-4}}

\indent 3. The Birthday Problem Revisited.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Suppose there are \(n=20\) students in a classroom. My birthday, the instructor, is April 3rd. What is the probability that at least one student shares my birthday? Assume only 365 days in a year and assume that all birthdays are equally likely.
\end{enumerate}

\[
\mbox{P}(\mbox{at least one other person shares my bday})=1-\mbox{P}(\mbox{no one else has my bday}) = 
\]

\[
1-\left( \frac{364}{365}\right)^{20} = 0.0534
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  In \texttt{R}, find the probability that at least one other person shares my birthday for each value of \(n\) from 1 to 80. Plot these probabilities with \(n\) on the \(x\)-axis and probability on the \(y\)-axis. At what value of \(n\) would the probability be at least 50\%?
\end{enumerate}

Generalizing,
\[
\mbox{P}(\mbox{at least one other person shares my bday})=1-\mbox{P}(\mbox{no one else has my bday}) = 1-\left( \frac{364}{365}\right)^{n}
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n<-}\DecValTok{1}\OperatorTok{:}\DecValTok{300}
\NormalTok{mybday<-}\ControlFlowTok{function}\NormalTok{(x) }\DecValTok{1}\OperatorTok{-}\NormalTok{(}\DecValTok{364}\OperatorTok{/}\DecValTok{365}\NormalTok{)}\OperatorTok{^}\NormalTok{x}
\NormalTok{mybday <-}\StringTok{ }\KeywordTok{Vectorize}\NormalTok{(mybday)}
\end{Highlighting}
\end{Shaded}

Check our function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mybday}\NormalTok{(}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.05339153
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_line}\NormalTok{(}\KeywordTok{mybday}\NormalTok{(n)}\OperatorTok{~}\StringTok{ }\NormalTok{n,}
        \DataTypeTok{xlab=}\StringTok{"Number of People"}\NormalTok{,}
        \DataTypeTok{ylab=}\StringTok{"Probability of Match"}\NormalTok{,}
        \DataTypeTok{title=}\StringTok{"Probability of at least 1 person matching my birthday"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(theme_bw)}
\end{Highlighting}
\end{Shaded}

\includegraphics{08-Probability-Rules-Solutions_files/figure-latex/unnamed-chunk-3-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob <-}\StringTok{ }\KeywordTok{mybday}\NormalTok{(n)}
\KeywordTok{which}\NormalTok{(prob}\OperatorTok{>=}\StringTok{ }\FloatTok{.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
## [20] 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290
## [39] 291 292 293 294 295 296 297 298 299 300
\end{verbatim}

So 253 people.

\hypertarget{problem-4-1}{%
\subsection{Problem 4}\label{problem-4-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Thinking of the cards again. Answer the following questions:
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Define two events that are mutually exclusive.
\end{enumerate}

The first card drawn is red.\\
The first card drawn is black.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Define two events that are independent.
\end{enumerate}

The first card drawn is black.\\
The first card drawn is a face card.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Define an event and its complement.
\end{enumerate}

The first card drawn is less than 5.\\
The first card drawn is equal to or more than 5.

\hypertarget{problem-5-1}{%
\subsection{Problem 5}\label{problem-5-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Consider the license plate example from the reading.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What is the probability that a license plate contains \textbf{exactly} one ``B''?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#fourth spot}
\NormalTok{num4<-}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{1}\OperatorTok{*}\DecValTok{25}\OperatorTok{*}\DecValTok{25}

\CommentTok{#fifth spot}
\NormalTok{num5<-}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{25}\OperatorTok{*}\DecValTok{1}\OperatorTok{*}\DecValTok{25}

\CommentTok{#sixth spot}
\NormalTok{num6<-}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{25}\OperatorTok{*}\DecValTok{25}\OperatorTok{*}\DecValTok{1}

\NormalTok{denom<-}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{26}\OperatorTok{*}\DecValTok{26}\OperatorTok{*}\DecValTok{26}

\NormalTok{(num4}\OperatorTok{+}\NormalTok{num5}\OperatorTok{+}\NormalTok{num6)}\OperatorTok{/}\NormalTok{denom}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1066796
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What is the probability that a license plate contains \textbf{at least one} ``B''?
\end{enumerate}

\[
1-\mbox{P}(\mbox{no B's})
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num0<-}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{10}\OperatorTok{*}\DecValTok{25}\OperatorTok{*}\DecValTok{25}\OperatorTok{*}\DecValTok{25}
\DecValTok{1}\OperatorTok{-}\NormalTok{num0}\OperatorTok{/}\NormalTok{denom}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1110036
\end{verbatim}

\hypertarget{problem-6}{%
\subsection{Problem 6}\label{problem-6}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Consider the party example in the reading.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Suppose 8 people showed up to the party dressed as zombies. What is the probability that all three awards are won by people dressed as zombies?
  \[
  \frac{8\cdot 7 \cdot 6}{25\cdot 24 \cdot 23}
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{8}\OperatorTok{*}\DecValTok{7}\OperatorTok{*}\DecValTok{6}\NormalTok{)}\OperatorTok{/}\NormalTok{(}\DecValTok{25}\OperatorTok{*}\DecValTok{24}\OperatorTok{*}\DecValTok{23}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02434783
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What is the probability that zombies win ``most creative'' and ``funniest'' but not ``scariest''?
  \[
  \frac{8 \cdot 17 \cdot 7}{25 \cdot 24 \cdot 23}
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{8}\OperatorTok{*}\DecValTok{17}\OperatorTok{*}\DecValTok{7}\NormalTok{)}\OperatorTok{/}\NormalTok{(}\DecValTok{25}\OperatorTok{*}\DecValTok{24}\OperatorTok{*}\DecValTok{23}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.06898551
\end{verbatim}

\hypertarget{problem-7}{%
\subsection{Problem 7}\label{problem-7}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Consider the cards example from the reading.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  How many ways can we obtain a ``two pairs'' (2 of one number, 2 of another, and the final different)?
\end{enumerate}

We have to pick the rank of the two pairs.

\[\binom{13}{2}\]
Notice here the order does matter because a pair of Kings and 4s is the same as a pair of 4s and Kings. This is different from the full house example. Make sure you understand this point.

Now we have to pick two of the fours cards for each rank

\[\binom{4}{2}\binom{4}{2}\]

And finally we need the last card to come from the 44 remaining cards so that we don't get a full house.

\(\binom{44}{1}\)

Putting it all together:

\(\binom{13}{2}\binom{4}{2}\binom{4}{2}\binom{44}{1}\)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{choose}\NormalTok{(}\DecValTok{13}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\KeywordTok{choose}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\KeywordTok{choose}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\KeywordTok{choose}\NormalTok{(}\DecValTok{44}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 123552
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What is the probability of drawing a ``four of a kind'' (four cards of the same value)?
\end{enumerate}

\[
\mbox{P}(\mbox{4 of a kind})=\frac{\binom{13}{1}\binom{4}{4}\binom{48}{1}}{\binom{52}{5}}
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{13}\OperatorTok{*}\DecValTok{1}\OperatorTok{*}\DecValTok{48}\NormalTok{)}\OperatorTok{/}\KeywordTok{choose}\NormalTok{(}\DecValTok{52}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.000240096
\end{verbatim}

\hypertarget{problem-8}{%
\subsection{Problem 8}\label{problem-8}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Advanced Question: Consider rolling 5 dice. What is the \textbf{probability} of a pour resulting in a full house?
\end{enumerate}

First pick the value for the three of a kind, there are 6. Then pick the value from the remaining 5 for the two of a kind. This is actually a permutation. There are 30 distinct ``flavors'' of full house (three 1's \& two 2's, three 1's \& two 3's, etc.). In the reading we did this as
\[
\binom{6}{1} \times \binom{5}{1}
\]
We now have the 5 dice. We have to select three to have the same value and the order doesn't matter since they are the same value. Thus we multiple by \(\binom{5}{3}\). Divide this by the total distinct ways the dice could have landed (assuming order matters).
\[
\mbox{P}(\mbox{full house}) = \frac{30 \times \frac{5!}{3!2!}}{6^5}
\]
\[
\mbox{P}(\mbox{full house}) = \frac{\binom{6}{1} \times \binom{5}{1} \times \binom{5}{3}}{6^5}
\]

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{30}\OperatorTok{*}\DecValTok{10}\OperatorTok{/}\NormalTok{(}\DecValTok{6}\OperatorTok{^}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.03858025
\end{verbatim}

Simulating is tough so let's write some code that may help.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{23}\NormalTok{)}
\NormalTok{temp<-}\KeywordTok{table}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{,}\DataTypeTok{size=}\DecValTok{5}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{))}
\NormalTok{temp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 1 3 4 5 
## 1 2 1 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(temp}\OperatorTok{==}\DecValTok{2}\NormalTok{) }\OperatorTok{&}\StringTok{ }\KeywordTok{sum}\NormalTok{(temp}\OperatorTok{==}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp<-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{temp<-}\KeywordTok{table}\NormalTok{(temp)}
\NormalTok{temp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## temp
## 1 2 
## 3 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(temp}\OperatorTok{==}\DecValTok{2}\NormalTok{) }\OperatorTok{&}\StringTok{ }\KeywordTok{sum}\NormalTok{(temp}\OperatorTok{==}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

Let's write a function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{full_house <-}\ControlFlowTok{function}\NormalTok{(x)\{}
\NormalTok{  temp<-}\KeywordTok{table}\NormalTok{(x)}
  \KeywordTok{sum}\NormalTok{(temp}\OperatorTok{==}\DecValTok{2}\NormalTok{) }\OperatorTok{&}\StringTok{ }\KeywordTok{sum}\NormalTok{(temp}\OperatorTok{==}\DecValTok{3}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp<-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\KeywordTok{full_house}\NormalTok{(temp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{751}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{full_house}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{,}\DataTypeTok{size=}\DecValTok{5}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{))}
\KeywordTok{mean}\NormalTok{(}\OperatorTok{~}\NormalTok{full_house,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.039
\end{verbatim}

\hypertarget{CONDPROB}{%
\chapter{Conditional Probability}\label{CONDPROB}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}

\hypertarget{objectives-8}{%
\section{Objectives}\label{objectives-8}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define conditional probability and distinguish it from joint probability.\\
\item
  Find a conditional probability using its definition.\\
\item
  Using conditional probability, determine whether two events are independent.\\
\item
  Apply Bayes' Rule mathematically and via simulation.
\end{enumerate}

\hypertarget{homework-8}{%
\section{Homework}\label{homework-8}}

\hypertarget{problem-1-8}{%
\subsection{Problem 1}\label{problem-1-8}}

\indent 1. Consider Exercise 1 from Lesson 2. Recall: \(A\), \(B\) and \(C\) are events such that \(\mbox{P}(A)=0.5\), \(\mbox{P}(B)=0.3\), \(\mbox{P}(C)=0.4\), \(\mbox{P}(A \cap B)=0.2\), \(\mbox{P}(B \cap C)=0.12\), \(\mbox{P}(A \cap C)=0.1\), and \(\mbox{P}(A \cap B \cap C)=0.05\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Are \(A\) and \(B\) independent?
\end{enumerate}

No.~\(\mbox{P}(A)\mbox{P}(B)=0.15\neq \mbox{P}(A\cap B)\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Are \(B\) and \(C\) independent?
\end{enumerate}

Yes. \(\mbox{P}(B)\mbox{P}(C)=0.12 = \mbox{P}(B\cap C)\). Also,
\[
\mbox{P}(B|C)=\frac{\mbox{P}(B\cap C)}{\mbox{P}(C)}= 0.12/0.4 = 0.3 =\mbox{P}(B)
\]

\hypertarget{problem-2-8}{%
\subsection{Problem 2}\label{problem-2-8}}

\indent 2. Suppose I have a biased coin (the probability I flip a heads is 0.6). I flip that coin twice. Assume that the coin is memoryless (flips are independent of one another).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What is the probability that the second flip results in heads?
\end{enumerate}

0.6

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What is the probability that the second flip results in heads, given the first also resulted in heads?
\end{enumerate}

The coin is memoryless. So,
\[
\mbox{P}(\mbox{2nd flip heads}|\mbox{1st flip heads}) = 0.6
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What is the probability both flips result in heads?
\end{enumerate}

Since the flips are independent,
\[
\mbox{P}(\mbox{both heads})=\mbox{P}(\mbox{1st flip heads})\mbox{P}(\mbox{2nd flip heads}) = 0.6*0.6=0.36
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  What is the probability exactly one coin flip results in heads?
\end{enumerate}

This could happen in two ways. The first could be heads OR the second could be heads.
\[
\mbox{P}(\mbox{exactly one heads})=\mbox{P}(\mbox{1st flip heads})\mbox{P}(\mbox{2nd flip tails}) + \mbox{P}(\mbox{1st flip tails})\mbox{P}(\mbox{2nd flip heads})
\]
\[
0.6*0.4+0.4*0.6 = 0.48
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Now assume I flip the coin five times. What is the probability the result is 5 heads?
  \[
  \mbox{P}(\mbox{5 heads})= 0.6^5 = 0.0778
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.6}\OperatorTok{^}\DecValTok{5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.07776
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  What is the probability the result is exactly 2 heads (out of 5 flips)?
\end{enumerate}

There are \(\binom{5}{2} = 10\) ways for this to happen (\{HHTTT\},\{HTHTT\},\ldots). So,
\[
\mbox{P}(\mbox{2 heads out of 5 flips})=\binom{5}{2} 0.6^2(1-0.6)^3 = 0.2304
\]

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{choose}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\FloatTok{0.6}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\FloatTok{0.4}\OperatorTok{^}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2304
\end{verbatim}

\hypertarget{problem-3-5}{%
\subsection{Problem 3}\label{problem-3-5}}

\indent 3. (Adapted from IPSUR, \citep{ipsur}). Suppose there are three assistants working at a company: Moe, Larry and Curly. All three assist with a filing process. Only one filing assistant is needed at a time. Moe assists 60\% of the time, Larry assists 30\% of the time and Curly assists the remaining 10\% of the time. Occasionally, they make errors (misfiles); Moe has a misfile rate of 0.01, Larry has a misfile rate of 0.025, and Curly has a rate of 0.05. Suppose a misfile was discovered, but it is unknown who was on schedule when it occurred. Who is most likely to have committed the misfile? Calculate the probabilities for each of the three assistants.

Let \(E\) be the event a misfile was committed. Also, let \(M\), \(L\), and \(C\) denote the events that Moe, Larry and Curly was the assistant at the time, respectively.

\[
\mbox{P}(E)=\mbox{P}(E \cap M)+\mbox{P}(E \cap L)+\mbox{P}(E\cap C) 
\]
\[
= \mbox{P}(E|M)\mbox{P}(M)+\mbox{P}(E|L)\mbox{P}(L)+\mbox{P}(E|C)\mbox{P}(C) = 0.01*0.6+0.025*0.3+0.05*0.1 = 0.0185
\]

Thus,
\[
\mbox{P}(M|E)=\frac{\mbox{P}(E \cap M)}{\mbox{P}(E)}= \frac{0.01*0.6}{0.0185}=0.3243
\]

Similarly, \(\mbox{P}(L|E)=0.4054\) and \(\mbox{P}(C|E)=0.2702\).

Larry is the assistant most likely to have committed the error.

\hypertarget{problem-4-2}{%
\subsection{Problem 4}\label{problem-4-2}}

\indent 4. You are playing a game where there are two coins. One coin is fair and the other comes up \emph{heads} 80\% of the time. One coin is flipped 3 times and the result is three \emph{heads}, what is the probability that the coin flipped is the fair coin? You will need to make an assumption about the probability of either coin being selected.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Use Bayes formula to solve this problem.
\end{enumerate}

I will assume either coin is selected with a 50\% probability.

\[
\mbox{P}(Fair) = \mbox{P}(Biased) = .5
\]
\[
\mbox{P}(3 Heads|Fair)=\frac{1}{2}^3=\frac{1}{8}
\]
\[
\mbox{P}(3 Heads|Biased)=.8^3=0.512
\]

Now

\[
\mbox{P}(Fair | 3 Heads) = \frac{\mbox{P}(3 Heads | Fair)\mbox{P}(Fair)}{\mbox{P}(3 Heads | Fair)\mbox{P}(Fair)+\mbox{P}(3 Heads| Biased)\mbox{P}(Biased)}
\]

Which is

\[
\mbox{P}(Fair | 3 Heads) =  \frac{\frac{1}{8}\frac{1}{2}}{\frac{1}{8}\frac{1}{2}+.8^{3}\frac{1}{2}} = 0.196
\]

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{.125}\OperatorTok{*}\NormalTok{.}\DecValTok{5}\OperatorTok{/}\NormalTok{(.}\DecValTok{125}\OperatorTok{*}\NormalTok{.}\DecValTok{5}\FloatTok{+.8}\OperatorTok{^}\DecValTok{3}\OperatorTok{*}\NormalTok{.}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1962323
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Use simulation to solve this problem.
\end{enumerate}

Let's use the same assumptions. We could do this problem in two ways. We could flip each coin a fixed number of times and combine the information or use a random process to pick a flipped coin and then flip it three times. Let's do the first.

Let's flip a fair coin 50,000 times and count how many heads we get.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1154}\NormalTok{)}
\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{50000}\NormalTok{)}\OperatorTok{*}\KeywordTok{rflip}\NormalTok{(}\DecValTok{3}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(heads}\OperatorTok{==}\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{count=}\KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6157
\end{verbatim}

Now flip the biased coin.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{50000}\NormalTok{)}\OperatorTok{*}\KeywordTok{rflip}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DataTypeTok{prob=}\FloatTok{0.8}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(heads}\OperatorTok{==}\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{count=}\KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 25743
\end{verbatim}

So we have a total 6157 + 25743 heads of which 6157 came from the fair coin.

Thus the probability of the coin being fair given 3 heads on the flips is:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{6157}\OperatorTok{/}\NormalTok{(}\DecValTok{6157} \OperatorTok{+}\StringTok{ }\DecValTok{25743}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1930094
\end{verbatim}

Or 19.3\%.

Next pick a one of the coins with equal probability 100,000 times.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{501}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{rflip}\NormalTok{(}\DecValTok{100000}\NormalTok{,}\DataTypeTok{summarize =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       n heads tails prob
## 1 1e+05 50226 49774  0.5
\end{verbatim}

Now the fair coin was flipped 50226 times.

Let's see how many times we get 3 heads when we flip that coin 3 times.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{50226}\NormalTok{)}\OperatorTok{*}\KeywordTok{rflip}\NormalTok{(}\DecValTok{3}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(heads}\OperatorTok{==}\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{count=}\KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6270
\end{verbatim}

We have 6270 cases with 3 heads. Now for the biased coin.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{49774}\NormalTok{)}\OperatorTok{*}\KeywordTok{rflip}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DataTypeTok{prob=}\FloatTok{0.8}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(heads}\OperatorTok{==}\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{count=}\KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 25512
\end{verbatim}

Now we can determine the probability of a fair coin given 3 heads.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{6270}\OperatorTok{/}\NormalTok{(}\DecValTok{6270}\OperatorTok{+}\DecValTok{25512}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1972815
\end{verbatim}

This code we could easily adapt if we don't think each coin is being selected with the same frequency. Suppose we think the fair coin has a 75\% chance of being selected. The analysis would look like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{9021}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{rflip}\NormalTok{(}\DecValTok{100000}\NormalTok{,}\DataTypeTok{prob=}\NormalTok{.}\DecValTok{75}\NormalTok{,}\DataTypeTok{summarize =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{results}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       n heads tails prob
## 1 1e+05 75023 24977 0.75
\end{verbatim}

Now the fair coin was flipped 75023 times.

Let's see how many times we get 3 heads when we flip that coin 3 times.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{75023}\NormalTok{)}\OperatorTok{*}\KeywordTok{rflip}\NormalTok{(}\DecValTok{3}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(heads}\OperatorTok{==}\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{count=}\KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9579
\end{verbatim}

We have 9579 cases with 3 heads. Now for the biased coin.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data.frame}\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{24977}\NormalTok{)}\OperatorTok{*}\KeywordTok{rflip}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DataTypeTok{prob=}\FloatTok{0.8}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(heads}\OperatorTok{==}\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{count=}\KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12789
\end{verbatim}

Now we can determine the probability of a fair coin given 3 heads.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{9579}\OperatorTok{/}\NormalTok{(}\DecValTok{9579}\OperatorTok{+}\DecValTok{12789}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4282457
\end{verbatim}

A much different answer. That is because prior to getting the data we believed the fair coin would be selected with a 75\% probability. The data indicates that we need to update and lower this probability. We only flipped 3 times but the evidence is so in favor of the biased coin, that our probability dropped substantially. This is why Bayes is such a powerful tool.

Think about what we just did with this problem. We started with a subjective believe that either coin would be selected with equal probability. This is called the prior probability. We then collected data on three flips of the coin. We used this empirical data to update our belief into a posterior probability. This is the basis for Bayesian statistical analysis. Bayesian statistics is an entire discipline unto itself.

\hypertarget{RANDVAR}{%
\chapter{Random Variables}\label{RANDVAR}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}

\hypertarget{objectives-9}{%
\section{Objectives}\label{objectives-9}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and use properly in context all new terminology.\\
\item
  Given a discrete random variable, obtain the pmf and cdf, and use them to obtain probabilities of events.\\
\item
  Simulate random variable for a discrete distribution.\\
\item
  Find the moments of a discrete random variable.\\
\item
  Find the expected value of a linear transformation of a random variable.
\end{enumerate}

\hypertarget{homework-9}{%
\section{Homework}\label{homework-9}}

\hypertarget{problem-1-9}{%
\subsection{Problem 1}\label{problem-1-9}}

\indent 1. Suppose we are flipping a fair coin, and the result of a single coin flip is either heads or tails. Let \(X\) be a random variable representing the number of flips until the first heads.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Is \(X\) discrete or continuous? What is the domain/support of \(X\)?
\end{enumerate}

\(X\) is discrete since number of flips is a discrete process (I can't perform a fraction of a flip). The wording is specific in that it is the number of flips until the first heads, so we must flip at least once. The domain of \(X\) is \(S_X=\{1,2,...\}\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What values do you \emph{expect} \(X\) to take? What do you think is the average of \(X\)? Don't actually do any formal math, just think about if you were flipping a regular coin, how long it would take you to get the first heads.
\end{enumerate}

I would \emph{expect} \(X\) to be 1 or 2 fairly often, since the coin is fair and has an even chance of landing on heads or tails. I would expect large values of \(X\) to be rare. For these reasons, I think the average of \(X\) should be around 2 flips or a little less than 2.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Advanced: In \texttt{R}, generate 10,000 observations from \(X\). What is the average value of \(X\) based on this simulation?
\end{enumerate}

Note: There are many ways to do this. Below is a description of one approach.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{68}\NormalTok{)}
\KeywordTok{which}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"H"}\NormalTok{,}\StringTok{"T"}\NormalTok{),}\DecValTok{1000}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{)}\OperatorTok{==}\StringTok{"H"}\NormalTok{)[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

Now repeat using \texttt{replicate()} or \texttt{do()}. We will repeat 10000 times.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{which}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"H"}\NormalTok{,}\StringTok{"T"}\NormalTok{),}\DecValTok{1000}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{)}\OperatorTok{==}\StringTok{"H"}\NormalTok{)[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(}\OperatorTok{~}\NormalTok{result,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.9849
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{result,}\DataTypeTok{data=}\NormalTok{results,}\DataTypeTok{format=}\StringTok{"percent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## result
##     1     2     3     4     5     6     7     8     9    10    11    12    13 
## 49.89 25.35 12.33  6.56  3.25  1.27  0.66  0.39  0.12  0.07  0.06  0.03  0.02
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_props}\NormalTok{(}\OperatorTok{~}\NormalTok{result,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color =} \StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Number of flips"}\NormalTok{,}
          \DataTypeTok{subtitle=}\StringTok{"Number of flips until first heads"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{10-Random-Variables-Solutions_files/figure-latex/unnamed-chunk-5-1.pdf}

As predicted, the mean is close to 2, and the most common values of \(X\) are 1 and 2. The most common is 1 occurring 50\% of the time, this is what we would think since the coin comes up Heads 50\% of the time.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  We know that \(\mbox{P}(X=1) = \frac{1}{2}\) and \(\mbox{P}(X=2) = \frac{1}{2^2}\) so in general \(\mbox{P}(X=x) = \frac{1}{2^x}\). This is the pmf.
\end{enumerate}

As an extra, to show that the sum of the infinite sequence of probabilities is 1 requires some Calculus knowledge. Let's start with a partial sum:
\[S_n=\frac{1}{2}+\frac{1}{4} +\cdots + \frac{1}{2^n}\]
Now multiply both sides by \(\frac{1}{2}\).

\[\frac{1}{2}S_n=\frac{1}{4}+\frac{1}{8} +\cdots + \frac{1}{2^{n+1}}\]

The difference between these two sums is
\[S_n-\frac{1}{2}S_n=\frac{1}{2}S_n=\frac{1}{2}-\frac{1}{2^{n+1}}\]

Now as \[\lim_{n \to +\infty} \frac{1}{2^{n+1}} = 0\]

So \[\lim_{n \to +\infty} \left[ \frac{1}{2}S_n=\frac{1}{2}-\frac{1}{2^{n+1}} \right]\]

This implies that \(S = 1\).

\hypertarget{problem-2-9}{%
\subsection{Problem 2}\label{problem-2-9}}

\indent 2. Repeat Problem 1, except part d, but with a different random variable, \(Y\): the number of coin flips until the \emph{fifth} heads.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \(Y\) is discrete for the same reasons as \(X\). The domain of \(Y\) is \(S_Y=\{5,6,...\}\).
\item
  In order to land on heads five times, it would be reasonable to expect around 9 to 13 flips. Thus, I would expect \(Y\) to take values 8, 9, 10, 11, and 12 fairly often, and values outside of that range less often. I think the average of \(Y\) should be around 10 or so.
\item
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{102}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{which}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"H"}\NormalTok{,}\StringTok{"T"}\NormalTok{),}\DecValTok{1000}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{)}\OperatorTok{==}\StringTok{"H"}\NormalTok{)[}\DecValTok{5}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(}\OperatorTok{~}\NormalTok{result,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9.9728
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{result,}\DataTypeTok{data=}\NormalTok{results,}\DataTypeTok{format=}\StringTok{"percent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## result
##     5     6     7     8     9    10    11    12    13    14    15    16    17 
##  3.06  8.21 12.14 13.26 13.71 11.52 10.74  8.17  6.06  4.50  3.02  1.86  1.32 
##    18    19    20    21    22    23    24    25    28    29 
##  0.88  0.65  0.31  0.21  0.16  0.12  0.04  0.04  0.01  0.01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_props}\NormalTok{(}\OperatorTok{~}\NormalTok{result,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color =} \StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Number of flips"}\NormalTok{,}
          \DataTypeTok{subtitle=}\StringTok{"Number of flips until 5th heads"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{10-Random-Variables-Solutions_files/figure-latex/unnamed-chunk-9-1.pdf}

The most common values of \(Y\) are between 6 and 11. The average of \(Y\) in this simulation is 9.97, close to what we predicted.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  The pmf is not that bad but you must know about the binomial distribution first. If we get the fifth heads on the nth flip, the prior n-1 flips are a binomial with n-1 successes. The final flip is a success so we multiply the binomial by the probability of success.
\end{enumerate}

\hypertarget{problem-3-6}{%
\subsection{Problem 3}\label{problem-3-6}}

\indent 3. Suppose you are a data analyst for a large international airport. Your boss, the head of the airport, is dismayed that this airport has received negative attention in the press for inefficiencies and sluggishness. In a staff meeting, your boss gives you a week to build a report addressing the ``timeliness'' at the airport. Your boss is in a big hurry and gives you no further information or guidance on this task.

Prior to building the report, you will need to conduct some analysis. To aid you in this, create a list of at least three random variables that will help you address timeliness at the airport. For each of your random variables,

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Determine whether it is discrete or continuous.
\item
  Report its domain.
\item
  What is the experimental unit?
\item
  Explain how this random variable will be useful in addressing timeliness at the airport.
\end{enumerate}

I will provide one example:

Let \(D\) be the difference between a flight's actual departure and its scheduled departure. This is a continuous random variable, since time can be measured in fractions of minutes. A flight can be early or late, so domain is any real number. The experimental unit is each individual (non-canceled) flight. This is a useful random variable because the average value of \(D\) will describe whether flights take off on time. We could also find out how often \(D\) exceeds 0 (implying late departure) or how often \(D\) exceeds 30 minutes, which could indicate a ``very late'' departure.

There are many correct answers.

\(X\): Time it takes for a passenger to go through security (defined as time from entering security line to departing security with all belongings). Continuous. Experimental unit is individual passenger. This variable would help identify whether security line is too long. We could also explore how \(X\) changes based on day or time of day.

\(Y\): Status of each scheduled departure (on time, somewhat late, very late, canceled). Discrete. Experimental unit is each scheduled departure. This variable will help describe how often flights are canceled or late. We could also explore \(Y\) by airline, destination, time of day, etc.

\(Z\): Number of time-related complaints at customer service desk in a given day. Discrete. Experimental unit is day. This variable will describe attitudes/perceptions of customers. It is probably a bad sign if customers feel like the airport is not working efficiently. We can explore how \(Z\) changes over time.

\hypertarget{problem-4-3}{%
\subsection{Problem 4}\label{problem-4-3}}

\indent 4. Consider the experiment of rolling two fair six-sided dice. Let the random variable \(Y\) be the absolute difference between the two numbers that appear upon rolling the dice.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What is the domain/support of \(Y\)?
\end{enumerate}

\(S_Y=\{0,1,2,3,4,5\}\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What values do you \emph{expect} \(Y\) to take? What do you think is the average of \(Y\)? Don't actually do any formal math, just think about the experiment.
\end{enumerate}

I'd say that \(Y\) should take values 0,1 and 2 fairly often. I'd guess that the average should be around 1.5.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find the probability mass function and cumulative distribution function of \(Y\).
\end{enumerate}

Using counting methods, we know there are 36 possible values. We can just count them. The number 0 will occur when both numbers are the same, which happens six times. The number 1 happens when the first die is one larger than the second, 5 times, or vice versa. Thus 1 happens 10 times. Continue this process. Thus, the pmf of \(Y\) becomes:

\[
f_Y(y)=\left\{ \renewcommand{\arraystretch}{1.4} \begin{array}{ll} \frac{6}{36}, & y=0 \\
\frac{10}{36}, & y=1 \\
\frac{8}{36}, & y=2 \\
\frac{6}{36}, & y=3 \\
\frac{4}{36}, & y=4 \\
\frac{2}{36}, & y=5 \\
0, & \mbox{otherwise} \end{array} \right . 
\]
We could also create a table and count the entries.

\[
\begin{array}{cc|cccccc} & & & &\textbf{Die} & \textbf{2}
\\ & & 1 & 2 & 3 & 4 & 5 & 6  
\\&\hline 1 & 0 & 1 & 2 & 3 & 4 & 5 
\\\textbf{Die 1} & 2 & 1 & 0 & 1 & 2 &3 & 4  
\\& 3 & 2 & 1 & 0 & 1 & 2 & 3 
\\& 4 & 3 & 2 & 1 & 0 & 1 & 2
\\& 5 & 4 & 3 & 2 & 1 & 0 & 1
\\& 6 & 5 & 4 & 3 & 2 & 1 & 0
\end{array} 
\]

The cdf of \(Y\) is thus,
\[
F_Y(y)=\left\{\renewcommand{\arraystretch}{1.4}
\begin{array}{ll} 0, &  y < 0 \\
\frac{6}{36}, & 0\leq y <1 \\
\frac{16}{36}, & 1\leq y <2 \\
\frac{24}{36}, & 2 \leq y <3 \\
\frac{30}{36}, & 3 \leq y <4 \\
\frac{34}{36}, & 4 \leq y <5 \\
\frac{36}{36}, & y\geq 5 \end{array} \right .
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find the expected value and variance of \(Y\).
  \[
  \mbox{E}(Y)=\sum_{y=0}^5 y\mbox{P}(Y=y) = 0\times {6\over 36} + 1 \times {10\over 36} + 2\times {8\over 36} + 3\times {6\over 36} + 4 \times {4\over 36} + 5 \times {2\over 36} =
  \]
  \[
  {70\over 36} = 1.944
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y<-}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\NormalTok{mean_y<-}\KeywordTok{sum}\NormalTok{(y}\OperatorTok{*}\KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{36}\NormalTok{)}
\NormalTok{mean_y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.944444
\end{verbatim}

The variance is:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{((y}\OperatorTok{-}\NormalTok{mean_y)}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{36}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.052469
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Advanced: In \texttt{R}, obtain 10,000 realizations of \(Y\). In other words, simulate the roll of two fair dice, record the absolute difference and repeat this 10,000 times. Construct a frequency table of your results (what percentage of time did you get a difference of 0? difference of 1? etc.) Find the mean and variance of your simulated sample of \(Y\). Were they close to your answers in part d?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{9}\NormalTok{)}
\NormalTok{sim_diffs<-}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{abs}\NormalTok{(}\KeywordTok{diff}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DataTypeTok{replace=}\NormalTok{T)))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{abs,}\DataTypeTok{data=}\NormalTok{sim_diffs,}\DataTypeTok{format=}\StringTok{"proportion"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## abs
##      0      1      2      3      4      5 
## 0.1643 0.2752 0.2273 0.1618 0.1116 0.0598
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(}\OperatorTok{~}\NormalTok{abs,}\DataTypeTok{data=}\NormalTok{sim_diffs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.9606
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{(sim_diffs)}\OperatorTok{*}\DecValTok{9999}\OperatorTok{/}\DecValTok{10000}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          abs
## abs 2.077248
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{true_mean<-}\KeywordTok{sum}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{36}\OperatorTok{*}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\NormalTok{true_mean}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.944444
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\DecValTok{36}\OperatorTok{*}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)}\OperatorTok{-}\NormalTok{true_mean)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.052469
\end{verbatim}

We got similar mean and variance to the theoretical values.

\hypertarget{problem-5-2}{%
\subsection{Problem 5}\label{problem-5-2}}

\indent 5. Prove the Lemma from the Notes: Let \(X\) be a discrete random variable, and let \(a\) and \(b\) be constants. Show \(\mbox{E}(aX + b)=a\mbox{E}(X)+b\).\\
\[
\mbox{E}(aX+b)=\sum_x (ax+b)f_X(x) = \sum_x axf_X(x)+\sum_x bf_X(x) + a\sum_x xf_X(x)+b\sum_x f_X(x)
\]

Since \(\sum_x xf_X(x) = \mbox{E}(X)\) and \(\sum_x f_X(x)=1\), this reduces to \(a\mbox{E}(X)+b\).

\[
\mbox{Var}(aX+b)=\mbox{E}\left[(aX+b-\mbox{E}(aX+b))^2\right]=\mbox{E}\left[(aX+b-a\mbox{E}(X)-b)^2\right]=\mbox{E}\left[(aX-a\mbox{E}(X)^2\right]
\]
\[
=\mbox{E}\left[a^2(X-\mbox{E}(X))^2\right]=a^2\mbox{E}\left[(X-\mbox{E}(X))^2\right]=a^2\mbox{Var}(X)
\]

\hypertarget{problem-6-1}{%
\subsection{Problem 6}\label{problem-6-1}}

\indent 6. In the Notes, we saw that \(\mbox{Var}(X)=\mbox{E}[(X-\mu_X)^2]\). Show that \(\mbox{Var}(X)\) is also equal to \(\mbox{E}(X^2)-[\mbox{E}(X)]^2\).
\[
\mbox{Var}(X)=\mbox{E}[(X-\mu_X)^2]=\mbox{E}[X^2-2\mu_XX+\mu_X^2] = \mbox{E}(X^2)-\mbox{E}(2\mu_XX)+\mbox{E}(\mu_X^2)
\]

The quantity \(\mu_X\) is a constant with respect to \(X\), so
\[
=\mbox{E}(X^2)-2\mu_X\mbox{E}(X)+\mu_X^2=\mbox{E}(X^2)-2\mu_X^2+\mu_X^2 = \mbox{E}(X^2)-\mu_X^2
\]

\hypertarget{CONRANDVAR}{%
\chapter{Continuous Random Variables}\label{CONRANDVAR}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}

\hypertarget{objectives-10}{%
\section{Objectives}\label{objectives-10}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and properly use the new terms to include probability density function (pdf) and cumulative distribution function (cdf) for continuous random variables.\\
\item
  Given a continuous random variable, find probabilities using the pdf and/or the cdf.\\
\item
  Find the mean and variance of a continuous random variable.
\end{enumerate}

\hypertarget{homework-10}{%
\section{Homework}\label{homework-10}}

\hypertarget{problem-1-10}{%
\subsection{Problem 1}\label{problem-1-10}}

\indent 1. Let \(X\) be a continuous random variable on the domain \(-k \leq X \leq k\). Also, let \(f(x)=\frac{x^2}{18}\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Assume that \(f(x)\) is a valid pdf. Find the value of \(k\).
\end{enumerate}

Because \(f\) is a valid pdf, we know that \(\int_{-k}^k \frac{x^2}{18}\mathop{}\!\mathrm{d}x = 1\). So,
\[
\int_{-k}^k \frac{x^2}{18}\mathop{}\!\mathrm{d}x = \frac{x^3}{54}\bigg|_{-k}^k = \frac{k^3}{54}-\frac{-k^3}{54}=\frac{k^3}{27}=1
\]

Thus, \(k=3\).

Using \texttt{R}, see if you can follow the code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pdf <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)}\KeywordTok{integrate}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(y)y}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\DecValTok{18}\NormalTok{,}\OperatorTok{-}\NormalTok{x,x)}\OperatorTok{$}\NormalTok{value}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_pdf<-}\KeywordTok{Vectorize}\NormalTok{(my_pdf)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{domain <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(.}\DecValTok{01}\NormalTok{,}\DecValTok{5}\NormalTok{,.}\DecValTok{1}\NormalTok{)}
\KeywordTok{gf_line}\NormalTok{(}\KeywordTok{my_pdf}\NormalTok{(domain)}\OperatorTok{~}\NormalTok{domain) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Cumulative probability for different values of k"}\NormalTok{,}\DataTypeTok{x=}\StringTok{"k"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Cummulative Probability"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{1}\NormalTok{,}\DataTypeTok{color =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{11-Continuous-Random-Variable-Solutions_files/figure-latex/unnamed-chunk-3-1.pdf}

Looks like \(k \approx 3\) from the plot.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{uniroot}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)}\KeywordTok{my_pdf}\NormalTok{(x)}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{))}\OperatorTok{$}\NormalTok{root}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.999997
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Plot the pdf of \(X\).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x<-}\KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{,}\FloatTok{0.001}\NormalTok{)}
\NormalTok{fx<-x}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\DecValTok{18}
\KeywordTok{gf_line}\NormalTok{(fx}\OperatorTok{~}\NormalTok{x,}\DataTypeTok{ylab=}\StringTok{"f(x)"}\NormalTok{,}\DataTypeTok{title=}\StringTok{"pdf of X"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{11-Continuous-Random-Variable-Solutions_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)), }\KeywordTok{aes}\NormalTok{(x)) }\OperatorTok{+}\StringTok{ }
\StringTok{ }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun=}\ControlFlowTok{function}\NormalTok{(x) x}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\DecValTok{18}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_classic}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{y=}\StringTok{"f(x)"}\NormalTok{,}\DataTypeTok{title=}\StringTok{"pdf of X"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{11-Continuous-Random-Variable-Solutions_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{curve}\NormalTok{(x}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\DecValTok{18}\NormalTok{,}\DataTypeTok{from=}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\DataTypeTok{to=}\DecValTok{3}\NormalTok{,}\DataTypeTok{ylab=}\StringTok{"f(x)"}\NormalTok{,}\DataTypeTok{main=}\StringTok{"pdf of X"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{11-Continuous-Random-Variable-Solutions_files/figure-latex/hw9a-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find and plot the cdf of \(X\).
  \[
  F_X(x)=\mbox{P}(X\leq x)=\int_{-3}^x \frac{t^2}{18}\mathop{}\!\mathrm{d}t = \frac{t^3}{54}\bigg|_{-3}^x = \frac{x^3}{54}+\frac{1}{2}
  \]
\end{enumerate}

\[
F_X(x)=\left\{\begin{array}{ll} 0, & x<-3 \\ \frac{x^3}{54}+\frac{1}{2}, & -3\leq x \leq 3 \\ 1, & x>3 \end{array}\right.
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x<-}\KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\FloatTok{3.5}\NormalTok{,}\FloatTok{3.5}\NormalTok{,}\FloatTok{0.001}\NormalTok{)}
\NormalTok{fx<-}\KeywordTok{pmin}\NormalTok{(}\DecValTok{1}\NormalTok{,(}\DecValTok{1}\OperatorTok{*}\NormalTok{(x}\OperatorTok{>=-}\DecValTok{3}\NormalTok{)}\OperatorTok{*}\NormalTok{(x}\OperatorTok{^}\DecValTok{3}\OperatorTok{/}\DecValTok{54}\OperatorTok{+}\DecValTok{1}\OperatorTok{/}\DecValTok{2}\NormalTok{)))}
\KeywordTok{gf_line}\NormalTok{(fx}\OperatorTok{~}\NormalTok{x,}\DataTypeTok{ylab=}\StringTok{"F(x)"}\NormalTok{,}\DataTypeTok{title=}\StringTok{"cdf of X"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{11-Continuous-Random-Variable-Solutions_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find \(\mbox{P}(X<1)\).
  \[
  \mbox{P}(X<1)=F(1)=\frac{1}{54}+\frac{1}{2}=0.519
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{integrate}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)x}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\DecValTok{18}\NormalTok{,}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 0.5185185 with absolute error < 5.8e-15
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Find \(\mbox{P}(1.5<X\leq 2.5)\).
  \[
  \mbox{P}(1.5< X \leq 2.5)=F(2.5)-F(1.5)=\frac{2.5^3}{54}+\frac{1}{2}-\frac{1.5^3}{54}-\frac{1}{2}=0.227
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{integrate}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)x}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\DecValTok{18}\NormalTok{,}\FloatTok{1.5}\NormalTok{,}\FloatTok{2.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 0.2268519 with absolute error < 2.5e-15
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Find the 80th percentile of \(X\) (the value \(x\) for which 80\% of the distribution is to the left of that value).
\end{enumerate}

Need \(x\) such that \(F(x)=0.8\). Solving \(\frac{x^3}{54}+\frac{1}{2}=0.8\) for \(x\) yields \(x=2.530\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{uniroot}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)x}\OperatorTok{^}\DecValTok{3}\OperatorTok{/}\DecValTok{54}\FloatTok{+.5-.8}\NormalTok{,}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $root
## [1] 2.530293
## 
## $f.root
## [1] -1.854422e-06
## 
## $iter
## [1] 6
## 
## $init.it
## [1] NA
## 
## $estim.prec
## [1] 6.103516e-05
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Find the value \(x\) such that \(\mbox{P}(-x \leq X \leq x)=0.4\).
\end{enumerate}

Because this distribution is symmetric, finding \(x\) is equivalent to finding \(x\) such that \(\mbox{P}(X>x)=0.3\). (It helps to draw a picture). Thus, we need \(x\) such that \(F(x)=0.7\). Solving \(\frac{x^3}{54}+\frac{1}{2}=0.7\) for \(x\) yields \(x=2.210\).

\includegraphics{11-Continuous-Random-Variable-Solutions_files/figure-latex/unnamed-chunk-11-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Find the mean and variance of \(X\).
  \[
  \mbox{E}(X)=\int_{-3}^3 x\cdot\frac{x^2}{18}\mathop{}\!\mathrm{d}x = \frac{x^4}{72}\bigg|_{-3}^3=\frac{81}{72}-\frac{81}{72} = 0
  \]
\end{enumerate}

\[
\mbox{E}(X^2)=\int_{-3}^3 x^2\cdot\frac{x^2}{18}\mathop{}\!\mathrm{d}x = \frac{x^5}{90}\bigg|_{-3}^3=\frac{243}{90}-\frac{-243}{90} = 5.4
\]

\[
\mbox{Var}(X)=\mbox{E}(X^2)-\mbox{E}(X)^2=5.4-0^2=5.4
\]

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  Simulate 10000 values from this distribution and plot the density.
\end{enumerate}

This is tricky since we need a cube root function. Just raising to the one-third power won't work. Let's write our own function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cuberoot <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
  \KeywordTok{sign}\NormalTok{(x) }\OperatorTok{*}\StringTok{ }\KeywordTok{abs}\NormalTok{(x)}\OperatorTok{^}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{)\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{4}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{cuberoot}\NormalTok{((}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{)}\OperatorTok{-}\NormalTok{.}\DecValTok{5}\NormalTok{)}\OperatorTok{*}\DecValTok{54}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_dens}\NormalTok{(}\OperatorTok{~}\NormalTok{cuberoot) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"pdf from simulation"}\NormalTok{,}\DataTypeTok{x=}\StringTok{"x"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"f(x)"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\includegraphics{11-Continuous-Random-Variable-Solutions_files/figure-latex/unnamed-chunk-14-1.pdf}

Notice that the smoothing operation goes past the support of \(X\) and thus shows a concave down curve. We could clean up by limiting the x-axis to the interval {[}-3,3{]}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## quantitative variables:  
##          name   class       min        Q1     median       Q3      max
## ...1 cuberoot numeric -2.999981 -2.382864 -0.1574198 2.376346 2.999347
##              mean       sd     n missing
## ...1 -0.002416475 2.322639 10000       0
\end{verbatim}

\newpage

\hypertarget{problem-2-10}{%
\subsection{Problem 2}\label{problem-2-10}}

\indent 2. Let \(X\) be a continuous random variable. Prove that the cdf of \(X\), \(F_X(x)\) is a non-decreasing function. (Hint: show that for any \(a < b\), \(F_X(a) \leq F_X(b)\).)

Let \(a<b\), where \(a\) and \(b\) are both in the domain of \(X\). Note that \(F_X(a)=\mbox{P}(X\leq a)\) and \(F_X(b)=\mbox{P}(X\leq b)\). Since \(a<b\), we can partition \(\mbox{P}(X\leq b)\) as \(\mbox{P}(X\leq a)+\mbox{P}(a < X \leq b)\). One of the axioms of probability is that a probability must be non-negative, so I know that \(\mbox{P}(a < X \leq b)\geq 0\). Thus,
\[
\mbox{P}(X\leq b)=\mbox{P}(X\leq a)+\mbox{P}(a < X \leq b) \geq \mbox{P}(X\leq a)
\]

So, we have shown that \(F_X(a)\leq F_X(b)\). Thus, \(F_X(x)\) is a non-decreasing function.

\hypertarget{DISCRETENAMED}{%
\chapter{Named Discrete Distributions}\label{DISCRETENAMED}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}

\hypertarget{objectives-11}{%
\section{Objectives}\label{objectives-11}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Recognize and setup for use common discrete distributions (Uniform, Binomial, Poisson, Hypergeometric) to include parameters, assumptions, and moments.\\
\item
  Use \texttt{R} to calculate probabilities and quantiles involving random variables with common discrete distributions.
\end{enumerate}

\hypertarget{homework-11}{%
\section{Homework}\label{homework-11}}

For each of the problems below, \textbf{\emph{1)}} define a random variable that will help you answer the question, \textbf{\emph{2)}} state the distribution and parameters of that random variable; \textbf{\emph{3)}} determine the expected value and variance of that random variable, and \textbf{\emph{4)}} use that random variable to answer the question.

We will demonstrate using 1a and 1b.

\hypertarget{problem-1-11}{%
\subsection{Problem 1}\label{problem-1-11}}

\indent 1. The T-6 training aircraft is used during UPT. Suppose that on each training sortie, aircraft return with a maintenance-related failure at a rate of 1 per 100 sorties.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find the probability of no maintenance failures in 15 sorties.
\end{enumerate}

\(X\): the number of maintenance failures in 15 sorties.

\(X\sim \textsf{Bin}(n=15,p=0.01)\)

\(\mbox{E}(X)=15*0.01=0.15\) and \(\mbox{Var}(X)=15*0.01*0.99=0.1485\).

\(\mbox{P}(\mbox{No maintenance failures})=\mbox{P}(X=0)={15\choose 0}0.01^0(1-0.01)^{15}=0.99^{15}\)

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.99}\OperatorTok{^}\DecValTok{15}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8600584
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## or }
\KeywordTok{dbinom}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{15}\NormalTok{,}\FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8600584
\end{verbatim}

This probability makes sense, since the expected value is fairly low. Because, on average, only 0.15 failures would occur every 15 trials, 0 failures would be a very common result. Graphically, the pmf looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"binom"}\NormalTok{,}\DataTypeTok{size=}\DecValTok{15}\NormalTok{,}\DataTypeTok{prob=}\FloatTok{0.01}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{12-Named-Discrete-Distributions-Solutions_files/figure-latex/hw8b-1} \end{center}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the probability of at least two maintenance failures in 15 sorties.
\end{enumerate}

We can use the same \(X\) as above. Now, we are looking for \(\mbox{P}(X\geq 2)\). This is equivalent to finding \(1-\mbox{P}(X\leq 1)\):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Directly}
\DecValTok{1}\OperatorTok{-}\NormalTok{(}\FloatTok{0.99}\OperatorTok{^}\DecValTok{15} \OperatorTok{+}\StringTok{ }\DecValTok{15}\OperatorTok{*}\FloatTok{0.01}\OperatorTok{*}\FloatTok{0.99}\OperatorTok{^}\DecValTok{14}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.009629773
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## or, using R}
\KeywordTok{sum}\NormalTok{(}\KeywordTok{dbinom}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{15}\NormalTok{,}\DecValTok{15}\NormalTok{,}\FloatTok{0.01}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.009629773
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## or}
\DecValTok{1}\OperatorTok{-}\KeywordTok{sum}\NormalTok{(}\KeywordTok{dbinom}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{1}\NormalTok{,}\DecValTok{15}\NormalTok{,}\FloatTok{0.01}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.009629773
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## or}
\DecValTok{1}\OperatorTok{-}\KeywordTok{pbinom}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{15}\NormalTok{,}\FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.009629773
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## or }
\KeywordTok{pbinom}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{15}\NormalTok{,}\FloatTok{0.01}\NormalTok{,}\DataTypeTok{lower.tail =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.009629773
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find the probability of at least 30 successful (no mx failures) sorties before the first failure.
\end{enumerate}

\(X\): the number of maintenance failures out of 30 sorties.

\(X\sim \textsf{Binom}(n=30,p=0.01)\), and \(\mbox{E}(X)=0.3\) and \(\mbox{Var}(X)=0.297\).

\(\mbox{P}(\mbox{0 failures})=\mbox{P}(X=0)=0.99^{30}\)

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.99}\OperatorTok{^}\DecValTok{30}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7397004
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{##or }
\KeywordTok{dbinom}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{30}\NormalTok{,}\FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7397004
\end{verbatim}

Using negative binomial, which was not in the reading but you can research:

\(Y\): the number of successful sorties before the first failure.

\(Y\sim \textsf{NegBin}(n=1,p=0.01)\), and \(\mbox{E}(X)=99\) and \(\mbox{Var}(X)=9900\).

\(\mbox{P}(\mbox{at least 30 successes before first failure})=\mbox{P}(Y\geq 30)\)

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pnbinom}\NormalTok{(}\DecValTok{29}\NormalTok{,}\DecValTok{1}\NormalTok{,}\FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.7397004
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find the probability of at least 50 successful sorties before the third failure.
\end{enumerate}

Using a binomial random variable, we have 52 trials and need at least 50 to be a success. The random variable is \(X\) the number of successful sorties out of 52.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pbinom}\NormalTok{(}\DecValTok{49}\NormalTok{,}\DecValTok{52}\NormalTok{,.}\DecValTok{99}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9846474
\end{verbatim}

Or using a negative binomial, let

\(Y\): the number of successful sorties before the third failure.

\(Y\sim \textsf{NegBin}(n=3,p=0.01)\), and \(\mbox{E}(X)=297\) and \(\mbox{Var}(X)=29700\).

\(\mbox{P}(\mbox{at least 50 successes before 3rd failure})=\mbox{P}(Y\geq 50)\)

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pnbinom}\NormalTok{(}\DecValTok{49}\NormalTok{,}\DecValTok{3}\NormalTok{,}\FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9846474
\end{verbatim}

Notice if the question had been exactly 50 successful sorties before the 3 failure, that is a different question. Then we could use either:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dbinom}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{52}\NormalTok{,.}\DecValTok{99}\NormalTok{)}\OperatorTok{*}\NormalTok{.}\DecValTok{01}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.000802238
\end{verbatim}

The \(0.01\) is because the last trial is a failure.

Or

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dnbinom}\NormalTok{(}\DecValTok{50}\NormalTok{,}\DecValTok{3}\NormalTok{,}\FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.000802238
\end{verbatim}

\newpage

\hypertarget{problem-2-11}{%
\subsection{Problem 2}\label{problem-2-11}}

\indent 2. On a given Saturday, suppose vehicles arrive at the USAFA North Gate according to a Poisson process at a rate of 40 arrivals per hour.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find the probability no vehicles arrive in 10 minutes.
\end{enumerate}

\(X\): number of vehicles that arrive in 10 minutes

\(X\sim \textsf{Pois}(\lambda=40/6=6.67)\) and \(\mbox{E}(X)=\mbox{Var}(X)=6.67\).

\(\mbox{P}(\mbox{no arrivals in 10 minutes})=\mbox{P}(X=0)=\frac{6.67^0 e^{-6.67}}{0!}=e^{-6.67}\)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\DecValTok{40}\OperatorTok{/}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001272634
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{##or}
\KeywordTok{dpois}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{40}\OperatorTok{/}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001272634
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the probability at least 50 vehicles arrive in an hour.
\end{enumerate}

\(X\): number of vehicles that arrive in an hour

\(X\sim \textsf{Pois}(\lambda=40)\) and \(\mbox{E}(X)=\mbox{Var}(X)=40\).

\(\mbox{P}(\mbox{at least 50 arrivals in 1 hour})=\mbox{P}(X\geq 50)\)

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{ppois}\NormalTok{(}\DecValTok{49}\NormalTok{,}\DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.07033507
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find the probability that at least 5 minutes will pass before the next arrival.
\end{enumerate}

\(X\): number of vehicles that arrive in 5 minutes

\(X\sim \textsf{Pois}(\lambda=40/12=3.33)\) and \(\mbox{E}(X)=\mbox{Var}(X)=3.33\).

\(\mbox{P}(\mbox{no arrivals in 5 minutes})=\mbox{P}(X=0)=\frac{3.33^0 e^{-3.33}}{0!}=e^{-3.33}\)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\DecValTok{40}\OperatorTok{/}\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.03567399
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{##or}
\KeywordTok{dpois}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{40}\OperatorTok{/}\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.03567399
\end{verbatim}

\newpage

\hypertarget{problem-3-7}{%
\subsection{Problem 3}\label{problem-3-7}}

\indent 3. Suppose there are 12 male and 7 female cadets in a classroom. I select 5 completely at random (without replacement).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find the probability I select no female cadets.
\end{enumerate}

\(X\): number of female cadets selected out of sample of size 5

\(X\sim \textsf{Hypergeom}(m=7,n=12,k=5)\) and \(\mbox{E}(X)=1.842\) and \(\mbox{Var}(X)=0.905\).

\[
\mbox{P}(\mbox{no female cadets selected})=\mbox{P}(X=0)=\frac{{7\choose 0}{12\choose 5}}{{19\choose 5}}
\]

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{choose}\NormalTok{(}\DecValTok{12}\NormalTok{,}\DecValTok{5}\NormalTok{)}\OperatorTok{/}\KeywordTok{choose}\NormalTok{(}\DecValTok{19}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.06811146
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{##or}
\KeywordTok{dhyper}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{12}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.06811146
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the probability I select more than 2 female cadets.
\end{enumerate}

Using the same random variable:
\[
\mbox{P}(\mbox{more than 2 female})=\mbox{P}(X>2)=1-\mbox{P}(X\leq 2)
\]

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{phyper}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{12}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2365841
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{##or}
\KeywordTok{sum}\NormalTok{(}\KeywordTok{dhyper}\NormalTok{(}\DecValTok{3}\OperatorTok{:}\DecValTok{5}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{12}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2365841
\end{verbatim}

\hypertarget{CONTNNAMED}{%
\chapter{Named Continuous Distributions}\label{CONTNNAMED}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand{\diff}{\,\mathrm{d}}

\hypertarget{objectives-12}{%
\section{Objectives}\label{objectives-12}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Recognize when to use common continuous distributions (Uniform, Exponential, Gamma, Normal, Beta), identify parameters, and find moments.\\
\item
  Use \texttt{R} to calculate probabilities and quantiles involving random variables with common continuous distributions.\\
\item
  Understand the relationship between the Poisson process and the Poisson \& Exponential distributions.\\
\item
  Know when to apply and then use the memoryless property.
\end{enumerate}

\hypertarget{homework-12}{%
\section{Homework}\label{homework-12}}

For problems 1-3 below, \textbf{\emph{1)}} define a random variable that will help you answer the question, \textbf{\emph{2)}} state the distribution and parameters of that random variable; \textbf{\emph{3)}} determine the expected value and variance of that random variable, and \textbf{\emph{4)}} use that random variable to answer the question.

\hypertarget{problem-1-12}{%
\subsection{Problem 1}\label{problem-1-12}}

\indent 1. On a given Saturday, suppose vehicles arrive at the USAFA North Gate according to a Poisson process at a rate of 40 arrivals per hour.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find the probability no vehicles arrive in 10 minutes.
\end{enumerate}

\(X\): number of vehicles that arrive in 10 minutes

\(X\sim \textsf{Pois}(\lambda=40/6=6.67)\) and \(\mbox{E}(X)=\mbox{Var}(X)=6.67\).

\(\mbox{P}(\mbox{no arrivals in 10 minutes})=\mbox{P}(X=0)=\frac{6.67^0 e^{-6.67}}{0!}=e^{-6.67}\)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\DecValTok{40}\OperatorTok{/}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001272634
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{##or}
\KeywordTok{dpois}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{40}\OperatorTok{/}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001272634
\end{verbatim}

or, using the exponential distribution:

\(Y\): time in minutes until the next arrival

\(Y\sim \textsf{Expon}(\lambda=40/60=0.667)\) and \(\mbox{E}(Y)=1.5\) and \(\mbox{Var}(Y)=2.25\).

\[
\mbox{P}(\mbox{at least 10 minutes until the next arrival})=\mbox{P}(Y\geq 10)=\int_{10}^\infty \frac{2}{3}e^{-\frac{2}{3}y}\,\mathrm{d}y
\]

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pexp}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001272634
\end{verbatim}

or using simulation:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{616}\NormalTok{)}
\KeywordTok{mean}\NormalTok{(}\KeywordTok{rpois}\NormalTok{(}\DecValTok{100000}\NormalTok{,}\DecValTok{40}\OperatorTok{/}\DecValTok{6}\NormalTok{) }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.00126
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(}\KeywordTok{rexp}\NormalTok{(}\DecValTok{100000}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{) }\OperatorTok{>=}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.00127
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the probability that at least 5 minutes will pass before the next arrival.
\end{enumerate}

\(Y\): same as in part a

\[
\mbox{P}(\mbox{at least 5 minutes until next arrival})=\mbox{P}(Y\geq 5)=\int_{5}^\infty \frac{2}{3}e^{-\frac{2}{3}y}\,\mathrm{d}y
\]

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pexp}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.03567399
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find the probability that the next vehicle will arrive between 2 and 10 minutes from now.
\end{enumerate}

Same \(Y\) as defined above.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pexp}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{)}\OperatorTok{-}\KeywordTok{pexp}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2623245
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find the probability that at least 7 minutes will pass before the next arrival, given that 2 minutes have already passed. Compare this answer to part (b). This is an example of the memoryless property of the exponential distribution.
  \[
  \mbox{P}(Y\geq 7|Y\geq 2) = \frac{\mbox{P}(Y\geq 7, Y\geq 2)}{\mbox{P}(Y\geq 2)} = \frac{\mbox{P}(Y\geq 7)}{\mbox{P}(Y\geq 2)}
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pexp}\NormalTok{(}\DecValTok{7}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{))}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pexp}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.03567399
\end{verbatim}

This is the same answer and a result of the memoryless property.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Fill in the blank. There is a probability of 90\% that the next vehicle will arrive within \_\_ minutes. This value is known as the 90\% percentile of the random variable.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qexp}\NormalTok{(}\FloatTok{0.9}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.453878
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Use the function \texttt{stripplot()} to visualize the arrival of 30 vehicles using a random sample from the appropriate exponential distribution.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{202}\NormalTok{)}
\KeywordTok{stripplot}\NormalTok{(}\KeywordTok{cumsum}\NormalTok{(}\KeywordTok{rexp}\NormalTok{(}\DecValTok{30}\NormalTok{,}\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{)),}\DataTypeTok{xlab=}\StringTok{"Arrival Time"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{13-Named-Continuous-Distributions-Solutions_files/figure-latex/unnamed-chunk-4-1.pdf}

\newpage

\hypertarget{problem-2-12}{%
\subsection{Problem 2}\label{problem-2-12}}

\indent 2. Suppose time until computer errors on the F-35 follows a Gamma distribution with mean 20 hours and variance 10.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find the probability that 20 hours pass without a computer error.
\end{enumerate}

\(X\): time in hours until next computer error.

\(X\sim \textsf{Gamma}(\alpha = 40, \lambda = 2)\)

We need to find \(\alpha\) and \(\lambda\) from the given moments.

\(\mbox{E}(X) = 20 = \frac{\alpha}{\lambda}\)

\(\mbox{Var}(X) = 10 = \frac{\alpha}{\lambda^2}\)

Notice that \(\frac{\mbox{E}(X)}{\mbox{Var}(X)} = \lambda = \frac{20}{10}=2\) and then using \(\mbox{E}(X) = 20 = \frac{\alpha}{\lambda}\) we get \(\alpha = 40\).

\(\mbox{P}(X\geq 20)\):

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pgamma}\NormalTok{(}\DecValTok{20}\NormalTok{,}\DataTypeTok{shape=}\DecValTok{40}\NormalTok{,}\DataTypeTok{rate=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4789711
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the probability that 45 hours pass without a computer error, given that 25 hours have already passed. Does the memoryless property apply to the Gamma distribution?
  \[
  P(X\geq 45|X\geq 25) = \frac{P(X\geq 45, X\geq 25)}{P(X\geq 25)} = \frac{P(X\geq 45)}{P(X\geq 25)}
  \]
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pgamma}\NormalTok{(}\DecValTok{45}\NormalTok{,}\DecValTok{40}\NormalTok{,}\DecValTok{2}\NormalTok{))}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pgamma}\NormalTok{(}\DecValTok{25}\NormalTok{,}\DecValTok{40}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.77803e-08
\end{verbatim}

No, the memoryless property does not apply to the Gamma distribution.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find \(a\) and \(b\) where there is a 95\% probability that the time until next computer error will be between \(a\) and \(b\). (Note: technically, there are many answers to this question, but find \(a\) and \(b\) such that each tail has equal probability.)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qgamma}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{,}\FloatTok{0.975}\NormalTok{),}\DecValTok{40}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 14.28829 26.65714
\end{verbatim}

So in the time interval \([14,29,26.66]\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qgamma}\NormalTok{(.}\DecValTok{95}\NormalTok{,}\DecValTok{40}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 25.46987
\end{verbatim}

Another answer is between \([0,25,47]\).

\newpage

\hypertarget{problem-3-8}{%
\subsection{Problem 3}\label{problem-3-8}}

\indent 3. Suppose PFT scores in the cadet wing follow a normal distribution with mean 330 and standard deviation 50.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find the probability a randomly selected cadet has a PFT score higher than 450.
\end{enumerate}

\(X\): PFT score of a randomly selected cadet

\(X\sim \textsf{Norm}(\mu=330,\sigma=50)\)

\(\mbox{E}(X) = 330\) and \(\mbox{Var}(X)=50^2=2500\).

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pnorm}\NormalTok{(}\DecValTok{450}\NormalTok{,}\DecValTok{330}\NormalTok{,}\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.008197536
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the probability a randomly selected cadet has a PFT score within 2 standard deviations of the mean.
\end{enumerate}

Need \(\mbox{P}(230 \leq X \leq 430)\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pnorm}\NormalTok{(}\DecValTok{430}\NormalTok{,}\DecValTok{330}\NormalTok{,}\DecValTok{50}\NormalTok{)}\OperatorTok{-}\KeywordTok{pnorm}\NormalTok{(}\DecValTok{230}\NormalTok{,}\DecValTok{330}\NormalTok{,}\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9544997
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find \(a\) and \(b\) such that 90\% of PFT scores will be between \(a\) and \(b\).
\end{enumerate}

Need \(a\) such that \(\mbox{P}(X\leq a)=0.05\) and \(b\) such that \(\mbox{P}(X\geq b)=0.05\):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.05}\NormalTok{,}\DecValTok{330}\NormalTok{,}\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 247.7573
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.95}\NormalTok{,}\DecValTok{330}\NormalTok{,}\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 412.2427
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find the probability a randomly selected cadet has a PFT score higher than 450 given he/she is among the top 10\% of cadets.
\end{enumerate}

Need \(\mbox{P}(X>450|X>x_{0.9})\) where \(x_{0.9}\) is the 90th percentile of \(X\).

The 90th percentile is:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.9}\NormalTok{,}\DecValTok{330}\NormalTok{,}\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 394.0776
\end{verbatim}

\[
\mbox{P}(X>450|X>x_{0.9})=\frac{\mbox{P}(X>450, X>x_{0.9})}{\mbox{P}(X>x_{0.9})}=\frac{\mbox{P}(X>450, X>394.08)}{\mbox{P}(X>x_{0.9})}=\frac{\mbox{P}(X>450)}{0.1}
\]

This is assuming that \(x_{0.9}<450\). Otherwise the problem is trivial and the probability is 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pnorm}\NormalTok{(}\DecValTok{450}\NormalTok{,}\DecValTok{330}\NormalTok{,}\DecValTok{50}\NormalTok{))}\OperatorTok{/}\FloatTok{0.1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.08197536
\end{verbatim}

\newpage

\hypertarget{problem-4-4}{%
\subsection{Problem 4}\label{problem-4-4}}

\indent 4. Let \(X \sim \textsf{Beta}(\alpha=1,\beta=1)\). Show that \(X\sim \textsf{Unif}(0,1)\). Hint: write out the beta distribution pdf where \(\alpha=1\) and \(\beta=1\).

The beta pdf is:
\[
f_X(x)=\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}
\]

When \(X\sim\textsf{Beta}(\alpha=1,\beta=1)\), this becomes:
\[
f_X(x)=\frac{\Gamma(2)}{\Gamma(1)\Gamma(1)}x^{1-1}(1-x)^{1-1} = 1
\]

\hypertarget{problem-5-3}{%
\subsection{Problem 5}\label{problem-5-3}}

\indent 5. When using \texttt{R} to calculate probabilities related to the gamma distribution, we often use \texttt{pgamma}. Recall that \texttt{pgamma} is equivalent to the cdf of the gamma distribution. If \(X\sim\textsf{Gamma}(\alpha,\lambda)\), then
\[
\mbox{P}(X\leq x)=\textsf{pgamma(x,alpha,lambda)}
\]

The \texttt{dgamma} function exists in \texttt{R} too. In plain language, explain what \texttt{dgamma} returns. I'm not looking for the definition found in \texttt{R} documentation. I'm looking for a simple description of what that function returns. Is the output of \texttt{dgamma} useful? If so, how?

The \texttt{dgamma} function returns the value of probability density function. While this is not a probability, it is still a useful quantity. It can be said that larger densities (\(f(x)\)) imply that values near \(x\) are more likely to occur than values associated with smaller densities. It is also useful when computing conditional probability distributions.

\newpage

\hypertarget{problem-6-2}{%
\subsection{Problem 6}\label{problem-6-2}}

\indent 6. Advanced. You may have heard of the 68-95-99.7 rule. This is a helpful rule of thumb that says if a population has a normal distribution, then 68\% of the data will be within one standard deviation of the mean, 95\% of the data will be within two standard deviations and 99.7\% of the data will be within three standard deviations. Create a function in \texttt{R} that has two inputs (a mean and a standard deviation). It should return a vector with three elements: the probability that a randomly selected observation from the normal distribution with the inputted mean and standard deviation lies within one, two and three standard deviations. Test this function with several values of mu and sd. You should get the same answer each time.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rulethumb<-}\ControlFlowTok{function}\NormalTok{(mu,sd)\{}
  \KeywordTok{pnorm}\NormalTok{(mu}\OperatorTok{+}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)}\OperatorTok{*}\NormalTok{sd,mu,sd)}\OperatorTok{-}\KeywordTok{pnorm}\NormalTok{(mu}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{)}\OperatorTok{*}\NormalTok{sd,mu,sd)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rulethumb}\NormalTok{(}\DecValTok{15}\NormalTok{,}\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6826895 0.9544997 0.9973002
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rulethumb}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6826895 0.9544997 0.9973002
\end{verbatim}

\hypertarget{problem-7-1}{%
\subsection{Problem 7}\label{problem-7-1}}

\indent 7. Derive the mean of a general uniform distribution, \(U(a,b)\).

From the definition

\[E(X)=\int_{a}^{b}xf(x)dx=\]
\[ =\int_{a}^{b}\frac{x}{b-a}dx =\]

\[ =\frac{1}{b-a}\int_{a}^{b}xdx = \frac{1}{b-a}\cdot\frac{x^2}{2}\bigg|_{a}^{b}=\]

\[ =\frac{1}{b-a}\cdot\frac{b^2-a^2}{2}= \frac{1}{b-a}\cdot\frac{(b-a)(b+a)}{2}=\frac{(b+a)}{2}\]

\hypertarget{MULTIDISTS}{%
\chapter{Multivariate Distributions}\label{MULTIDISTS}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand{\diff}{\,\mathrm{d}}

\hypertarget{objectives-13}{%
\section{Objectives}\label{objectives-13}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define (and distinguish between) the terms joint probability mass/density function, marginal pmf/pdf, and conditional pmf/pdf.\\
\item
  Given a joint pmf/pdf, obtain the marginal and conditional pmfs/pdfs.\\
\item
  Use joint, marginal and conditional pmfs/pdfs to obtain probabilities.
\end{enumerate}

\hypertarget{homework-13}{%
\section{Homework}\label{homework-13}}

\hypertarget{problem-1-13}{%
\subsection{Problem 1}\label{problem-1-13}}

\indent 1. Let \(X\) and \(Y\) be continuous random variables with joint pmf:
\[
f_{X,Y}(x,y)=x + y
\]

where \(0 \leq x \leq 1\) and \(0 \leq y \leq 1\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Verify that \(f\) is a valid pdf.
  \[
  \int_0^1\int_0^1 x+y\,\mathrm{d}y \,\mathrm{d}x = \int_0^1 xy + \frac{y^2}{2}\bigg|_0^1 \,\mathrm{d}x = \int_0^1 x+\frac{1}{2}\,\mathrm{d}x = \frac{x^2}{2}+\frac{x}{2}\bigg|_0^1=1
  \]
\end{enumerate}

Or

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(cubature) }\CommentTok{# load the package "cubature"}
\NormalTok{f <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{ (x[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\NormalTok{x[}\DecValTok{2}\NormalTok{]) \} }\CommentTok{# "x" is vector}
\KeywordTok{adaptIntegrate}\NormalTok{(f, }\DataTypeTok{lowerLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DataTypeTok{upperLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $integral
## [1] 1
## 
## $error
## [1] 0
## 
## $functionEvaluations
## [1] 17
## 
## $returnCode
## [1] 0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the marginal pdfs of \(X\) and \(Y\).
  \[
  f_X(x)=\int_0^1 x+y\,\mathrm{d}y = xy + \frac{y^2}{2}\bigg|_0^1 =  x+\frac{1}{2}
  \]
  where \(0\leq x \leq 1\).
\end{enumerate}

Similarly, \(f_Y(y)=y+\frac{1}{2}\) for \(0 \leq y \leq 1\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find the conditional pdfs of \(X|Y=y\) and \(Y|X=x\).
  \[
  f_{X|Y=y}(x)=\frac{x+y}{y+\frac{1}{2}}
  \]
  where \(0\leq x \leq 1\).
\end{enumerate}

Similarly, \(f_{Y|X=x}(y)=\frac{x+y}{x+\frac{1}{2}}\) for \(0\leq y \leq 1\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find the following probabilities: \(\mbox{P}(X<0.5)\); \(\mbox{P}(Y>0.8)\); \(\mbox{P}(X<0.2,Y\geq 0.75)\); \(\mbox{P}(X<0.2|Y\geq 0.75)\); \(\mbox{P}(X<0.2|Y= 0.25)\); Optional - \(\mbox{P}(X\leq Y)\).
\end{enumerate}

\[
\mbox{P}(X<0.5)=\int_0^{0.5} x+\frac{1}{2}\,\mathrm{d}x = \frac{x^2}{2}+\frac{x}{2}\bigg|_0^{0.5}=0.375
\]

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{integrate}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)(x}\OperatorTok{+}\DecValTok{1}\OperatorTok{/}\DecValTok{2}\NormalTok{),}\DecValTok{0}\NormalTok{,}\DecValTok{1}\OperatorTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 0.375 with absolute error < 4.2e-15
\end{verbatim}

Or using multivariate integration, integrate out \(y\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{adaptIntegrate}\NormalTok{(f, }\DataTypeTok{lowerLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DataTypeTok{upperLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $integral
## [1] 0.375
## 
## $error
## [1] 5.551115e-17
## 
## $functionEvaluations
## [1] 17
## 
## $returnCode
## [1] 0
\end{verbatim}

\[
\mbox{P}(Y<0.8)=\int_{0.8}^1 y+\frac{1}{2}\,\mathrm{d}y = \frac{y^2}{2}+\frac{y}{2}\bigg|_{0.8}^1=1-0.72=0.28
\]

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{adaptIntegrate}\NormalTok{(f, }\DataTypeTok{lowerLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.8}\NormalTok{), }\DataTypeTok{upperLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $integral
## [1] 0.28
## 
## $error
## [1] 5.551115e-17
## 
## $functionEvaluations
## [1] 17
## 
## $returnCode
## [1] 0
\end{verbatim}

\[
\mbox{P}(X<0.2,Y\geq 0.75)=\int_0^{0.2}\int_{0.75}^1 x+y\,\mathrm{d}y \,\mathrm{d}x= \int_0^{0.2} xy+\frac{y^2}{2}\bigg|_{0.75}^1\,\mathrm{d}x 
\]
\[
=\int_0^{0.2} x+\frac{1}{2}-\frac{3x}{4}-\frac{9}{32}\,\mathrm{d}x = \int_0^{0.2} \frac{x}{4}+\frac{7}{32}\,\mathrm{d}x = \frac{x^2}{8}+\frac{7x}{32}\bigg|_0^{0.2}=0.04875
\]

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{adaptIntegrate}\NormalTok{(f, }\DataTypeTok{lowerLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.75}\NormalTok{), }\DataTypeTok{upperLimit =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $integral
## [1] 0.04875
## 
## $error
## [1] 0
## 
## $functionEvaluations
## [1] 17
## 
## $returnCode
## [1] 0
\end{verbatim}

\[
\mbox{P}(X<0.2|Y\geq 0.75)=\frac{\mbox{P}(X<0.2,Y\geq 0.75)}{\mbox{P}(Y\geq 0.75)}=\frac{0.04875}{\int_{0.75}^1 y+\frac{1}{2}\,\mathrm{d}y}=\frac{0.04875}{0.34375} \approx 0.142
\]

For
\[
\mbox{P}(X<0.2|Y= 0.25) 
\]
we need

\[
f_{X|Y=.25}(x)=\frac{x+y}{y+\frac{1}{2}}\bigg|_{y=0.25}=\frac{x+.25}{.25+\frac{1}{2}}=\frac{x+.25}{.75}=\frac{4x+1}{3}
\]

\[
\mbox{P}(X<0.2|Y= 0.25) =  \int_{0}^{0.2} \frac{4x+1}{3} \,\mathrm{d}x
\]
\[
=\frac{1}{3}\left( 2x^2 +x \right) \bigg|_0^{0.2} = \frac{1}{3}\left( 2\cdot0.2^2 +0.2 \right) \approx 0.0933
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f2 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{ (}\DecValTok{4}\OperatorTok{*}\NormalTok{x[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)}\OperatorTok{/}\DecValTok{3}\NormalTok{ \} }\CommentTok{# "x" is vector}
\KeywordTok{adaptIntegrate}\NormalTok{(f2, }\DataTypeTok{lowerLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{), }\DataTypeTok{upperLimit =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $integral
## [1] 0.09333333
## 
## $error
## [1] 1.036208e-15
## 
## $functionEvaluations
## [1] 15
## 
## $returnCode
## [1] 0
\end{verbatim}

Optional

\[
\mbox{P}(X\leq Y)=\int_0^1\int_0^y x+y \,\mathrm{d}x \,\mathrm{d}y = \int_0^1 xy+\frac{x^2}{2}\bigg|_0^y \,\mathrm{d}x = \int_0^1 \frac{3y^2}{2}\,\mathrm{d}y = \frac{y^3}{2}\bigg|_0^1 = \frac{1}{2}
\]

\hypertarget{problem-2-13}{%
\subsection{Problem 2}\label{problem-2-13}}

\indent 2. In the Notes, we saw an example where \(f_X(x)=f_{X|Y=y}(x)\) and \(f_Y(y)=f_{Y|X=x}(y)\). This is not common and is important. What does this imply about \(X\) and \(Y\)?

Since the conditional density function is always equal to the marginal, it means that \(X\) and \(Y\) are independent of one another. Also, if the conditioning variable does not appear in the conditional density function and the domain of the joint density is rectangular, the bounds of the two variables are constants, the random variables are independent. The variables in the previous problem are dependent, look at the conditional density functions to see that the conditional density depends on the conditioned variable.

\hypertarget{problem-3-9}{%
\subsection{Problem 3}\label{problem-3-9}}

\indent 3. ADVANCED: Recall on an earlier assignment, we came up with random variables to describe timeliness at an airport. Suppose over the course of 210 days, on each day we recorded the number of customer complaints regarding timeliness. Also on each day, we recorded the weather (our airport is located somewhere without snow and without substantial wind). The data are displayed below.

\[
\begin{array}{cc|ccc} & & &\textbf{Weather Status} &
\\ & & \mbox{Clear} & \mbox{Light Rain} & \mbox{Rain}  \\
&\hline 0 & 28 & 11 & 4  \\
\textbf{num complaints} & 1 & 18 & 15 & 8 \\
& 2 & 17 & 25 & 12  \\
& 3 & 13 & 15 & 16  \\
& 4 & 8 & 8 & 10 \\
& 5 & 0 & 1 & 1 \\
\end{array} 
\]

First, define two random variables for this scenario. One of them (\# of complaints) is essentially already a random variable. For the other (weather status) you will need to assign a number to each status.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Use the table above to build an empirical joint pmf of the two random variables.
\end{enumerate}

We will simply label the weather random variable as 0, 1, 2. We convert to probabilities by dividing by 210.

\[
\begin{array}{cc|ccc} & & &\textbf{Weather Status} &
\\ & & \mbox{Clear} & \mbox{Light Rain} & \mbox{Rain}  \\
&\hline 0 & 0.133 & 0.052 & 0.019  \\
\textbf{num complaints} & 1 & 0.086 & 0.071 & 0.038  \\
& 2 & 0.081 & 0.119 & 0.057  \\
& 3 & 0.062 & 0.071 & 0.076  \\
& 4 & 0.038 & 0.038 & 0.048 \\
& 5 & 0 & 0.005 & 0.005 \\
\end{array} 
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\item
  Find the marginal pmfs of each random variable.
  \[
  f_X(x)=\left\{\begin{array}{ll} 0.400, & x=0 \\
  0.357, & x=1 \\
  0.243, & x=2 \\
  0, & \mbox{otherwise} 
  \end{array}\right.
  \]
  \[
  f_Y(y)=\left\{\begin{array}{ll} 0.205, & y=0 \\
  0.195, & y=1 \\
  0.257, & y=2 \\
  0.210, & y=3 \\
  0.124, & y=4 \\
  0.010, & y=5 \\
  0, & \mbox{otherwise} 
  \end{array}\right.
  \]
\item
  Find the probability of fewer than 3 complaints.
\end{enumerate}

\[
\mbox{P}(Y<3)=0.205+0.195+0.257=0.657
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find the probability of fewer than 3 complaints given there is no rain.
  \[
  \mbox{P}(Y<3|X=0)=\frac{0.133+0.086+0.081}{0.4}=0.75
  \]
\end{enumerate}

\hypertarget{problem-4-5}{%
\subsection{Problem 4}\label{problem-4-5}}

\textbf{Optional for those of you that like Calc III and want a challenge.}

\indent 4. Let \(X\) and \(Y\) be continuous random variables with joint pmf:
\[
f_{X,Y}(x,y)=1
\]

where \(0 \leq x \leq 1\) and \(0 \leq y \leq 2x\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Verify that \(f\) is a valid pdf.
  \[
  \int_0^1 \int_0^{2x} 1 \,\mathrm{d}y \,\mathrm{d}x = \int_0^1 y\bigg|_0^{2x}\,\mathrm{d}x = \int_0^1 2x\,\mathrm{d}x = x^2\bigg|_0^1 = 1
  \]
\item
  Find the marginal pdfs of \(X\) and \(Y\).
  \[
  f_X(x)=\int_0^{2x} 1 \,\mathrm{d}y = y\bigg|_0^{2x}=2x
  \]
  where \(0\leq x \leq 1\).
\end{enumerate}

\[
f_Y(y)=\int_{y/2}^1 1 \,\mathrm{d}x = x\bigg|_{y/2}^1 = 1-\frac{y}{2}
\]
where \(0 \leq y \leq 2\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find the conditional pdfs of \(X|Y=y\) and \(Y|X=x\).
  \[
  f_{X|Y=y}(x)=\frac{1}{1-\frac{y}{2}}=\frac{2}{2-y} 
  \]
  where \(y/2 \leq x \leq 1\).
\end{enumerate}

\[
f_{Y|X=x}(y)=\frac{1}{2x}
\]
where \(0\leq y \leq 2x\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find the following probabilities: \(\mbox{P}(X<0.5)\); \(\mbox{P}(Y>1)\); \(\mbox{P}(X<0.5,Y\leq 0.8)\); \(\mbox{P}(X<0.5|Y= 0.8)\); Optional \(\mbox{P}(Y\leq 1-X)\). (It would probably help to draw some pictures.)
  \[
  \mbox{P}(X<0.5)=\int_0^{0.5} 2x \,\mathrm{d}x = x^2\bigg|_0^{0.5}=0.25
  \]
  \[
  \mbox{P}(Y>1)=\int_1^2 1-\frac{y}{2}\,\mathrm{d}y = y-\frac{y^2}{4}\bigg|_1^2 = 1-\frac{3}{4}=0.25
  \]
  \[
  \mbox{P}(X<0.5,Y\leq 0.8)=\int_0^{0.4}\int_0^{2x} 1 \,\mathrm{d}y \,\mathrm{d}x + \int_{0.4}^{0.5}\int_0^{0.8} 1 \,\mathrm{d}y \,\mathrm{d}x = 0.16+0.08=0.24
  \]
  \[
  \mbox{P}(X<0.5|Y= 0.8)=\int_{0.4}^{0.5} \frac{2}{2-0.8}\,\mathrm{d}x = \frac{5x}{3}\bigg|_{0.4}^{0.5}=0.1667
  \]
  \[
  \mbox{P}(Y\leq 1-X)=\int_0^{1/3}\int_0^{2x} 1 \,\mathrm{d}y \,\mathrm{d}x + \int_{1/3}^1\int_0^{1-x}1 \,\mathrm{d}y \,\mathrm{d}x = \int_0^{1/3}2x\,\mathrm{d}x + \int_{1/3}^1 1-x\,\mathrm{d}x
  \]
  \[
  =\frac{1}{9}+\left(x-\frac{x^2}{2}\right)_{1/3}^1=\frac{1}{9}+\frac{1}{2}-\frac{1}{3}+\frac{1}{18} = \frac{1}{3}
  \]
\end{enumerate}

\hypertarget{MULTIEXP}{%
\chapter{Multivariate Expectation}\label{MULTIEXP}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand{\diff}{\,\mathrm{d}}

\hypertarget{objectives-14}{%
\section{Objectives}\label{objectives-14}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Given a joint pmf/pdf, obtain means and variances of random variables and functions of random variables.\\
\item
  Define the terms covariance and correlation, and given a joint pmf/pdf, obtain the covariance and correlation between two random variables.\\
\item
  Given a joint pmf/pdf, determine whether random variables are independent of one another.\\
\item
  Find conditional expectations.
\end{enumerate}

\hypertarget{homework-14}{%
\section{Homework}\label{homework-14}}

\hypertarget{problem-1-14}{%
\subsection{Problem 1}\label{problem-1-14}}

\indent 1. Let \(X\) and \(Y\) be continuous random variables with joint pdf:
\[
f_{X,Y}(x,y)=x + y
\]

where \(0 \leq x \leq 1\) and \(0 \leq y \leq 1\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find \(\mbox{E}(X)\) and \(\mbox{E}(Y)\). We will use the marginal pdfs found in the Application 14 solution.
\end{enumerate}

\[
\mbox{E}(X)=\int_0^1 x\left(x+\frac{1}{2}\right)\,\mathrm{d}x=\frac{x^3}{3}+\frac{x^2}{4}\bigg|_0^1=\frac{1}{3}+\frac{1}{4}=\frac{7}{12}=0.583
\]
Or numerically:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{ x[}\DecValTok{1}\NormalTok{]}\OperatorTok{*}\NormalTok{(x[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\NormalTok{x[}\DecValTok{2}\NormalTok{]) \} }\CommentTok{# "x" is vector}
\KeywordTok{adaptIntegrate}\NormalTok{(f, }\DataTypeTok{lowerLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DataTypeTok{upperLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $integral
## [1] 0.5833333
## 
## $error
## [1] 1.110223e-16
## 
## $functionEvaluations
## [1] 17
## 
## $returnCode
## [1] 0
\end{verbatim}

\[
\mbox{E}(Y)=\int_0^1 y\left(y+\frac{1}{2}\right)\,\mathrm{d}y = 0.583
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find \(\mbox{Var}(X)\) and \(\mbox{Var}(Y)\).
\end{enumerate}

\[
\mbox{Var}(X)=\mbox{E}(X^2)-\mbox{E}(X)^2
\]
\[
\mbox{E}(X^2)=\int_0^1 x^2\left(x+\frac{1}{2}\right)\,\mathrm{d}x = \frac{x^4}{4}+\frac{x^3}{6}\bigg|_0^1=\frac{1}{ 4}+\frac{1}{6}=\frac{5}{12}=0.417
\]
As a check:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{ x[}\DecValTok{1}\NormalTok{]}\OperatorTok{^}\DecValTok{2}\OperatorTok{*}\NormalTok{(x[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\NormalTok{x[}\DecValTok{2}\NormalTok{]) \} }\CommentTok{# "x" is vector}
\KeywordTok{round}\NormalTok{(}\KeywordTok{adaptIntegrate}\NormalTok{(f, }\DataTypeTok{lowerLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DataTypeTok{upperLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}\OperatorTok{$}\NormalTok{integral,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.417
\end{verbatim}

So, \(\mbox{Var}(X)=0.417-0.583^2=0.076\).

Similarly, \(\mbox{Var}(Y)=0.076\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find \(\mbox{Cov}(X,Y)\) and \(\rho\). Are \(X\) and \(Y\) independent?
  \[
  \mbox{Cov}(X,Y)=\mbox{E}(XY)-\mbox{E}(X)\mbox{E}(Y)
  \]
  \[
  \mbox{E}(XY)=\int_0^1\int_0^1 xy(x+y)\,\mathrm{d}y \,\mathrm{d}x = \int_0^1 \frac{x^2y^2}{2}+\frac{xy^3}{3}\bigg|_0^1 \,\mathrm{d}x = \int_0^1 \frac{x^2}{2}+\frac{x}{3}\,\mathrm{d}x
  \]
  \[
  =\frac{x^3}{6}+\frac{x^2}{6}\bigg|_0^1=\frac{1}{ 3}=0.333
  \]
\end{enumerate}

As a check:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{ x[}\DecValTok{1}\NormalTok{]}\OperatorTok{*}\NormalTok{x[}\DecValTok{2}\NormalTok{]}\OperatorTok{*}\NormalTok{(x[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\NormalTok{x[}\DecValTok{2}\NormalTok{]) \} }\CommentTok{# "x" is vector}
\KeywordTok{round}\NormalTok{(}\KeywordTok{adaptIntegrate}\NormalTok{(f, }\DataTypeTok{lowerLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DataTypeTok{upperLimit =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}\OperatorTok{$}\NormalTok{integral,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.333
\end{verbatim}

So,
\[
\mbox{Cov}(X,Y)=\frac{1}{3}-\left(\frac{7}{12}\right)^2=-0.007
\]

\[
\rho=\frac{\mbox{Cov}(X,Y)}{\sqrt{\mbox{Var}(X)\mbox{Var}(Y)}}=\frac{-0.007}{\sqrt{0.076\times0.076}}=-0.0909
\]

As a check:

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{-0.007}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(.}\DecValTok{076}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.09210526
\end{verbatim}

Using exact values:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\OperatorTok{-}\NormalTok{(}\DecValTok{7}\OperatorTok{/}\DecValTok{12}\NormalTok{)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{((}\DecValTok{5}\OperatorTok{/}\DecValTok{12}\OperatorTok{-}\NormalTok{(}\DecValTok{7}\OperatorTok{/}\DecValTok{12}\NormalTok{)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.09090909
\end{verbatim}

With a non-zero covariance, \(X\) and \(Y\) are not independent.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find \(\mbox{Var}(3X+2Y)\).
  \[
  \mbox{Var}(3X+2Y)=\mbox{Var}(3X)+\mbox{Var}(2Y)+2\mbox{Cov}(3X,2Y)=
  \]
  \[
  9\mbox{Var}(X)+4\mbox{Var}(Y)+12\mbox{Cov}(X,Y) =
  \]
  \[
  9*0.076+4*0.076+12*-0.007 = 0.910
  \]
\end{enumerate}

\hypertarget{problem-2-14}{%
\subsection{Problem 2}\label{problem-2-14}}

\indent 2. Optional - not difficult but does have small Calc III idea. Let \(X\) and \(Y\) be continuous random variables with joint pmf:
\[
f_{X,Y}(x,y)=1
\]

where \(0 \leq x \leq 1\) and \(0 \leq y \leq 2x\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Find \(\mbox{E}(X)\) and \(\mbox{E}(Y)\).
  \[
  \mbox{E}(X)=\int_0^1 x\cdot 2x\,\mathrm{d}x = \frac{2x^3}{3}\bigg|_0^1=0.667
  \]
\end{enumerate}

\[
\mbox{E}(Y)=\int_0^2 y\left(1-\frac{y}{2}\right)\,\mathrm{d}y = \frac{y^2}{2}-\frac{y^3}{6}\bigg|_0^2=2-\frac{8}{ 6}=0.667
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find \(\mbox{Var}(X)\) and \(\mbox{Var}(Y)\).
  \[
  \mbox{E}(X^2)=\int_0^1 x^2\cdot 2x\,\mathrm{d}x = \frac{x^4}{2}\bigg|_0^1=0.5
  \]
\end{enumerate}

So, \(\mbox{Var}(X)=0.5-\left(\frac{2}{3}\right)^2=\frac{1}{ 18}=0.056\)

\[
\mbox{E}(Y^2)=\int_0^2 y^2\left(1-\frac{y}{2}\right)\,\mathrm{d}y = \frac{y^3}{3}-\frac{y^4}{8}\bigg|_0^2=\frac{8}{ 3}-2=0.667
\]

So, \(\mbox{Var}(Y)=\frac{2}{ 3}-\left(\frac{2}{3}\right)^2=\frac{2}{9}=0.222\)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find \(\mbox{Cov}(X,Y)\) and \(\rho\). Are \(X\) and \(Y\) independent?
\end{enumerate}

\[
\mbox{E}(XY)=\int_0^1\int_0^{2x} xy\,\mathrm{d}y \,\mathrm{d}x = \int_0^1 \frac{xy^2}{2}\bigg|_0^{2x}\,\mathrm{d}x = \int_0^1 2x^3\,\mathrm{d}x = \frac{x^4}{2}\bigg|_0^1=\frac{1}{2}
\]

So,
\[
\mbox{Cov}(X,Y)=\frac{1}{2}-\frac{2}{3}\frac{2}{3}=\frac{1}{18}=0.056
\]

\[
\rho=\frac{\mbox{Cov}(X,Y)}{ \sqrt{\mbox{Var}(X)\mbox{Var}(Y)}}=\frac{\frac{1}{ 18}}{\sqrt{\frac{1}{18}\frac{2}{9}}}=0.5
\]

\(X\) and \(Y\) appear to be positively correlated (thus not independent).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find \(\mbox{Var}\left(\frac{X}{2}+2Y\right)\).
  \[
  \mbox{Var}\left(\frac{X}{2}+2Y\right) = \frac{1}{ 4}\mbox{Var}(X)+4\mbox{Var}(Y)+2\mbox{Cov}(X,Y)=\frac{1}{72}+\frac{8}{ 9}+\frac{1}{9}=1.014
  \]
\end{enumerate}

\hypertarget{problem-3-10}{%
\subsection{Problem 3}\label{problem-3-10}}

\indent 3. Suppose \(X\) and \(Y\) are \emph{independent} random variables. Show that \(\mbox{E}(XY)=\mbox{E}(X)\mbox{E}(Y)\).

If \(X\) and \(Y\) are independent, then \(\mbox{Cov}(X,Y)=0\). So,
\[
\mbox{Cov}(X,Y)=\mbox{E}(XY)-\mbox{E}(X)\mbox{E}(Y)=0
\]

Thus,
\[
\mbox{E}(XY)=\mbox{E}(X)\mbox{E}(Y)
\]

\hypertarget{problem-4-6}{%
\subsection{Problem 4}\label{problem-4-6}}

\indent 4. You are playing a game with a friend. Each of you roll a fair sided die and record the result.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Write the joint probability mass function.
\end{enumerate}

Let \(X\) be the number on your die and \(Y\) be the number on your friend's die.

\[
\begin{array}{cc|ccc} & & &\textbf{X} & \\ 
& & 1 & 2 & 3 & 4 & 5 & 6 \\
&\hline  1 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} \\
 & 2 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} \\
\textbf{Y}& 3 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} \\
& 4 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} \\
& 5 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} \\
& 6 & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36} & \frac{1}{36}  \\
\end{array} 
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the expected value of the product of your score and your friend's score.
\end{enumerate}

To find \(E[XY]\), we determine all 36 values of the product of \(X\) and \(Y\) and multiply by the associated probabilities. Since the probabilities are all equal, we will take the \(\frac{1}{36}\) out of the summation. Now

\[E[XY]=\frac{1}{36}(1+2+3+4+5+6+2+4+\]
\[6+8+10+12+3+6+9+12+15+18+4+8+12+16+20+24+\]
\[5+10+15+20+25+30+6+12+18+24+30+36)\]
\[=12.25\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Verify the previous part using simulation.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1012}\NormalTok{)}
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{100000}\NormalTok{)}\OperatorTok{*}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{,}\DataTypeTok{size=}\DecValTok{2}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{prod=}\NormalTok{V1}\OperatorTok{*}\NormalTok{V2) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Expec=}\KeywordTok{mean}\NormalTok{(prod))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Expec
## 1 12.25016
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Using simulation, find the expected value of the maximum number on the two roles.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{100000}\NormalTok{)}\OperatorTok{*}\KeywordTok{max}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{,}\DataTypeTok{size=}\DecValTok{2}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{))) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Expec=}\KeywordTok{mean}\NormalTok{(max))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Expec
## 1 4.4737
\end{verbatim}

\hypertarget{problem-5-4}{%
\subsection{Problem 5}\label{problem-5-4}}

\indent 5. A miner is trapped in a mine containing three doors. The first door leads to a tunnel that takes him to safety after two hours of travel. The second door leads to a tunnel that returns him to the mine after three hours of travel. The third door leads to a tunnel that returns him to his mine after five hours. Assuming that the miner is at all times equally likely to choose any one of the doors, yes a bad assumption but it makes for a nice problem, what is the expected length of time until the miner reaches safety?

Simulating this is a little more challenging because we need a conditional but we try it first before going to the mathematical solution.

Let's write a function that takes a vector and returns the sum of the values up to the first time the number 2 appears, we are using the time values as our sample space. Anytime you are repeating something more than 5 times, it might make sense to write a function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{miner_time <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
\NormalTok{  index <-}\StringTok{ }\KeywordTok{which}\NormalTok{(x}\OperatorTok{==}\DecValTok{2}\NormalTok{)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  total<-}\KeywordTok{cumsum}\NormalTok{(x)}
  \KeywordTok{return}\NormalTok{(total[index])}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{113}\NormalTok{)}
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{miner_time}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{),}\DataTypeTok{size=}\DecValTok{20}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{))) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{Exp=}\KeywordTok{mean}\NormalTok{(miner_time))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Exp
## 1 10.0092
\end{verbatim}

Now let's find it mathematically.

Let \(X\) be the time it takes and \(Y\) the door. Then we have

\[E[X] = E[E[X|Y]] \]
\[ = \frac{1}{3}E[X|Y=1]+\frac{1}{3}E[X|Y=2]+\frac{1}{3}E[X|Y=3]\]
Now if door 2 is selected
\[E[X|Y=2]=E[X]+3\]
since the miner will travel for 3 hours and then be back at the starting point.

Likewise if door 3 is select
\[E[X|Y=2]=E[X]+5\]
So
\[ E[x]= \frac{1}{3}2+\frac{1}{3}\left( E[X]+3 \right)+\frac{1}{3}\left( E[X]+5 \right)\]

\[E[x] -  \frac{2}{3}E[X] = \frac{2}{3}+\frac{3}{3}+\frac{5}{3}\]
\[\frac{1}{3}E[X]=\frac{10}{3}\]

\[E[X]=10\]

\hypertarget{problem-6-3}{%
\subsection{Problem 6}\label{problem-6-3}}

\indent 6. ADVANCED: Let \(X_1,X_2,...,X_n\) be independent, identically distributed random variables. (This is often abbreviated as ``iid''). Each \(X_i\) has mean \(\mu\) and variance \(\sigma^2\) (i.e., for all \(i\), \(\mbox{E}(X_i)=\mu\) and \(\mbox{Var}(X_i)=\sigma^2\)).

Let \(S=X_1+X_2+...+X_n=\sum_{i=1}^n X_i\). And let \(\bar{X}={\sum_{i=1}^n \frac{X_i}{n}}\).

Find \(\mbox{E}(S)\), \(\mbox{Var}(S)\), \(\mbox{E}(\bar{X})\) and \(\mbox{Var}(\bar{X})\).
\[
\mbox{E}(S)=\mbox{E}(X_1+X_2+...+X_n)=\mbox{E}(X_1)+\mbox{E}(X_2)+...+\mbox{E}(X_n)=\mu+\mu+...+\mu=n\mu
\]

Since the \(X_i\)s are all independent:
\[
\mbox{Var}(S)=\mbox{Var}(X_1+X_2+...+X_n)=\mbox{Var}(X_1)+\mbox{Var}(X_2)+...+\mbox{Var}(X_n)=n\sigma^2
\]

\[
\mbox{E}(\bar{X})=\frac{1}{n}\mbox{E}(X_1+X_2+...+X_n)=\frac{1}{n}n\mu=\mu
\]
\[
\mbox{Var}(\bar{X})=\frac{1}{n^2}\mbox{Var}(X_1+X_2+...+X_n)=\frac{1}{n^2}n\sigma^2=\frac{\sigma^2}{n}
\]

\hypertarget{TRANS}{%
\chapter{Transformations}\label{TRANS}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand{\diff}{\,\mathrm{d}}

\hypertarget{objectives-15}{%
\section{Objectives}\label{objectives-15}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Given a discrete random variable, determine the distribution of a transformation of that random variable.\\
\item
  Given a continuous random variable, use the cdf method to determine the distribution of a transformation of that random variable.\\
\item
  Use simulation methods to find the distribution of a transform of single or multivariate random variables.
\end{enumerate}

\hypertarget{homework-15}{%
\section{Homework}\label{homework-15}}

\hypertarget{problem-1-15}{%
\subsection{Problem 1}\label{problem-1-15}}

\indent 1. Let \(X\) be a random variable and let \(g\) be a function. By this point, it should be clear that \(\mbox{E}[g(X)]\) is not necessarily equal to \(g(\mbox{E}[X])\).

Let \(X\sim \textsf{Expon}(\lambda=0.5)\) and \(g(X)=X^2\). We know that \(\mbox{E}(X)=\frac{1}{0.5}=2\) so \(g(\mbox{E}(X))=\mbox{E}(X)^2=4\). Use \texttt{R} to find \(\mbox{E}[g(X)]\). Make use of the fact that \texttt{R} has \texttt{rexp()} built into it, so you don't have to create your own random variable generator.

Let \(Y=X^2\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sims<-}\KeywordTok{rexp}\NormalTok{(}\DecValTok{10000}\NormalTok{,}\FloatTok{0.5}\NormalTok{)}
\KeywordTok{mean}\NormalTok{(sims}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8.164164
\end{verbatim}

So, \(g(\mbox{E}(X))=4\) and \(\mbox{E}(g(X))\approx 7.84\).

\hypertarget{problem-2-15}{%
\subsection{Problem 2}\label{problem-2-15}}

\indent 2. Let \(X\sim \textsf{Binom}(n,\pi)\). What is the pmf for \(X+3\)? Make sure you specify the domain of \(Y\). {[}Note, we have used \(p\) for the probability of success in a binomial distribution in past lessons but some references use \(\pi\) instead.{]}

Let \(Y=X+3\):
\[
f_Y(y)=\mbox{P}(Y=y)=\mbox{P}(X+3=y)=\mbox{P}(X=y-3)=f_X(y-3)=\binom{n}{y-3}\pi^{y-3}(1-\pi)^{n-y+3}
\]

where \(3\leq Y \leq n+3\).

\hypertarget{problem-3-11}{%
\subsection{Problem 3}\label{problem-3-11}}

\indent 3. Let \(X\sim \textsf{Expon}(\lambda)\). Let \(Y=X^2\). Find the pdf of \(Y\).

CDF method:
\[
F_Y(y)=\mbox{P}(Y\leq y)=\mbox{P}(X^2\leq y)=\mbox{P}(X\leq \sqrt y)=1-e^{-\lambda \sqrt y}
\]

So,
\[
f_Y(y)=\frac{\,\mathrm{d}}{\,\mathrm{d}y}F_Y(y)=-e^{-\lambda \sqrt y}\times\frac{-\lambda}{2\sqrt y}=\frac{\lambda e^{-\lambda \sqrt y}}{2\sqrt y}
\]

for \(y >0\).

PDF method:
\[
f_Y(y)=\lambda e^{-\lambda \sqrt{y}}\frac{1}{2\sqrt y}=\frac{\lambda e^{-\lambda \sqrt y}}{2\sqrt y}
\]

for \(y>0\).

\hypertarget{problem-4-7}{%
\subsection{Problem 4}\label{problem-4-7}}

\indent 4. OPTIONAL: In exercise 3, you found the pdf of \(Y=X^2\) when \(X\sim \textsf{Expon}(\lambda)\). Rearrange the pdf to show that \(Y\sim \textsf{Weibull}\) and find the parameters of that distribution.

\[
f_Y(y)=\frac{\lambda e^{-\lambda \sqrt y}}{2\sqrt y}=\frac{\lambda}{2\sqrt y}e^{-\lambda \sqrt y}=\frac{\lambda^2}{2} \frac{1}{\lambda\sqrt y} e^{-\sqrt{\lambda^2 y}}=\frac{1/2}{1/\lambda^2}\left(\frac{y}{1/\lambda^2}\right)^{\frac{1}{2}-1}e^{-\left(\frac{y}{1/\lambda^2}\right)^{\frac{1}{2}}}
\]

So, \(Y\sim \textsf{Weibull}\left(\alpha=\frac{1}{2},\beta=\frac{1}{\lambda^2}\right)\).

\hypertarget{problem-5-5}{%
\subsection{Problem 5}\label{problem-5-5}}

\indent 5. You are on a team of two. You are both tasked to complete an exercise. The time it takes you \(T_1\), and likewise, your teammate \(T_2\) to complete the exercise are independent random variables. Exercise completion time, in minutes, is distributed with the following pdf:

\[
f_T(t)= \frac{-t}{200}+\frac{3}{20}; 10 \leq t \leq30
\]

Figure \ref{fig:fig1} is a plot of the pdf.

\begin{figure}

{\centering \includegraphics{16-Transformation-Solutions_files/figure-latex/fig1-1} 

}

\caption{pdf of $T$}\label{fig:fig1}
\end{figure}

We want to find the probability our combined time is less than 40 minutes, \(\mbox{P}(T_1 + T_2 < 40)\). We will solve this in steps in this problem. We are going to use a computational method because the mathematics is long and algebra intensive. You are welcome to try a mathematical solution if you like but we will not provide a mathematical solution.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Use the \texttt{integrate()} function to confirm this is a valid pdf.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{integrate}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)}\OperatorTok{-}\NormalTok{x}\OperatorTok{/}\DecValTok{200}\OperatorTok{+}\DecValTok{3}\OperatorTok{/}\DecValTok{20}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 1 with absolute error < 1.1e-14
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the cdf of \(T\) mathematically.
\end{enumerate}

\[
\int_{10}^{x} \frac{-t}{200}+\frac{3}{20} \,\mathrm{d}t = \frac{-t^2}{400}+\frac{3t}{20}\bigg|_{10}^x = \frac{-x^2}{400}+\frac{3x}{20} - \frac{5}{4} 
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  To use the cdf to simulate random variables from this distribution, we need the inverse of the cdf which means we have to solve a quadratic equation. We can do this mathematically or just use the function \texttt{uniroot()}. So first, we will make sure we understand how to use \texttt{uniroot()}.
\end{enumerate}

As a check, we know the median of the distribution is approximately 15.857. Here is code to show that 15.857 is approximately the median. We are integrating the pdf from 10 to 15.857 to confirm that this is 0.5.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{integrate}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)}\OperatorTok{-}\NormalTok{x}\OperatorTok{/}\DecValTok{200}\OperatorTok{+}\DecValTok{3}\OperatorTok{/}\DecValTok{20}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{15.857}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 0.4999389 with absolute error < 5.6e-15
\end{verbatim}

Use \texttt{uniroot()} and your cdf to confirm that 15.857 is the median.

Solution.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{uniroot}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)}\OperatorTok{-}\NormalTok{x}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\DecValTok{400}\OperatorTok{+}\DecValTok{3}\OperatorTok{*}\NormalTok{x}\OperatorTok{/}\DecValTok{20-5}\OperatorTok{/}\DecValTok{4}\FloatTok{-.5}\NormalTok{,}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{30}\NormalTok{))}\OperatorTok{$}\NormalTok{root}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.85786
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  We will create a function to take a random uniform variable on the interval \([0,1]\) and return a value of our random variable, \(T\), exercise time. We can then use this function to simulate each of the exercise times and then create a new random variable that is the sum. Complete the \texttt{R} code and check that it returns the median.
\end{enumerate}

\begin{verbatim}
T <- function(y){
  uniroot(function(x)"YOUR CDF HERE as a function of x"-y,c(10,30))$root
}
\end{verbatim}

We made it a function of \(y\) since we are using \(x\) in our cdf. There are two function calls here, can you see why?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(y)\{}
  \KeywordTok{uniroot}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)}\OperatorTok{-}\NormalTok{x}\OperatorTok{^}\DecValTok{2}\OperatorTok{/}\DecValTok{400}\OperatorTok{+}\DecValTok{3}\OperatorTok{*}\NormalTok{x}\OperatorTok{/}\DecValTok{20-5}\OperatorTok{/}\DecValTok{4}\OperatorTok{-}\NormalTok{y,}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{30}\NormalTok{))}\OperatorTok{$}\NormalTok{root}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{T}\NormalTok{(.}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.85786
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Vectorize the function you just created using the \texttt{Vectorize()} function. Check that it is vectorized by entering \texttt{c(.5,.75)} into the function. You should get 15.85786 20.00000 as an output.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T<-}\KeywordTok{Vectorize}\NormalTok{(T)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{T}\NormalTok{(}\KeywordTok{c}\NormalTok{(.}\DecValTok{5}\NormalTok{,.}\DecValTok{75}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.85786 20.00000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{integrate}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x)}\OperatorTok{-}\NormalTok{x}\OperatorTok{/}\DecValTok{200}\OperatorTok{+}\DecValTok{3}\OperatorTok{/}\DecValTok{20}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 0.75 with absolute error < 8.3e-15
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  We are ready. Let's create a data frame with 10000 simulation for our time and another 10000 for our teammates. Remember to set a seed. At this point it may be hard to remember what we have done. The function we created takes as input a vector of random number from a uniform distribution and then applies the inverse cdf to generate a random sample from our given pdf.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{T}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.32941 19.70073 11.19341
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1144}\NormalTok{)}
\NormalTok{sim_exercise <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}\DataTypeTok{T1=}\KeywordTok{T}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{10000}\NormalTok{)),}\DataTypeTok{T2=}\KeywordTok{T}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\DecValTok{10000}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Do a numerical summary of the data and plot a density plot of your exercise times to give us confidence that we simulated the process correctly.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(sim_exercise)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## quantitative variables:  
##      name   class      min       Q1   median       Q3      max     mean
## ...1   T1 numeric 10.00066 12.69182 15.91884 20.04111 29.85565 16.69611
## ...2   T2 numeric 10.00028 12.65653 15.79768 20.03195 29.63950 16.64766
##            sd     n missing
## ...1 4.719835 10000       0
## ...2 4.716582 10000       0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dens}\NormalTok{(}\OperatorTok{~}\NormalTok{T1,}\DataTypeTok{data=}\NormalTok{sim_exercise) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{16-Transformation-Solutions_files/figure-latex/unnamed-chunk-13-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Create the new variable that is the sum of the two exercise time and then find the probability that the sum is less than 40.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sim_exercise }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{T_sum=}\NormalTok{T1}\OperatorTok{+}\NormalTok{T2) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{prob=}\KeywordTok{mean}\NormalTok{(T_sum}\OperatorTok{<}\DecValTok{40}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 1
##    prob
##   <dbl>
## 1 0.835
\end{verbatim}

\hypertarget{EST}{%
\chapter{Estimation Methods}\label{EST}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand{\diff}{\,\mathrm{d}}

\hypertarget{objectives-16}{%
\section{Objectives}\label{objectives-16}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Obtain a method of moments estimate of a parameter or set of parameters.\\
\item
  Given a random sample from a distribution, obtain the likelihood function.\\
\item
  Obtain a maximum likelihood estimate of a parameter or set of parameters.
\end{enumerate}

\hypertarget{homework-16}{%
\section{Homework}\label{homework-16}}

\hypertarget{problem-1-16}{%
\subsection{Problem 1}\label{problem-1-16}}

\indent 1. In the chapter notes, we found that if we take a sample from the uniform distribution \(\textsf{Unif}(0,\theta)\), the method of moments estimate of \(\theta\) is \(\hat{\theta}_{MoM}=2\bar{x}\). Suppose our sample consists of the following values:
\[
0.2 \hspace{0.4cm} 0.9 \hspace{0.4cm} 1.9 \hspace{0.4cm} 2.2 \hspace{0.4cm} 4.7 \hspace{0.4cm} 5.1
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  What is \(\hat{\theta}_{MoM}\) for this sample?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x<-}\KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{,}\FloatTok{0.9}\NormalTok{,}\FloatTok{1.9}\NormalTok{,}\FloatTok{2.2}\NormalTok{,}\FloatTok{4.7}\NormalTok{,}\FloatTok{5.1}\NormalTok{)}
\NormalTok{thetamom<-}\DecValTok{2}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(x)}
\NormalTok{thetamom}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  What is wrong with this estimate?
\end{enumerate}

For our distribution \(\theta\) is the upper bound or largest value for the random variable. The estimate for \(\theta\) is 5, which is an impossible value for \(\theta\), since one of our observations (5.1) is beyond this value.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Show that this estimator is unbiased.
\end{enumerate}

We need to show that
\[
E\left( \hat{\theta}_{MoM} \right) = \theta
\]
We proceed as follows
\[
E \left(2\bar{X} \right) = 2 E\left( \sum{\frac{X_i}{n}} \right) = \frac{2}{n} E\left( \sum{X_i} \right)
\]
\[
=\frac{2}{n}  \sum{E\left(X_i \right)} =\frac{2}{n}\sum{\frac{\theta}{2}}=\frac{n\theta}{n}=\theta
\]
Notice that in performing this derivation, we treated \(X\) as a random variable and not as \(x\), a data value.

\pagebreak

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  ADVANCED: Use simulation in \texttt{R} to find out how often the method of moment estimator is less the maximum observed value, (\(\hat{\theta}_{MoM} < \max x\)). Report an answer for various sizes of samples. You can just pick an arbitrary value for \(\theta\) when you sample from the uniform. However, the minimum must be 0.
\end{enumerate}

Let's start by writing code for one sample size and then generalize. This function will take as input the number of data points, sample that many points from a uniform with a max of 5, and then return a logical value comparing the method of moments estimate to the observed maximum. The choice of a maximum value for the uniform distribution is arbitrary.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{check <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(}\DataTypeTok{n=}\DecValTok{10}\NormalTok{)\{}
\NormalTok{  temp<-}\KeywordTok{runif}\NormalTok{(n,}\DataTypeTok{max=}\DecValTok{5}\NormalTok{)}
  \DecValTok{2}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(temp)}\OperatorTok{<}\KeywordTok{max}\NormalTok{(temp)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Let's test the function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{3030}\NormalTok{)}
\NormalTok{temp<-}\KeywordTok{runif}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DataTypeTok{max=}\DecValTok{5}\NormalTok{)}
\NormalTok{temp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1.048619 2.370056 0.675677 2.434443 2.994015 3.930865 4.708367 1.645806
##  [9] 2.592365 3.664424
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(temp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5.212927
\end{verbatim}

Reset the seed and run the function, we should get FALSE.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{3030}\NormalTok{)}
\KeywordTok{check}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

Now let's repeat the test 10000 find the proportion of times the method of moments estimator is unrealistic.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{check}\NormalTok{(}\DecValTok{10}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\KeywordTok{mean}\NormalTok{(check)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.285
\end{verbatim}

Let's make \texttt{check} a vectorized function for we can run for many sample sizes.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{check <-}\StringTok{ }\KeywordTok{Vectorize}\NormalTok{(check)}
\end{Highlighting}
\end{Shaded}

Run 1000 replicates for each sample size. The rest of the code gets my data frame in the proper shape.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_data<-(}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{check}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{200}\NormalTok{,}\DecValTok{5}\NormalTok{))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise_all}\NormalTok{(mean) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\KeywordTok{everything}\NormalTok{(),}\DataTypeTok{names_to =} \StringTok{"Sample"}\NormalTok{,}\DataTypeTok{values_to =} \StringTok{"Percent"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Sample=}\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{200}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

A quick look at the data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(my_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   Sample Percent
##    <dbl>   <dbl>
## 1     10   0.282
## 2     15   0.358
## 3     20   0.362
## 4     25   0.362
## 5     30   0.398
## 6     35   0.389
\end{verbatim}

Now we can plot the results of sample size versus

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_data }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_line}\NormalTok{(Percent}\OperatorTok{~}\NormalTok{Sample,}\DataTypeTok{xlab=}\StringTok{"Sample Size"}\NormalTok{,}\DataTypeTok{title=}\StringTok{"Percent When Estimator is Invalid"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\DataTypeTok{theme =} \KeywordTok{theme_minimal}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{17-Estimation-Methods-Solutions_files/figure-latex/unnamed-chunk-10-1.pdf}

Here is more traditional, old school \texttt{R} code.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{simn<-}\ControlFlowTok{function}\NormalTok{(n)\{}
\NormalTok{  y<-}\KeywordTok{replicate}\NormalTok{(}\DecValTok{1000}\NormalTok{,\{}
\NormalTok{    x<-}\KeywordTok{runif}\NormalTok{(n)}
\NormalTok{    (}\DecValTok{2}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(x))}\OperatorTok{<}\KeywordTok{max}\NormalTok{(x)}
\NormalTok{  \})}
  \KeywordTok{mean}\NormalTok{(y)}
\NormalTok{\}}

\NormalTok{t<-}\KeywordTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{200}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\NormalTok{persim<-}\KeywordTok{sapply}\NormalTok{(t,simn)}
\KeywordTok{plot}\NormalTok{(t,persim,}\DataTypeTok{type=}\StringTok{"l"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{17-Estimation-Methods-Solutions_files/figure-latex/lesson20b-1.pdf}

\hypertarget{problem-2-16}{%
\subsection{Problem 2}\label{problem-2-16}}

\indent 2. Let \(x_1,x_2,...,x_n\) be a simple random sample from an exponentially distributed population with parameter \(\lambda\). Find \(\hat{\lambda}_{MoM}\).

Recall that \(\mbox{E}(X)={1\over \lambda}\). Setting this equal to the sample moment \(\bar{x}\) and solving for \(\lambda\) yields the method of moment estimator. Thus,
\[
\hat{\lambda}_{MoM}={1\over \bar{x}}
\]

\hypertarget{problem-3-12}{%
\subsection{Problem 3}\label{problem-3-12}}

\indent 3. Let \(x_1,x_2,...,x_n\) be an iid random sample from an exponentially distributed population with parameter \(\lambda\). Find \(\hat{\lambda}_{MLE}\).

Recall that
\[
f_X(x;\lambda)=\lambda e^{-\lambda x}
\]

So the likelihood function is:
\[
L(\lambda;\boldsymbol{x})=\prod_{i=1}^n \lambda e^{-\lambda x_i}=\lambda^n e^{-\lambda\sum x_i}
\]

And the log-likelihood function is:
\[
l(\lambda;\boldsymbol{x})=n\log \lambda - \lambda \sum x_i
\]

Taking the derivative with respect to \(\lambda\) and setting equal to 0:
\[
{\,\mathrm{d}l(\lambda;\boldsymbol{x})\over \,\mathrm{d}\lambda}={n\over \lambda}-\sum x_i =0
\]

Note that \({\,\mathrm{d}^2 l(\lambda;\boldsymbol{x})\over\,\mathrm{d}\lambda^2}=-{n\over \lambda^2}<0\), so \(l\) is always concave down. Thus, any optimum found is a maximum.

So,
\[
\hat{\lambda}_{MLE}={n\over \sum x_i}={1\over \bar{x}}
\]

\hypertarget{problem-4-8}{%
\subsection{Problem 4}\label{problem-4-8}}

\indent 4. It is mathematically difficult to determine if the estimators found in questions 2 and 3 are unbiased. Since the sample mean is in the denominator; mathematically we may have to work with the joint pdf. So instead, use simulation to get an sense of whether the method of moments estimator for the exponential distribution is unbaised.

We need to sample data from an exponential and then compare the the reciprocal of the mean to the parameter.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{630}\NormalTok{)}
\DecValTok{1}\OperatorTok{/}\KeywordTok{mean}\NormalTok{(}\KeywordTok{rexp}\NormalTok{(}\DecValTok{1000}\NormalTok{,}\DataTypeTok{rate=}\DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10.09422
\end{verbatim}

This is close, maybe we just got lucky. Let's repeat many times.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\KeywordTok{mean}\NormalTok{(}\KeywordTok{rexp}\NormalTok{(}\DecValTok{1000}\NormalTok{,}\DataTypeTok{rate=}\DecValTok{10}\NormalTok{)))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(}\OperatorTok{~}\NormalTok{result)}
\end{Highlighting}
\end{Shaded}

\includegraphics{17-Estimation-Methods-Solutions_files/figure-latex/unnamed-chunk-12-1.pdf}

Looks like it has the potential to be unbiased. We would need to investigate other values for \(\lambda\).

\hypertarget{problem-5-6}{%
\subsection{Problem 5}\label{problem-5-6}}

\indent 5. Find a maximum likelihood estimator for \(\theta\) when \(X\sim\textsf{Unif}(0,\theta)\). Compare this to the method of moments estimator we found. Hint: Do not take the derivative of the likelihood function.

\[
L(\theta;\boldsymbol{x})=\frac{1}{\theta^n}, \hspace{0.5cm} \mbox{only if all }x_i\leq \theta
\]

A better way to write this is so as to see the answer is to let \(M =max(x_i)\), then:

\[
L(\theta;\boldsymbol{x})=\left\{\begin{array}{ll} 0, & \theta < M= max(x_i) \\
\frac{1}{\theta^n}, & \theta \geq M = max(x_i) \\
\end{array}\right. 
\]
Figure \ref{fig:fig1} is a plot of this likelihood function and you can see that the maximum occurs at the maximum observed data point.

\begin{figure}

{\centering \includegraphics[width=16in]{figures/L_theta} 

}

\caption{A graph of the likelihood function}\label{fig:fig1}
\end{figure}

Recall that \(f(x_i;\theta)={1\over \theta}\) if \(x_i\in [0,\theta]\) and 0 elsewhere. And since the likelihood function is simply the product of these pdfs, if any \(x_i\) is beyond \(\theta\), then the entire likelihood function is 0.

You can picture \(L\) as a decreasing function of \(\theta\), but remembering that \(L\) takes the value 0 if \(\theta\) is smaller than at least one \(x_i\). Thus, \(L\) achieves its maximum at \(\theta=\max x_i\).

This estimate is more intuitive than the method of moments estimate (\(2\bar{x}\)). The method of moments estimate is sometimes not feasible. Meanwhile, the MLE (\(\max x_i\)) is always feasible.

\hypertarget{part-statistical-modeling}{%
\part{Statistical Modeling}\label{part-statistical-modeling}}

\hypertarget{CS3}{%
\chapter{Case Study}\label{CS3}}

\hypertarget{objectives-17}{%
\section{Objectives}\label{objectives-17}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Define and use properly in context all new terminology.\\
\item
  Conduct a hypothesis test using a permutation test to include all 4 steps.
\end{enumerate}

\hypertarget{homework-17}{%
\section{Homework}\label{homework-17}}

\hypertarget{problem-1-17}{%
\subsection{Problem 1}\label{problem-1-17}}

\indent 1. Side effects of Avandia

Rosiglitazone is the active ingredient in the controversial type\textasciitilde2 diabetes medicine Avandia and has been linked to an increased risk of serious cardiovascular problems such as stroke, heart failure, and death. A common alternative treatment is pioglitazone, the active ingredient in a diabetes medicine called Actos. In a nationwide retrospective observational study of 227,571 Medicare beneficiaries aged 65 years or older, it was found that 2,593 of the 67,593 patients using rosiglitazone and 5,386 of the 159,978 using pioglitazone had serious cardiovascular problems. These data are summarized in the contingency table below.

\[
\begin{array}{ccc|cc|c} & & &\textbf{Cardiovascular} & \textbf{problems} &
\\& &       & Yes   & No        & Total \\
&\hline \textbf{Treatment}      & \textit{Rosiglitazone}    & 2,593 & 65,000        & 67,593    \\
& & \textit{Pioglitazone}       & 5,386     & 154,592   & 159,978\\
&\hline &Total          & 7,979 & 219,592       & 227,571
\end{array} 
\]

Determine if each of the following statements is true or false. If false, explain why. \textit{Be careful:} The reasoning may be wrong even if the statement's conclusion is correct. In such cases, the statement should be considered false.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Since more patients on pioglitazone had cardiovascular problems (5,386 vs.~2,593), we can conclude that the rate of cardiovascular problems for those on a pioglitazone treatment is higher.
\end{enumerate}

False. Instead of comparing counts, we should compare percentages.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The data suggest that diabetic patients who are taking rosiglitazone are more likely to have cardiovascular problems since the rate of incidence was (2,593 / 67,593 = 0.038) 3.8\% for patients on this treatment, while it was only (5,386 / 159,978 = 0.034) 3.4\% for patients on pioglitazone.
\end{enumerate}

True.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The fact that the rate of incidence is higher for the rosiglitazone group proves that rosiglitazone causes serious cardiovascular problems.
\end{enumerate}

False. We cannot infer a causal relationship from an association in an observational study. However, we can say the drug a person is on affects his risk in this case, as he chose that drug and his choice may be associated with other variables, which is why part (b) is true. The difference in these statements is subtle but important.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Based on the information provided so far, we cannot tell if the difference between the rates of incidences is due to a relationship between the two variables or due to chance.
\end{enumerate}

True.

\pagebreak

\hypertarget{problem-2-17}{%
\subsection{Problem 2}\label{problem-2-17}}

\indent 2. Heart transplants

The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was designated an official heart transplant candidate, meaning that he was gravely ill and would most likely benefit from a new heart. Some patients got a transplant and some did not. The variable \texttt{group} indicates which group the patients were in; patients in the treatment group got a transplant and those in the control group did not. Another variable called \texttt{outcome} was used to indicate whether or not the patient was alive at the end of the study.

In the study, of the 34 patients in the control group, 4 were alive at the end of the study. Of the 69 patients in the treatment group, 24 were alive. The contingency table below summarizes these results.

\[
\begin{array}{ccc|cc|c} & & &\textbf{Group} &  &
\\& &       & Control   & Treatment         & Total \\
&\hline \textbf{Outcome}        & \textit{Alive}    & 4     & 24            & 28    \\
& & \textit{Dead}       & 30        & 45            & 75\\
&\hline &Total              & 34        & 69            & 103
\end{array} 
\]

The data is in a file called \textbf{Stanford\_heart\_study.csv}. Read the data in and answer the following questions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{heart<-}\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/Stanford_heart_study.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What proportion of patients in the treatment group and what proportion of patients in the control group died?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(heart)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## categorical variables:  
##      name     class levels   n missing
## 1 outcome character      2 103       0
## 2   group character      2 103       0
##                                    distribution
## 1 Dead (72.8%), Alive (27.2%)                  
## 2 Treatment (67%), Control (33%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{outcome}\OperatorTok{+}\NormalTok{group,}\DataTypeTok{data=}\NormalTok{heart,}\DataTypeTok{margins =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        group
## outcome Control Treatment Total
##   Alive       4        24    28
##   Dead       30        45    75
##   Total      34        69   103
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(outcome}\OperatorTok{~}\NormalTok{group,}\DataTypeTok{data=}\NormalTok{heart,}\DataTypeTok{margins =} \OtherTok{TRUE}\NormalTok{,}\DataTypeTok{format=}\StringTok{"percent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        group
## outcome   Control Treatment
##   Alive  11.76471  34.78261
##   Dead   88.23529  65.21739
##   Total 100.00000 100.00000
\end{verbatim}

So 88.2\% of patients in control group died and 65.2\% in the treatment group.

One approach for investigating whether or not the treatment is effective is to use a randomization technique.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What are the claims being tested? Use the same null and alternative hypothesis notation used in the lesson notes.
\end{enumerate}

\(H_0\): \textbf{Independence model}. The variables \emph{group} and \emph{outcome} are independent. They have no relationship, and the difference in survival rates between the control and treatment groups was due to chance. In other words, heart transplant is not effective.\\
\(H_A\): \textbf{Alternative hypothesis}. The variables \emph{group} and \emph{outcome} are \textbf{not} independent. The difference in survival rates between the control and treatment groups was not due
to chance and the heart transplant is effective.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The paragraph below describes the set up for such approach, if we were to do it without using statistical software. Fill in the blanks with a number or phrase, whichever is appropriate.
\end{enumerate}

We write \emph{alive} on \textbf{28} cards representing patients who were alive at the end of the study, and \emph{dead} on \textbf{75} cards representing patients who were not. Then, we shuffle these cards and split them into two groups: one group of size \textbf{69} representing treatment, and another group of size \textbf{34} representing control. We calculate the difference between the proportion of \emph{dead} cards in the control and treatment groups (control - treatment), this is just so we have positive observed value, and record this value. We repeat this many times to build a distribution centered at \textbf{zero}. Lastly, we calculate the fraction of simulations where the simulated differences in proportions are \textbf{0.23} or \textbf{greater}. If this fraction of simulations, the empirical p-value, is low, we conclude that it is unlikely to have observed such an outcome by chance and that the null hypothesis should be rejected in favor of the alternative.

Next we will perform the simulation and use results to decide the effectiveness of the transplant program.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find observed value of the test statistic, which we decided to use the difference in proportions.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs<-}\KeywordTok{diffprop}\NormalTok{(outcome}\OperatorTok{~}\NormalTok{group,}\DataTypeTok{data=}\NormalTok{heart)}
\NormalTok{obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## diffprop 
## 0.230179
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Simulate 1000 values of the test statistic by using \texttt{shuffle()} on the variable \texttt{group}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1213}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{diffprop}\NormalTok{(outcome}\OperatorTok{~}\KeywordTok{shuffle}\NormalTok{(group),}\DataTypeTok{data=}\NormalTok{heart)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Plot distribution of results. Include a vertical line for the observed value. Clean up the plot as if you were presenting to a decision maker.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{diffprop,}\DataTypeTok{xlab=}\StringTok{"Difference in proportions"}\NormalTok{,}
               \DataTypeTok{ylab=}\StringTok{"Count"}\NormalTok{,}
               \DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}
               \DataTypeTok{color=}\StringTok{"black"}\NormalTok{,}
               \DataTypeTok{title=}\StringTok{"Stanford Heart Study"}\NormalTok{,}
               \DataTypeTok{subtitle=}\StringTok{"Distribution of difference between control and treatment groups"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{obs ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{18-Hypothesis-Testing-Case-Study-Solutions_files/figure-latex/unnamed-chunk-8-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Find p-value. Think carefully about what more extreme would mean.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{p_value =} \KeywordTok{mean}\NormalTok{(diffprop}\OperatorTok{>=}\NormalTok{obs))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   p_value
## 1   0.011
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Decide if the treatment is effective.
\end{enumerate}

Under the independence model, only 11 out of 1000 times (1.1\%) did we get a difference of 0.23 or higher between the proportions of patients that died in the control and treatment groups. Since this is a low probability, we can reject the claim of independence in favor of the alternate model. There is convincing evidence to suggest that the transplant program is defective.

\hypertarget{HYPOTEST}{%
\chapter{Hypothesis Testing}\label{HYPOTEST}}

\hypertarget{objectives-18}{%
\section{Objectives}\label{objectives-18}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Know and properly use the terminology of a hypothesis test.\\
\item
  Conduct all four steps of a hypothesis test using randomization.\\
\item
  Discuss and explain the ideas of decision errors, one-sided versus two-sided, and choice of statistical significance.
\end{enumerate}

\hypertarget{homework-18}{%
\section{Homework}\label{homework-18}}

\hypertarget{problem-1-18}{%
\subsection{Problem 1}\label{problem-1-18}}

\indent 1. Repeat the analysis of the commercial length in the notes. This time use a different test statistic.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ads<-}\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/ads.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ads}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##    basic premium
##    <dbl>   <dbl>
##  1  6.95    3.38
##  2 10.0     7.8 
##  3 10.6     9.42
##  4 10.2     4.66
##  5  8.58    5.36
##  6  7.62    7.63
##  7  8.23    4.95
##  8 10.4     8.01
##  9 11.0     7.8 
## 10  8.52    9.58
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ads <-}\StringTok{ }\NormalTok{ads }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\DataTypeTok{cols=}\KeywordTok{everything}\NormalTok{(),}\DataTypeTok{names_to=}\StringTok{"channel"}\NormalTok{,}\DataTypeTok{values_to =} \StringTok{"length"}\NormalTok{)}
\NormalTok{ads}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 20 x 2
##    channel length
##    <chr>    <dbl>
##  1 basic     6.95
##  2 premium   3.38
##  3 basic    10.0 
##  4 premium   7.8 
##  5 basic    10.6 
##  6 premium   9.42
##  7 basic    10.2 
##  8 premium   4.66
##  9 basic     8.58
## 10 premium   5.36
## 11 basic     7.62
## 12 premium   7.63
## 13 basic     8.23
## 14 premium   4.95
## 15 basic    10.4 
## 16 premium   8.01
## 17 basic    11.0 
## 18 premium   7.8 
## 19 basic     8.52
## 20 premium   9.58
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(length}\OperatorTok{~}\NormalTok{channel,}\DataTypeTok{data=}\NormalTok{ads)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   channel   min      Q1 median       Q3    max   mean       sd  n missing
## 1   basic 6.950 8.30375  9.298 10.30000 11.016 9.2051 1.396126 10       0
## 2 premium 3.383 5.05250  7.715  7.95975  9.580 6.8592 2.119976 10       0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  State the null and alternative hypotheses.
\end{enumerate}

\(H_0\): \textbf{Null hypothesis}. The distribution of length of commercials in premium and basic channels is the same.\\
\(H_A\): \textbf{Alternative hypothesis}. The distribution of length of commercials in premium and basic channels is different.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Compute a test statistic.
\end{enumerate}

We will use the difference in means so we can use \texttt{diffmeans()} from \texttt{mosiac}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs <-}\StringTok{ }\KeywordTok{diffmean}\NormalTok{(length}\OperatorTok{~}\NormalTok{channel,}\DataTypeTok{data=}\NormalTok{ads)}
\NormalTok{obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## diffmean 
##  -2.3459
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Determine the p-value.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{4172}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{diffmean}\NormalTok{(length}\OperatorTok{~}\KeywordTok{shuffle}\NormalTok{(channel),}\DataTypeTok{data=}\NormalTok{ads)}
\end{Highlighting}
\end{Shaded}

Next we create a plot of the empirical sampling distribution of the difference of means.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{diffmean,}
               \DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}
               \DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{obs) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Test statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{19-Hypothesis-Testing-Solutions_files/figure-latex/unnamed-chunk-7-1.pdf}

Again, notice it is centered at zero and symmetrical.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop1}\NormalTok{(}\OperatorTok{~}\NormalTok{(diffmean}\OperatorTok{<=}\NormalTok{obs),}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  prop_TRUE 
## 0.00459954
\end{verbatim}

The p-value is much smaller! The test statistic matters in terms of efficiency of the testing procedure.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Draw a conclusion.
\end{enumerate}

Based on our data, if there were really no difference in the distribution of lengths of commercials in 30 minute shows between basic and premium channels then the probability of finding our observed difference of means is 0.005. Since this is less than our significance level of 0.05, we reject the null in favor of the alternative that the basic channel has longer commercials.

\pagebreak

\hypertarget{problem-2-18}{%
\subsection{Problem 2}\label{problem-2-18}}

\indent 2. Is yawning contagious?

An experiment conducted by the \emph{MythBusters}, a science entertainment TV program on the Discovery Channel, tested if a person can be subconsciously influenced into yawning if another person near them yawns. 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a group where there wasn't a person yawning near them (control). The following table shows the results of this experiment.

\[
\begin{array}{ccc|cc|c} & & &\textbf{Group} &  &
\\& &       & Treatment     & Control       & Total \\
&\hline \textbf{Result}     & \textit{Yawn}     & 10        & 4         & 14    \\
& & \textit{No Yawn}        & 24        & 12            & 36\\
&\hline &Total              & 34        & 16            & 50
\end{array} 
\]

The data is in the file ``yawn.csv''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{yawn <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/yawn.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(yawn)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 50
## Columns: 2
## $ group   <chr> "treatment", "treatment", "control", "treatment", "treatmen...
## $ outcome <chr> "no_yawn", "no_yawn", "no_yawn", "no_yawn", "no_yawn", "yaw...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(yawn)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## categorical variables:  
##      name     class levels  n missing
## 1   group character      2 50       0
## 2 outcome character      2 50       0
##                                    distribution
## 1 treatment (68%), control (32%)               
## 2 no_yawn (72%), yawn (28%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(outcome}\OperatorTok{~}\NormalTok{group,}\DataTypeTok{data=}\NormalTok{yawn,}\DataTypeTok{margins =} \OtherTok{TRUE}\NormalTok{,}\DataTypeTok{format=}\StringTok{"proportion"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          group
## outcome     control treatment
##   no_yawn 0.7500000 0.7058824
##   yawn    0.2500000 0.2941176
##   Total   1.0000000 1.0000000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What are the hypotheses?
\end{enumerate}

\(H_0\): Yawning is not contagious, someone in the group yawning does not impact the percentage of the group that yawns. \(p_c - p_t = 0\) or equivalently \(p_c = p_t\) .\\
\(H_A\): Yawning does have an impact, it is contagious. If someone yawns then you are more likely to yawn. \(p_t > p_c\) or \(p_c - p_t < 0\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Calculate the observed difference between the yawning rates under the two scenarios. Yes we are giving you the test statistic.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs <-}\StringTok{ }\KeywordTok{diffprop}\NormalTok{(outcome}\OperatorTok{~}\NormalTok{group,}\DataTypeTok{data=}\NormalTok{yawn)}
\NormalTok{obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    diffprop 
## -0.04411765
\end{verbatim}

Notice that it is negative. If it had been positive, then we would not even need the next step; we would fail to reject the null because the p-value would be much larger than 0.05. Think about this and make sure you understand.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Estimate the p-value using randomization.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{56}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{diffprop}\NormalTok{(outcome}\OperatorTok{~}\KeywordTok{shuffle}\NormalTok{(group),}\DataTypeTok{data=}\NormalTok{yawn)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop1}\NormalTok{(}\OperatorTok{~}\NormalTok{(diffprop}\OperatorTok{<=}\NormalTok{obs),}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## prop_TRUE 
## 0.5140486
\end{verbatim}

This is a large p-value.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Plot the empirical sampling distribution.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{diffprop,}
               \DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}
               \DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{obs ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Test statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{19-Hypothesis-Testing-Solutions_files/figure-latex/unnamed-chunk-17-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Determine the conclusion of the hypothesis test.
\end{enumerate}

Since p-value, 0.54, is high, larger than 0.05, we fail to reject the null hypothesis of yawning is not contagious. The data do not provide convincing evidence that people are more likely to yawn if a person near them yawns.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  The traditional belief is that yawning is contagious -- one yawn can lead to another yawn, which might lead to another, and so on. In this exercise, there was the option of selecting a one-sided or two-sided test. Which would you recommend (or which did you choose)? Justify your answer in 1-3 sentences.
\end{enumerate}

I chose a one-sided test since as a researcher, I thought having someone in the group yawn would lead to more people in that group yawning.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  How did you select your level of significance? Explain in 1-3 sentences.
\end{enumerate}

Since there was no clear impact on one type of error being worse than the other, I stayed with the default of 0.05.

\hypertarget{PVALUES}{%
\chapter{Empirical p-values}\label{PVALUES}}

\newcommand{\Prob}{\mbox{P}}

\hypertarget{objective}{%
\section{Objective}\label{objective}}

Conduct all four steps of a hypothesis test using probability models.

\hypertarget{homework-19}{%
\section{Homework}\label{homework-19}}

\hypertarget{problem-1-19}{%
\subsection{Problem 1}\label{problem-1-19}}

\indent 1. Repeat the analysis of the yawning data from last lesson but this time use the hypergeometric distribution.

Is yawning contagious?

An experiment conducted by the \emph{MythBusters}, a science entertainment TV program on the Discovery Channel, tested if a person can be subconsciously influenced into yawning if another person near them yawns. 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a group where there wasn't a person yawning near them (control). The following table shows the results of this experiment.

\[
\begin{array}{ccc|cc|c} & & &\textbf{Group} &  &
\\& &       & Treatment     & Control       & Total \\
&\hline \textbf{Result}     & \textit{Yawn}     & 10        & 4         & 14    \\
& & \textit{No Yawn}        & 24        & 12            & 36\\
&\hline &Total              & 34        & 16            & 50
\end{array} 
\]

The data is in the file ``yawn.csv''.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  What are the hypotheses?
\end{enumerate}

\(H_0\): Yawning is not contagious, someone in the group yawning does not impact the percentage of the group that yawns.\\
\(H_A\): Yawning does have an impact, it is contagious. If someone yawns then you are more likely to yawn.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Calculate the observed statistic, pick a cell.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{yawn <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/yawn.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(yawn)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 50
## Columns: 2
## $ group   <chr> "treatment", "treatment", "control", "treatment", "treatmen...
## $ outcome <chr> "no_yawn", "no_yawn", "no_yawn", "no_yawn", "no_yawn", "yaw...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(yawn)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## categorical variables:  
##      name     class levels  n missing
## 1   group character      2 50       0
## 2 outcome character      2 50       0
##                                    distribution
## 1 treatment (68%), control (32%)               
## 2 no_yawn (72%), yawn (28%)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{outcome}\OperatorTok{+}\NormalTok{group,}\DataTypeTok{data=}\NormalTok{yawn,}\DataTypeTok{margins =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          group
## outcome   control treatment Total
##   no_yawn      12        24    36
##   yawn          4        10    14
##   Total        16        34    50
\end{verbatim}

The random variable is the number of control patients that yawned from a population of 16 control patients, 34 treatment patients, where a total of 14 yawned.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find the p-value using the hypergeometric distribution.
\end{enumerate}

In this case we want to find \(\mbox{P}(X \leq 4)\) and double it since it is a two-sided test.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{phyper}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{16}\NormalTok{,}\DecValTok{34}\NormalTok{,}\DecValTok{14}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5127818
\end{verbatim}

Doubling this will take us above 1, which is not valid. You might have seen this when we did the randomization test for this problem in a previous lesson. Again, since the hypergeometric is not symmetrical, we can't just double the p-value from the one-sided test. We could simply report the result as \(\approx 1\). If we look at a plot of the pmf, see the figure, you see that \(X=4\) is the highest probability outcome. Thus the p-value is 1 if we sum all the values less than or equal to \(P(X=4)\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"hyper"}\NormalTok{,}\DataTypeTok{m=}\DecValTok{16}\NormalTok{,}\DataTypeTok{n=}\DecValTok{34}\NormalTok{,}\DataTypeTok{k=}\DecValTok{14}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_hline}\NormalTok{(}\DataTypeTok{yintercept =} \KeywordTok{dhyper}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{16}\NormalTok{,}\DecValTok{34}\NormalTok{,}\DecValTok{14}\NormalTok{),}\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Hypergeometric pmf"}\NormalTok{,}
          \DataTypeTok{subtitle=}\StringTok{"Red line is P(X=4)"}\NormalTok{,}
          \DataTypeTok{y=}\StringTok{"Probability"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(theme_classic)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: geom_hline(): Ignoring `mapping` because `yintercept` was provided.
\end{verbatim}

\includegraphics{20-Empirical-p-values-Solutions_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fisher.test}\NormalTok{(}\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{group}\OperatorTok{+}\NormalTok{outcome,}\DataTypeTok{data=}\NormalTok{yawn))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Fisher's Exact Test for Count Data
## 
## data:  tally(~group + outcome, data = yawn)
## p-value = 1
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.2790902 6.5930656
## sample estimates:
## odds ratio 
##   1.244531
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp<-}\KeywordTok{dhyper}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{14}\NormalTok{,}\DecValTok{16}\NormalTok{,}\DecValTok{34}\NormalTok{,}\DecValTok{14}\NormalTok{)}
\KeywordTok{sum}\NormalTok{(temp[temp}\OperatorTok{<=}\KeywordTok{dhyper}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{16}\NormalTok{,}\DecValTok{34}\NormalTok{,}\DecValTok{14}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Plot the the sampling distribution.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"hyper"}\NormalTok{,}\DataTypeTok{m=}\DecValTok{16}\NormalTok{,}\DataTypeTok{n=}\DecValTok{34}\NormalTok{,}\DataTypeTok{k=}\DecValTok{14}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept =}\DecValTok{4}\NormalTok{,}\DataTypeTok{color=}\StringTok{"red"}\NormalTok{ ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Hypergeometric pmf"}\NormalTok{,}
          \DataTypeTok{subtitle=}\StringTok{"Red line is X=4"}\NormalTok{,}
          \DataTypeTok{y=}\StringTok{"Probability"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{20-Empirical-p-values-Solutions_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Determine the conclusion of the hypothesis test.
\end{enumerate}

Since p-value, 1, is high, larger than 0.05, we fail to reject the null hypothesis of yawning is not contagious. The data do not provide convincing evidence that people are more likely to yawn if a person near them yawns.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Compare your results with the randomization test.
\end{enumerate}

This result is essentially the same as the randomization test.

\hypertarget{problem-2-19}{%
\subsection{Problem 2}\label{problem-2-19}}

\indent 2. Repeat the golf ball example using a different test statistic.

Use a level of significance of 0.05.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  State the null and alternative hypotheses.
\end{enumerate}

We think that the numbers are not all equally likely. The question of one-sided versus two-sided is not relevant in this test, you will see this when we write the hypotheses.

\(H_0\): All of the numbers are equally likely.\(\pi_1 = \pi_2 = \pi_3 = \pi_4\) or \(\pi_1 = \frac{1}{4}, \pi_2 =\frac{1}{4}, \pi_3 =\frac{1}{4}, \pi_4 =\frac{1}{4}\)\\
\(H_A\): The is some other distribution of percentages in the population. At least one population proportion is not \(\frac{1}{4}\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Compute a test statistic.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{golf_balls <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/golf_balls.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(golf_balls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## quantitative variables:  
##        name   class min Q1 median Q3 max     mean       sd   n missing
## ...1 number numeric   1  1      2  3   4 2.366255 1.107432 486       0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{number,}\DataTypeTok{data=}\NormalTok{golf_balls,}\DataTypeTok{format =} \StringTok{"proportion"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## number
##         1         2         3         4 
## 0.2818930 0.2839506 0.2201646 0.2139918
\end{verbatim}

I will use the maximum deviation from the expected value

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs <-}\StringTok{ }\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(}\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{number,}\DataTypeTok{data=}\NormalTok{golf_balls) }\FloatTok{-121.5}\NormalTok{))}
\NormalTok{obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 17.5
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Determine the p-value.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2517}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(}\KeywordTok{table}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{,}\DataTypeTok{size=}\DecValTok{486}\NormalTok{,}\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{))}\OperatorTok{-}\FloatTok{121.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{max,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ obs) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Sampling Distribution of Maximum Deviation"}\NormalTok{,}
          \DataTypeTok{subtitle=}\StringTok{"Multinomial with equal probability"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"Range"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(theme_classic)}
\end{Highlighting}
\end{Shaded}

\includegraphics{20-Empirical-p-values-Solutions_files/figure-latex/unnamed-chunk-15-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop1}\NormalTok{(}\OperatorTok{~}\NormalTok{(max}\OperatorTok{>=}\NormalTok{obs),}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## prop_TRUE 
## 0.2382762
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Draw a conclusion.
\end{enumerate}

Since this p-value is larger than 0.05, we do not reject the null hypothesis. That is, based on our data, we do not find statistically significant evidence against the claim that the number on the golf balls are equally likely.

\hypertarget{problem-3-13}{%
\subsection{Problem 3}\label{problem-3-13}}

\indent 3. Body Temperature

Shoemaker\footnote{L. Shoemaker Allen (1996) What's Normal? -- Temperature, Gender, and Heart Rate, Journal of Statistics Education, 4:2} cites a paper from the American Medical Association\footnote{Mackowiak, P. A., Wasserman, S. S., and Levine, M. M. (1992), ``A Critical Appraisal of 98.6 Degrees F, the Upper Limit of the Normal Body Temperature, and Other Legacies of Carl Reinhold August Wunderlich,'' Journal of the American Medical Association, 268, 1578-1580.} that questions conventional wisdom that the average body temperature of a human is 98.6. One of the main points of the original article -- the traditional mean of 98.6 is, in essence, 100 years out of date. The authors cite problems with Wunderlich's original methodology, diurnal fluctuations (up to 0.9 degrees F per day), and unreliable thermometers. The authors believe the average temperature is less than 98.6. Test the hypothesis.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  State the null and alternative hypotheses.
\end{enumerate}

\(H_0\): The average body temperature is 98.6 \(\mu = 98.6\)\\
\(H_A\): The average body temperature is less than 98.6. \(\mu < 98.6\)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  State the significance level that will be used.
\end{enumerate}

There is no reason to believe one type of error is more important than another.

\(\alpha = 0.05\)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Load the data from the file ``temperature.csv'' and generate summary statistics and a boxplot of the temperature data. We will not be using gender or heart rate for this problem.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temperature <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/temperature.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(temperature)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 130
## Columns: 3
## $ temperature <dbl> 96.3, 96.7, 96.9, 97.0, 97.1, 97.1, 97.1, 97.2, 97.3, 9...
## $ gender      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...
## $ hr          <dbl> 70, 71, 74, 80, 73, 75, 82, 64, 69, 70, 68, 72, 78, 70,...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(}\OperatorTok{~}\NormalTok{temperature,}\DataTypeTok{data=}\NormalTok{temperature)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   min   Q1 median   Q3   max     mean        sd   n missing
##  96.3 97.8   98.3 98.7 100.8 98.24923 0.7331832 130       0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temperature }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(}\OperatorTok{~}\NormalTok{temperature) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(theme_classic)}
\end{Highlighting}
\end{Shaded}

\includegraphics{20-Empirical-p-values-Solutions_files/figure-latex/unnamed-chunk-20-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Compute a test statistic. We are going to help you with this part. We cannot do a randomization test since we don't have a second variable. It would be nice to use the mean as a test statistic but we don't yet know the sampling distribution of the sample mean.
\end{enumerate}

Let's get clever. If the distribution of the sample is symmetric, this is an assumption but look at the boxplot and summary statistics to determine if you are comfortable with it, then under the null hypothesis the observed values should be equally likely to either be greater or less than 98.6. Thus our test statistic is the number of cases that have a positive difference between the observed value and 98.6. This will be a binomial distribution with a probability of success of 0.5. You must also account for the possibility that there are observations of 98.6 in the data.

First let's find out how many data points are equal to 98.6.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temperature }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(temperature}\OperatorTok{==}\FloatTok{98.6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   `temperature == 98.6`     n
##   <lgl>                 <int>
## 1 FALSE                   120
## 2 TRUE                     10
\end{verbatim}

We have ten observations equal to 98.6, we will split this and make 5 have a positive difference and 5 have a negative difference.

Next determine that number of subjects that have a positive difference.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temperature }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pos=}\NormalTok{(temperature}\FloatTok{-98.6}\NormalTok{)}\OperatorTok{>}\DecValTok{0}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{num_less=}\KeywordTok{sum}\NormalTok{(pos))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 1
##   num_less
##      <int>
## 1       39
\end{verbatim}

Therefore we have a total 44 subjects whose temperature was greater than 98.6 and 86 who had a temperature less than 98.6

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Determine the p-value.
\end{enumerate}

Out of 130 subjects, 86 had a temperature less than 98.6 and 44 had a temperature greater. We can use either number to determine a p-value. If the null hypothesis were true, then the probability of 86 or more, this is more extreme under that alternative hypothesis, is

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pbinom}\NormalTok{(}\DecValTok{86}\NormalTok{,}\DecValTok{130}\NormalTok{,.}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7.100214e-05
\end{verbatim}

We could have also done 43 or less.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pbinom}\NormalTok{(}\DecValTok{43}\NormalTok{,}\DecValTok{130}\NormalTok{,.}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7.100214e-05
\end{verbatim}

Our p-value is 0.000071.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Draw a conclusion.
\end{enumerate}

Based on our data, if the true mean body temperature is 98.6, then the probability of having 86 or more subjects out of 130 with temperatures below this is 0.000071. This is too unlikely so we reject the hypothesis that the average body temperature is 98.6.

This is a clever way to test the claim. Make sure you understand how we solved. In the coming lessons we will show you alternative ways to attack the problem.

\hypertarget{CLT}{%
\chapter{Central Limit Theorem}\label{CLT}}

\newcommand{\E}{\mbox{E}}
\newcommand{\Var}{\mbox{Var}}
\newcommand{\Cov}{\mbox{Cov}}
\newcommand{\Prob}{\mbox{P}}
\newcommand{\diff}{\,\mathrm{d}}

\hypertarget{objectives-19}{%
\section{Objectives}\label{objectives-19}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Explain the central limit theorem and when you can use it for inference.\\
\item
  Conduct hypothesis tests of a single mean and proportion using the CLT and \texttt{R}.\\
\item
  Explain how the chi-squared and \(t\) distributions relate to the normal distribution, where we use them, and describe the impact on the shape of the distribution when the parameters are changed.
\end{enumerate}

\hypertarget{homework-20}{%
\section{Homework}\label{homework-20}}

\hypertarget{problem-1-20}{%
\subsection{Problem 1}\label{problem-1-20}}

\indent 1. Suppose we roll a fair six-sided die and let \(X\) be the resulting number. The distribution of \(X\) is discrete uniform. (Each of the six discrete outcomes is equally likely.)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Suppose we roll the fair die 5 times and record the value of \(\bar{X}\), the \emph{mean} of the resulting rolls. Under the central limit theorem, what should be the distribution of \(\bar{X}\)?
\end{enumerate}

The mean of \(X\) is 3.5 and the variance of \(X = \frac{(b-a+1)^2-1}{12} = \frac{35}{12}\) is 2.9167. So,
\[
\bar{X}\overset{approx}{\sim}\textsf{Norm}(3.5,0.764)
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Simulate this process in \texttt{R}. Plot the resulting empirical distribution of \(\bar{X}\) and report the mean and standard deviation of \(\bar{X}\). Was it what you expected?
\end{enumerate}

(HINT: You can simulate a die roll using the \texttt{sample} function. Be careful and make sure you use it properly.)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2003}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DataTypeTok{replace=}\NormalTok{T))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Test statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{21-Central-Limit-Theorem-Solutions_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  min Q1 median Q3 max    mean       sd     n missing
##    1  3    3.6  4   6 3.51278 0.772254 10000       0
\end{verbatim}

It appears to be roughly normally distributed with the mean and standard deviation we expected.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Repeat parts a) and b) for \(n=20\) and \(n=50\). Describe what you notice. Make sure all three plots are plotted on the same \(x\)-axis scale. You can use facets if you combine your data into one \texttt{tibble}.
\end{enumerate}

When \(n=20\):
\[
\bar{X}\overset{approx}{\sim}\textsf{Norm}(3.5,0.382)
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results2<-}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DataTypeTok{replace=}\NormalTok{T))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results2 }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Test statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{21-Central-Limit-Theorem-Solutions_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{data=}\NormalTok{results2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   min   Q1 median   Q3  max    mean        sd     n missing
##  2.15 3.25    3.5 3.75 4.95 3.49896 0.3828754 10000       0
\end{verbatim}

When \(n=50\):
\[
\bar{X}\overset{approx}{\sim}\textsf{Norm}(3.5,0.242)
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results3<-}\KeywordTok{do}\NormalTok{(}\DecValTok{10000}\NormalTok{)}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(}\KeywordTok{sample}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{50}\NormalTok{,}\DataTypeTok{replace=}\NormalTok{T))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results3 }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Test statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{21-Central-Limit-Theorem-Solutions_files/figure-latex/unnamed-chunk-8-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{data=}\NormalTok{results3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   min   Q1 median   Q3  max    mean        sd     n missing
##  2.54 3.34    3.5 3.66 4.36 3.49852 0.2423665 10000       0
\end{verbatim}

Now let's put them all together to make it easier to compare.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final_results<-}\KeywordTok{rbind}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(results,}\DataTypeTok{n=}\DecValTok{10}\NormalTok{),}\KeywordTok{cbind}\NormalTok{(results2,}\DataTypeTok{n=}\DecValTok{20}\NormalTok{),}\KeywordTok{cbind}\NormalTok{(results3,}\DataTypeTok{n=}\DecValTok{50}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final_results }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_dhistogram}\NormalTok{(}\OperatorTok{~}\NormalTok{mean}\OperatorTok{|}\NormalTok{n,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Test statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{21-Central-Limit-Theorem-Solutions_files/figure-latex/unnamed-chunk-11-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(}\OperatorTok{~}\NormalTok{mean}\OperatorTok{|}\NormalTok{n,}\DataTypeTok{data=}\NormalTok{final_results) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{select}\NormalTok{(mean,sd,n)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      mean        sd  n
## 1 3.51278 0.7722540 10
## 2 3.49896 0.3828754 20
## 3 3.49852 0.2423665 50
\end{verbatim}

All results were as expected. As \(n\) increased, the variance of the sample mean decreased.

\hypertarget{problem-2-20}{%
\subsection{Problem 2}\label{problem-2-20}}

\indent 2. The nutrition label on a bag of potato chips says that a one ounce (28 gram) serving of potato chips has 130 calories and contains ten grams of fat, with three grams of saturated fat. A random sample of 35 bags yielded a sample mean of 134 calories with a standard deviation of 17 calories. Is there evidence that the nutrition label does not provide an accurate measure of calories in the bags of potato chips? The conditions necessary for applying the normal model have been checked and are satisfied.

The question has been framed in terms of two possibilities: the nutrition label accurately lists the correct average calories per bag of chips or it does not, which may be framed as a hypothesis test.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Write the null and alternative hypothesis.
\end{enumerate}

\(H_0\): The average is listed correctly. \(\mu = 130\)\\
\(H_A\): The nutrition label is incorrect. \(\mu \neq 130\)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  What level of significance are you going to use?
\end{enumerate}

I am going to use \(\alpha = 0.05\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What is the distribution of the test statistic \({\bar{X}-\mu\over S/\sqrt{n}}\)? Calculate the observed value.
\end{enumerate}

The distribution of the test statistic is \(t\) with 34 degrees of freedom.

The observed average is \(\bar{x} = 134\) and the standard error may be calculated as \(SE = \frac{17}{\sqrt{35}} = 2.87\).

We can compute a test statistic as the t score:
\[
t = \frac{134 - 130}{2.87} = 1.39
\]
d.~Calculate a p-value.

The upper-tail area is 0.0823,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pt}\NormalTok{(}\FloatTok{1.39}\NormalTok{,}\DecValTok{34}\NormalTok{,}\DataTypeTok{lower.tail =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.08678153
\end{verbatim}

or

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pt}\NormalTok{(}\FloatTok{1.39}\NormalTok{,}\DecValTok{34}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.08678153
\end{verbatim}

so the p-value is \(2 \times 0.0823 = 0.1646\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Draw a conclusion.
\end{enumerate}

Since the p-value is larger than 0.05, we do not reject the null hypothesis. That is, there is not enough evidence to show the nutrition label has incorrect information.

\hypertarget{extra-material}{%
\subsubsection{Extra material}\label{extra-material}}

If we had used a normal model based on the CLT our p-value would have been close to the value from the \(t\) because our sample size is large.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pnorm}\NormalTok{(}\FloatTok{1.39}\NormalTok{,}\DataTypeTok{lower.tail =}\NormalTok{ F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.08226444
\end{verbatim}

\hypertarget{problem-3-14}{%
\subsection{Problem 3}\label{problem-3-14}}

\indent 3. Exploration of the chi-squared and \(t\) distributions.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  In \texttt{R}, plot the pdf of a random variable with the chi-squared distribution with 1 degree of freedom. On the same plot, include the pdfs with degrees of freedom of 5, 10 and 50. Describe how the behavior of the pdf changes with increasing degrees of freedom.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"chisq"}\NormalTok{,}\DataTypeTok{df=}\DecValTok{1}\NormalTok{,}\DataTypeTok{col=}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"chisq"}\NormalTok{,}\DataTypeTok{df=}\DecValTok{5}\NormalTok{,}\DataTypeTok{col=}\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"chisq"}\NormalTok{,}\DataTypeTok{df=}\DecValTok{10}\NormalTok{,}\DataTypeTok{col=}\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"chisq"}\NormalTok{,}\DataTypeTok{df=}\DecValTok{50}\NormalTok{,}\DataTypeTok{col=}\DecValTok{4}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_lims}\NormalTok{(}\DataTypeTok{y=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,.}\DecValTok{25}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{y=}\StringTok{"f(x)"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }
\end{Highlighting}
\end{Shaded}

\includegraphics{21-Central-Limit-Theorem-Solutions_files/figure-latex/unnamed-chunk-16-1.pdf}

The ``bump'' moves to the rights as the degrees of freedom increase.

The plot should have a legend, but I could not find a way to do it within \texttt{ggformula} so here it is in \texttt{ggplot}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{75}\NormalTok{)), }\KeywordTok{aes}\NormalTok{(x)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dchisq, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{df =} \DecValTok{1}\NormalTok{),}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline1"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dchisq, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{df =} \DecValTok{5}\NormalTok{),}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline2"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dchisq, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{df =} \DecValTok{10}\NormalTok{),}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline3"}\NormalTok{)) }\OperatorTok{+}\StringTok{    }
\StringTok{   }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dchisq, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{df =} \DecValTok{50}\NormalTok{),}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline4"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{   }\KeywordTok{ylab}\NormalTok{(}\StringTok{""}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{breaks =} \OtherTok{NULL}\NormalTok{) }\OperatorTok{+}
\StringTok{   }\KeywordTok{theme_classic}\NormalTok{()}\OperatorTok{+}
\KeywordTok{scale_colour_manual}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Legend"}\NormalTok{,}
    \DataTypeTok{values=}\KeywordTok{c}\NormalTok{(}\DataTypeTok{myline1=}\StringTok{"black"}\NormalTok{, }
             \DataTypeTok{myline2=}\StringTok{"red"}\NormalTok{,}
             \DataTypeTok{myline3=}\StringTok{"green"}\NormalTok{,}
             \DataTypeTok{myline4=}\StringTok{"blue"}\NormalTok{),}
    \DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"df=1"}\NormalTok{,}\StringTok{"df=5"}\NormalTok{,}\StringTok{"df=10"}\NormalTok{,}\StringTok{"df=50"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{21-Central-Limit-Theorem-Solutions_files/figure-latex/unnamed-chunk-17-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Repeat part (a) with the \(t\) distribution. Add the pdf of a standard normal random variable as well. What do you notice?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"t"}\NormalTok{,}\DataTypeTok{df=}\DecValTok{1}\NormalTok{,}\DataTypeTok{col=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"t"}\NormalTok{,}\DataTypeTok{df=}\DecValTok{5}\NormalTok{,}\DataTypeTok{col=}\StringTok{"red"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"t"}\NormalTok{,}\DataTypeTok{df=}\DecValTok{10}\NormalTok{,}\DataTypeTok{col=}\StringTok{"green"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"t"}\NormalTok{,}\DataTypeTok{df=}\DecValTok{50}\NormalTok{,}\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"norm"}\NormalTok{,}\DataTypeTok{lty=}\DecValTok{2}\NormalTok{,}\DataTypeTok{lwd=}\FloatTok{1.5}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_lims}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{y=}\StringTok{"f(x)"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }
\end{Highlighting}
\end{Shaded}

\includegraphics{21-Central-Limit-Theorem-Solutions_files/figure-latex/unnamed-chunk-18-1.pdf}

As degrees of freedom increases, the \(t\)-distribution approaches the standard normal distribution.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{)), }\KeywordTok{aes}\NormalTok{(x)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dt, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{df =} \DecValTok{1}\NormalTok{),}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline1"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dt, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{df =} \DecValTok{5}\NormalTok{),}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline2"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dt, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{df =} \DecValTok{10}\NormalTok{),}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline3"}\NormalTok{)) }\OperatorTok{+}\StringTok{    }
\StringTok{   }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dt, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{df =} \DecValTok{50}\NormalTok{),}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline4"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{   }\KeywordTok{stat_function}\NormalTok{(}\DataTypeTok{fun =}\NormalTok{ dnorm, }\DataTypeTok{n =} \DecValTok{101}\NormalTok{, }
                \DataTypeTok{args =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{mean=}\DecValTok{0}\NormalTok{,}\DataTypeTok{sd=}\DecValTok{1}\NormalTok{),}
                \DataTypeTok{linetype=}\StringTok{"dashed"}\NormalTok{,}
                \DataTypeTok{mapping=}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{col=}\StringTok{"myline5"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{   }\KeywordTok{ylab}\NormalTok{(}\StringTok{""}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{breaks =} \OtherTok{NULL}\NormalTok{) }\OperatorTok{+}
\StringTok{   }\KeywordTok{theme_classic}\NormalTok{()}\OperatorTok{+}
\KeywordTok{scale_colour_manual}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Legend"}\NormalTok{,}
    \DataTypeTok{values=}\KeywordTok{c}\NormalTok{(}\DataTypeTok{myline1=}\StringTok{"black"}\NormalTok{, }
             \DataTypeTok{myline2=}\StringTok{"red"}\NormalTok{,}
             \DataTypeTok{myline3=}\StringTok{"green"}\NormalTok{,}
             \DataTypeTok{myline4=}\StringTok{"blue"}\NormalTok{,}
             \DataTypeTok{myline5=}\StringTok{"grey"}\NormalTok{),}
    \DataTypeTok{labels=}\KeywordTok{c}\NormalTok{(}\StringTok{"df=1"}\NormalTok{,}\StringTok{"df=5"}\NormalTok{,}\StringTok{"df=10"}\NormalTok{,}\StringTok{"df=50"}\NormalTok{,}\StringTok{"Normal"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{21-Central-Limit-Theorem-Solutions_files/figure-latex/unnamed-chunk-19-1.pdf}

\hypertarget{problem-4-9}{%
\subsection{Problem 4}\label{problem-4-9}}

\indent 4. In this lesson, we have used the expression \emph{degrees of freedom} a lot. What does this expression mean? When we have sample of size \(n\), why are there \(n-1\) degrees of freedom for the \(t\) distribution? Give a short concise answer (about one paragraph). You will likely have to do a little research on your own.

Answers will vary. One possible explanation is that the degrees of freedom represents the number of independent pieces of information. For example, you'll notice that in order to get an unbiased estimate of \(\sigma^2\), we have to divide by \(n-1\). This is because in order to estimate \(\sigma^2\), we need to first estimate \(\mu\), which is done by obtaining the sample mean. Once we know the sample mean, we only have \(n-1\) pieces of independent information. For example, suppose we have a sample of size 10, and we know the sample mean. Once we are given the first 9 observations, we know exactly what the 10th observation must be.

\hypertarget{problem-5-7}{%
\subsection{Problem 5}\label{problem-5-7}}

\indent 5. Deborah Toohey is running for Congress, and her campaign manager claims she has more than 50\% support from the district's electorate. Ms.~Toohey's opponent claimed that Ms.~Toohey has \textbf{less} than 50\%. Set up a hypothesis test to evaluate who is right.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Should we run a one-sided or two-sided hypothesis test?
\end{enumerate}

We should run a two-sided. She could be greater than 50\% regardless of what the opponent claims.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Write the null and alternative hypothesis.
\end{enumerate}

\(H_0\): Ms.~Toohey's support is 50\%. \(p = 0.50\).

\(H_A\): Ms.~Toohey's support is either above or below 50\%. \(p \neq 0.50\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What level of significance are you going to use?
\end{enumerate}

\(\alpha = 0.05\)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  What are the assumptions of this test?
\end{enumerate}

\begin{itemize}
\item
  The observations are independent.
\item
  There are at least 10 votes for and 10 against.
\end{itemize}

Because this is a simple random sample that includes fewer than 10\% of the population, the observations are independent. In a single proportion hypothesis test, the success-failure condition is checked using the null proportion, \(p_0=0.5\): \(np_0 = n(1-p_0) = 500\times 0.5 = 250 \geq 10\). With these conditions verified, the normal model based on the CLT may be applied to \(\hat{p}\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Calculate the test statistic.
\end{enumerate}

A newspaper collects a simple random sample of 500 likely voters in the district and estimates Toohey's support to be 52\%.

The test statistic is \(\bar{x}=0.52\)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Calculate a p-value.
\end{enumerate}

Based on the normal model, we can compute a one-sided p-value and then double to get the correct p-value.

The standard error can be computed. The null value is used again here, because this is a hypothesis test for a single proportion with the specified value for the probability of success.

\[SE = \sqrt{\frac{p_0\times (1-p_0)}{n}} = \sqrt{\frac{0.5\times (1-0.5)}{500}} = 0.022\]

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\KeywordTok{pnorm}\NormalTok{(.}\DecValTok{52}\NormalTok{,}\DataTypeTok{mean=}\NormalTok{.}\DecValTok{5}\NormalTok{,}\DataTypeTok{sd=}\FloatTok{0.022}\NormalTok{,}\DataTypeTok{lower.tail =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3633021
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Draw a conclusion.
\end{enumerate}

Because the p-value is larger than 0.05, we do not reject the null hypothesis, and we do not find convincing evidence to support the campaign manager's claim.

\hypertarget{CI}{%
\chapter{Confidence Intervals}\label{CI}}

\hypertarget{objectives-20}{%
\section{Objectives}\label{objectives-20}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Using asymptotic methods based on the normal distribution, construct and interpret a confidence interval for an unknown parameter.\\
\item
  Describe the relationships between confidence intervals, confidence level, and sample size.\\
\item
  For proportions, be able to calculate the three different approaches for confidence intervals using \texttt{R}.
\end{enumerate}

\hypertarget{homework-21}{%
\section{Homework}\label{homework-21}}

\hypertarget{problem-1-21}{%
\subsection{Problem 1}\label{problem-1-21}}

\indent 1. Chronic illness

In 2013, the Pew Research Foundation reported that ``45\% of U.S. adults report that they live with one or more chronic conditions''.\footnote{\url{http://pewinternet.org/Reports/2013/The-Diagnosis-Difference.aspx} The Diagnosis Difference. November 26, 2013. Pew Research.} However, this value was based on a sample, so it may not be a perfect estimate for the population parameter of interest on its own. The study reported a standard error of about 1.2\%, and a normal model may reasonably be used in this setting.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Create a 95\% confidence interval for the proportion of U.S. adults who live with one or more chronic conditions. Also interpret the confidence interval in the context of the study.
\end{enumerate}

\(0.45 \pm 1.96 \times 0.012 = (0.426, 0.474)\)
We are 95\% confident that 42.6\% to 47.4\% of U.S. adults live with one or more chronic conditions.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a 99\% confidence interval for the proportion of U.S. adults who live with one or more chronic conditions. Also interpret the confidence interval in the context of the study.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qnorm}\NormalTok{(.}\DecValTok{995}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.575829
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.45} \OperatorTok{+}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\KeywordTok{qnorm}\NormalTok{(.}\DecValTok{995}\NormalTok{)}\OperatorTok{*}\FloatTok{0.012}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.41909 0.48091
\end{verbatim}

We are 99\% confident that 41.9\% to 48.1\% of U.S. adults live with one or more chronic conditions.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Identify each of the following statements as true or false. Provide an explanation to justify each of your answers.
\end{enumerate}

\begin{itemize}
\tightlist
\item
  We can say with certainty that the confidence interval from part a contains the true percentage of U.S. adults who suffer from a chronic illness.
\end{itemize}

False, we're only 95\% confident.

\begin{itemize}
\tightlist
\item
  If we repeated this study 1,000 times and constructed a 95\% confidence interval for each study, then approximately 950 of those confidence intervals would contain the true fraction of U.S. adults who suffer from chronic illnesses.
\end{itemize}

True, this is the definition of the confidence level.

\begin{itemize}
\tightlist
\item
  The poll provides statistically significant evidence (at the \(\alpha = 0.05\) level) that the percentage of U.S. adults who suffer from chronic illnesses is not 50\%.
\end{itemize}

True, the equivalent significance level of a two-sided hypothesis test for a 95\% confidence interval is indeed 5\%, and since the interval lies below 50\% this statement is correct.

\begin{itemize}
\tightlist
\item
  Since the standard error is 1.2\%, only 1.2\% of people in the study communicated uncertainty about their answer.
\end{itemize}

False, the 1.2\% measures the uncertainty associated with the sample proportion (the point estimate) not the uncertainty of individual observations, uncertainty in the sense of not being sure of one's answer to a survey question.

\begin{itemize}
\tightlist
\item
  Suppose the researchers had formed a one-sided hypothesis, they believed that the true proportion is less than 50\%. We could find an equivalent one-sided 95\% confidence interval by taking the upper bound of our two-sided 95\% confidence interval.
\end{itemize}

False. In constructing a one-sided confidence interval we need \(\alpha\) to be in one tail. Only taking the upper value of a two-sided 95\% confidence interval leads to a 97.5\% one-sided confidence interval, a more conservative value.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.644854
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.45} \OperatorTok{+}\KeywordTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{)}\OperatorTok{*}\FloatTok{0.012}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4697382
\end{verbatim}

Notice that 46.9 is smaller than 47.4.

\pagebreak

\hypertarget{problem-2-21}{%
\subsection{Problem 2}\label{problem-2-21}}

\indent 2. Vegetarian college students

Suppose that 8\% of college students are vegetarians. Determine if the following statements are true or false, and explain your reasoning.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  The distribution of the sample proportions of vegetarians in random samples of size 60 is approximately normal since \(n \ge 30\).
\end{enumerate}

FALSE. For the distribution of \(\hat{p}\) to be approximately normal, we need to have at least
10 successes and 10 failures in our sample.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The distribution of the sample proportions of vegetarian college students in random samples of size 50 is right skewed.
\end{enumerate}

TRUE. The success-failure condition is not satisfied
\[np = 50 \times 0.08 = 4\] and
\[n(1 - p) = 50 \times 0.92 = 46\]
therefore we know that the distribution of \(\hat{p}\) is not approximately normal. In most samples we would expect \(\hat{p}\) to be close to 0.08, the true population proportion. While \(\hat{p}\) can be as high as 1 (though we would expect this to effectively never happen), it can only go as low as 0. Therefore the distribution would probably take on a right-skewed shape. Plotting the sampling distribution would confirm this suspicion.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  A random sample of 125 college students where 12\% are vegetarians would be considered unusual.
\end{enumerate}

FALSE.
\[ SE_{\hat{p}}
    \approx \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\]
\[=\sqrt{\frac{.08(.92)}{125}} = 0.0243\]

A \(\hat{p}\) of 0.12 is only \(\frac{0.12 - 0.08}{0.0243} = 1.65\) standard errors away from the mean, which would not be considered unusual.

The p-value is:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pnorm}\NormalTok{(}\FloatTok{1.65}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.09894294
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  A random sample of 250 college students where 12\% are vegetarians would be considered unusual.
\end{enumerate}

TRUE.

\[ SE_{\hat{p}}
    \approx \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}\]
\[=\sqrt{\frac{.08(.92)}{250}} = 0.0172\]

Notice that doubling the sample size only reduced the standard error by \(\sqrt{2}\).

A \(\hat{p}\) of 0.12 is \(\frac{0.12 - 0.08}{0.0172} = 2.32\) standard errors away from the mean, which might be considered unusual.

The p-value is:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pnorm}\NormalTok{(}\FloatTok{2.32}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02034088
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  The standard error would be reduced by one-half if we increased the sample size from 125 to 250.
\end{enumerate}

FALSE. Since n appears under the square root sign in the formula for the standard error, increasing the sample size from 125 to 250 would decrease the standard error of the sample proportion only by a factor of \(\sqrt{2}\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  A 99\% confidence will be wider than a 95\% because to have a higher confidence level requires a wider interval.
\end{enumerate}

TRUE. The width is a function of the margin of error. Keeping all else the same, the critical values for 95\% and 99\% are

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp<-}\KeywordTok{qnorm}\NormalTok{(}\KeywordTok{c}\NormalTok{(.}\DecValTok{985}\NormalTok{,.}\DecValTok{995}\NormalTok{))}
\KeywordTok{names}\NormalTok{(temp)<-}\KeywordTok{c}\NormalTok{(}\StringTok{"95%"}\NormalTok{,}\StringTok{"99%"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      95%      99% 
## 2.170090 2.575829
\end{verbatim}

\hypertarget{problem-3-15}{%
\subsection{Problem 3}\label{problem-3-15}}

\indent 3. Orange tabbies

Suppose that 90\% of orange tabby cats are male. Determine if the following statements are true or false, and explain your reasoning.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  The distribution of sample proportions of random samples of size 30 is left skewed.
\end{enumerate}

TRUE. The success-failure condition is not satisfied

\[n\hat{p} = 30 \times 0.90 = 27\] and

\[n(1-\hat{p}) = 30 \times 0.10 = 3;\]

therefore we know that the distribution of \(\hat{p}\) is not nearly normal. In most samples we would expect \(\hat{p}\) to be close to 0.90, the true population proportion. While \(\hat{p}\) can be as low as 0 (though we would expect this to happen very rarely), it can only go as high as 1. Therefore the distribution would probably take on a left-skewed shape. Plotting the sampling distribution would confirm this suspicion.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Using a sample size that is 4 times as large will reduce the standard error of the sample proportion by one-half.
\end{enumerate}

TRUE. Since \(n\) appears in a square root for \(SE\), using a sample size that is 4 times as large will reduce the \(SE\) by half.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  The distribution of sample proportions of random samples of size 140 is approximately normal.
\end{enumerate}

TRUE. The success-failure condition is satisfied

\[n\hat{p} = 140 \times 0.90 = 126\] and

\[n(1-\hat{p}) = 140 \times 0.10 = 14;\]

therefore the distribution of \(\hat{p}\) is nearly normal.

\hypertarget{problem-4-10}{%
\subsection{Problem 4}\label{problem-4-10}}

\indent 4. Working backwards

A 90\% confidence interval for a population mean is (65,77). The population distribution is approximately normal and the population standard deviation is unknown. This confidence interval is based on a simple random sample of 25 observations. Calculate the sample mean, the margin of error, and the sample standard deviation.

The sample mean is the midpoint of the confidence interval:

\[\bar{x} = \frac{65+77}{2} = 71\]
The margin of error is half the width of the confidence interval:

\[ME = \frac{ \left(77 - 65 \right)}{2} = 6 \]

Using df = 25 - 1 = 24 and the confidence level of 90\% we can find the critical value from the t-table distribution.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qt}\NormalTok{(.}\DecValTok{95}\NormalTok{,}\DecValTok{24}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.710882
\end{verbatim}

Lastly, using the margin of error and the critical value we can solve for \(s\):
\[ ME = t_{24}\times \frac{s}{\sqrt{n}}\]
\[6 = 1.71\times \frac{s}{\sqrt{25}}\]
\[s = 17.54\]

\hypertarget{problem-5-8}{%
\subsection{Problem 5}\label{problem-5-8}}

\indent 5. Find the p-value

An independent random sample is selected from an approximately normal population with an unknown standard deviation. Find the p-value for the given set of hypotheses and \(T\) test statistic. Also determine if the null hypothesis would be rejected at \(\alpha = 0.05\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_{A}: \mu > \mu_{0}\), \(n = 11\), \(T = 1.91\)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pt}\NormalTok{(}\FloatTok{1.91}\NormalTok{,}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.04260244
\end{verbatim}

The p-value is less than 0.05, reject the null hypothesis.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(H_{A}: \mu < \mu_{0}\), \(n = 17\), \(T = - 3.45\)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pt}\NormalTok{(}\OperatorTok{-}\FloatTok{3.45}\NormalTok{,}\DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001646786
\end{verbatim}

The p-value is less than 0.05, reject the null hypothesis.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \(H_{A}: \mu \ne \mu_{0}\), \(n = 7\), \(T = 0.83\)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{pt}\NormalTok{(}\FloatTok{0.83}\NormalTok{,}\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.4383084
\end{verbatim}

The p-value is greater than 0.05, fail to reject the null hypothesis.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \(H_{A}: \mu > \mu_{0}\), \(n = 28\), \(T = 2.13\)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\OperatorTok{-}\KeywordTok{pt}\NormalTok{(}\FloatTok{2.13}\NormalTok{,}\DecValTok{27}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02121769
\end{verbatim}

The p-value is less than 0.05, reject the null hypothesis.

\hypertarget{problem-6-4}{%
\subsection{Problem 6}\label{problem-6-4}}

\indent 6. Sleep habits of New Yorkers

New York is known as ``the city that never sleeps''. A random sample of 25 New Yorkers were asked how much sleep they get per night. Statistical summaries of these data are shown below. Do these data provide strong evidence that New Yorkers sleep less than 8 hours a night on average?

\[
\begin{array}{cccccc} & & & &  &
\\& n & \bar{x} & s     & min   & max \\
&\hline 25  & 7.73      & 0.77  & 6.17  & 9.78 \\ 
&   &               &       &           & 
\end{array} 
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Write the hypotheses in symbols and in words.
\end{enumerate}

\(H_0: \mu = 8\) New Yorkers sleep 8 hrs per night on average.\\
\(H_A: \mu < 8\) New Yorkers sleep less than 8 hrs per night on average.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Check conditions, then calculate the test statistic, \(T\), and the associated degrees of freedom.
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Independence: The sample is random and 25 is less than 10\% of all New Yorkers, so it seems reasonable that the observations are independent.\\
\item
  Sample size: Sample size is less than 30, therefore we use a t-test which implies the population must be normal.\\
\item
  Skew: We don't have the data to look at a qq plot so we will make some guesses. All observations are within three standard deviations of the mean. For now we will proceed while acknowledging that we are assuming the skew is perhaps moderate or less (moderate skew would be acceptable for this sample size).
\end{enumerate}

The test statistic and degrees of freedom can be calculated as follows:
\[T = \frac{\bar{x} - \mu_0}{\frac{s}{\sqrt{n}}}  = \]
\[\frac{7.73 - 8}{\frac{0.77}{\sqrt{25}}} = - 1.75\]
\(df = 25 - 1 = 24\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Find and interpret the p-value in this context.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pt}\NormalTok{(}\OperatorTok{-}\FloatTok{1.75}\NormalTok{,}\DecValTok{24}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.04644754
\end{verbatim}

If in fact the true population mean of the amount New Yorkers sleep per night was 8 hours, the probability of getting a random sample of 25 New Yorkers where the average amount of sleep is 7.73 hrs per night or less is 0.046. This p-value is close to 0.05.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  What is the conclusion of the hypothesis test?
\end{enumerate}

Since the p-value is less than 0.05, we reject the null hypothesis that New Yorkers sleep an average of 8 hours per night in favor of the alternative that they sleep less than 8 hours per night on average. However, the p-value is close to the significance level and we may want to run the study again and/or look at sample sizes to determine how big of a difference from 8 hours is important from a practical standpoint.

Let's look at the power of this test. Remember that power is the probability of rejecting the null when the alternative is true. Since the alternative specifies a range of values for the parameter, we must specify a value. This is done by subject matter experts. How much of a difference in average sleep is needed from a practical standpoint to say it is different? Let's say that a half an hour is important to detect. We will use the function \texttt{power.t.test()} to determine the power of our test.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power.t.test}\NormalTok{(}\DataTypeTok{n=}\DecValTok{25}\NormalTok{,}\DataTypeTok{delta=}\NormalTok{.}\DecValTok{5}\NormalTok{,}\DataTypeTok{sd=}\NormalTok{.}\DecValTok{77}\NormalTok{,}\DataTypeTok{alternative =} \StringTok{"one.sided"}\NormalTok{,}\DataTypeTok{type=}\StringTok{"one.sample"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##      One-sample t test power calculation 
## 
##               n = 25
##           delta = 0.5
##              sd = 0.77
##       sig.level = 0.05
##           power = 0.9342637
##     alternative = one.sided
\end{verbatim}

This is a high level of power, the typical value used by researchers is 80\%.

Let's see what the power is for a 15 minute difference.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power.t.test}\NormalTok{(}\DataTypeTok{n=}\DecValTok{25}\NormalTok{,}\DataTypeTok{delta=}\NormalTok{.}\DecValTok{25}\NormalTok{,}\DataTypeTok{sd=}\NormalTok{.}\DecValTok{77}\NormalTok{,}\DataTypeTok{alternative =} \StringTok{"one.sided"}\NormalTok{,}\DataTypeTok{type=}\StringTok{"one.sample"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##      One-sample t test power calculation 
## 
##               n = 25
##           delta = 0.25
##              sd = 0.77
##       sig.level = 0.05
##           power = 0.4731184
##     alternative = one.sided
\end{verbatim}

This is a much lower power and thus not an effective test with that sample size for finding that small of a difference. We can turn the problem around and ask what sample size we need for 80\% power?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power.t.test}\NormalTok{(}\DataTypeTok{power=}\NormalTok{.}\DecValTok{8}\NormalTok{,}\DataTypeTok{delta=}\NormalTok{.}\DecValTok{25}\NormalTok{,}\DataTypeTok{sd=}\NormalTok{.}\DecValTok{77}\NormalTok{,}\DataTypeTok{alternative =} \StringTok{"one.sided"}\NormalTok{,}\DataTypeTok{type=}\StringTok{"one.sample"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##      One-sample t test power calculation 
## 
##               n = 60.02642
##           delta = 0.25
##              sd = 0.77
##       sig.level = 0.05
##           power = 0.8
##     alternative = one.sided
\end{verbatim}

We need 60 subjects in the study.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Construct a 95\% confidence interval that corresponded to this hypothesis test, would you expect 8 hours to be in the interval?
\end{enumerate}

We need an 95\% upper bound on the confidence interval.

\[\bar{x} + t_{24,0.95}{\frac{s}{\sqrt{n}}}  = \]

The critical value is

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qt}\NormalTok{(.}\DecValTok{95}\NormalTok{,}\DecValTok{24}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.710882
\end{verbatim}

So the upper confidence bound is

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{7.73}\OperatorTok{+}\KeywordTok{qt}\NormalTok{(.}\DecValTok{95}\NormalTok{,}\DecValTok{24}\NormalTok{)}\OperatorTok{*}\FloatTok{0.77}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7.993476
\end{verbatim}

The value of 8 is not included in the interval, but it is close. We need more data or another study to be confident in our results.

\hypertarget{problem-7-2}{%
\subsection{Problem 7}\label{problem-7-2}}

\indent 7. Vegetarian college students II

From problem 2 part c, suppose that it has been reported that 8\% of college students are vegetarians. We think USAFA is not typical because of their fitness and health awareness, we think there are more vegetarians. We collect a random sample of 125 cadets and find 12\% claimed they are vegetarians. Is there enough evidence to claim that USAFA cadets are different?

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Use \texttt{binom.test()} to conduct the hypothesis test and find a confidence interval.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{binom.test}\NormalTok{(}\DataTypeTok{x=}\DecValTok{15}\NormalTok{,}\DataTypeTok{n=}\DecValTok{125}\NormalTok{,}\DataTypeTok{p=}\NormalTok{.}\DecValTok{08}\NormalTok{,}\DataTypeTok{alternative =} \StringTok{"greater"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 
## 
## data:  15 out of 125
## number of successes = 15, number of trials = 125, p-value = 0.07483
## alternative hypothesis: true probability of success is greater than 0.08
## 95 percent confidence interval:
##  0.07544411 1.00000000
## sample estimates:
## probability of success 
##                   0.12
\end{verbatim}

We fail to reject. Notice 0.08 is in the interval.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Use \texttt{prop.test()} with \texttt{correct=FALSE} to conduct the hypothesis test and find a confidence interval.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.test}\NormalTok{(}\DataTypeTok{x=}\DecValTok{15}\NormalTok{,}\DataTypeTok{n=}\DecValTok{125}\NormalTok{,}\DataTypeTok{p=}\NormalTok{.}\DecValTok{08}\NormalTok{,}\DataTypeTok{alternative =} \StringTok{"greater"}\NormalTok{,}\DataTypeTok{correct=}\OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  1-sample proportions test without continuity correction
## 
## data:  15 out of 125
## X-squared = 2.7174, df = 1, p-value = 0.04963
## alternative hypothesis: true p is greater than 0.08
## 95 percent confidence interval:
##  0.08007111 1.00000000
## sample estimates:
##    p 
## 0.12
\end{verbatim}

We reject, what is going on?

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use \texttt{prop.test()} with \texttt{correction=TRUE} to conduct the hypothesis test and find a confidence interval.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop.test}\NormalTok{(}\DataTypeTok{x=}\DecValTok{15}\NormalTok{,}\DataTypeTok{n=}\DecValTok{125}\NormalTok{,}\DataTypeTok{p=}\NormalTok{.}\DecValTok{08}\NormalTok{,}\DataTypeTok{alternative =} \StringTok{"greater"}\NormalTok{,}\DataTypeTok{correct=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  1-sample proportions test with continuity correction
## 
## data:  15 out of 125
## X-squared = 2.2011, df = 1, p-value = 0.06896
## alternative hypothesis: true p is greater than 0.08
## 95 percent confidence interval:
##  0.07682087 1.00000000
## sample estimates:
##    p 
## 0.12
\end{verbatim}

We fail to reject.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Which test should you use?
\end{enumerate}

Go into the help for \texttt{binom.test()} in \texttt{R} and it explains these intervals. The way to compare these is to look at coverage. By this we mean for a 95\% confidence interval, does the interval include the true parameter 95\% of the time? This can be checked by simulation, but mathematics are really needed for a more definitive answer.

The first test is an exact test and as stated in the help, it guarantees that the coverage rate is at least 95\%. This means the interval tends to be too large. This is the largest interval and tends to be conservative.

The second test is the \textbf{Score} test, also called the \textbf{Wilson}. It is found by inverting the p-value, beyond the scope of this class. This interval is a nice compromise in its coverage.

The third is still a score but in the calculation of the p-value, a continuity correction is applied. This correction takes the limits on the binomial and extends it 0.5 in each direction. This is done to give the discrete binomial a better approximation to the continuous normal in the CLT. This interval is the default in \texttt{R} via \texttt{prop.test()}.

None of these are our simple confidence interval based on the normal approximation. Here is the code for it:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{binom.test}\NormalTok{(}\DataTypeTok{x=}\DecValTok{15}\NormalTok{,}\DataTypeTok{n=}\DecValTok{125}\NormalTok{,}\DataTypeTok{p=}\NormalTok{.}\DecValTok{08}\NormalTok{,}\DataTypeTok{alternative =} \StringTok{"greater"}\NormalTok{,}\DataTypeTok{ci.method =} \StringTok{"Wald"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Exact binomial test (Wald CI)
## 
## data:  15 out of 125
## number of successes = 15, number of trials = 125, p-value = 0.07483
## alternative hypothesis: true probability of success is greater than 0.08
## 95 percent confidence interval:
##  0.0721916 1.0000000
## sample estimates:
## probability of success 
##                   0.12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{15}\OperatorTok{/}\DecValTok{125}\OperatorTok{-}\KeywordTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{)}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(.}\DecValTok{12}\OperatorTok{*}\NormalTok{.}\DecValTok{88}\OperatorTok{/}\DecValTok{125}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0721916
\end{verbatim}

This interval is not very good. The coverage is poor especially for small sample sizes. To learn more, read \emph{Approximate is better then exact for interval estimation of binomial proportions.} A. Agresti and B. A. Coull, American Statistician 52, 1998, 119-126.

\hypertarget{BOOT}{%
\chapter{Bootstrap}\label{BOOT}}

\hypertarget{objectives-21}{%
\section{Objectives}\label{objectives-21}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Use the bootstrap to estimate the standard error, the standard deviation, of the sample statistic.\\
\item
  Using bootstrap methods, obtain and interpret a confidence interval for an unknown parameter, based on a random sample.\\
\item
  Describe the advantages, disadvantages, and assumptions behind using bootstrapping for confidence intervals.
\end{enumerate}

\hypertarget{homework-22}{%
\section{Homework}\label{homework-22}}

\hypertarget{problem-1-22}{%
\subsection{Problem 1}\label{problem-1-22}}

\indent 1. Poker\\
An aspiring poker player recorded her winnings and losses over 50 evenings of play, the data is in the \texttt{openintro} package in the object \texttt{poker}. The poker player would like to better understand the volatility in her long term play.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Load the data and plot a histogram.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poker<-}\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/poker.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poker }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{winnings,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Winnings"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{23-Bootstrap-Solutions_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Find the summary statistics.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(}\OperatorTok{~}\NormalTok{winnings,}\DataTypeTok{data=}\NormalTok{poker)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    min   Q1 median  Q3  max  mean       sd  n missing
##  -1000 -187     11 289 3712 90.08 703.6835 50       0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \emph{Mean absolute deviation} or \emph{MAD} is a more intuitive measure of spread than variance. It directly measures the average distance from the mean. It is found by the formula:
  \[mad = \sum_{i=1}^{n}\frac{\left| x_{i} - \bar{x} \right|}{n}\]
  Write a function and find the \emph{MAD} of the data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mad<-}\ControlFlowTok{function}\NormalTok{(x)\{}
\NormalTok{  xbar<-}\KeywordTok{mean}\NormalTok{(x)}
  \KeywordTok{sum}\NormalTok{(}\KeywordTok{abs}\NormalTok{(x}\OperatorTok{-}\NormalTok{xbar))}\OperatorTok{/}\KeywordTok{length}\NormalTok{(x)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs<-}\KeywordTok{mad}\NormalTok{(poker}\OperatorTok{$}\NormalTok{winnings)}
\NormalTok{obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 394.1792
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Find the bootstrap distribution of the \emph{MAD} using 1000 replicates.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1122}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{mad}\NormalTok{(}\KeywordTok{resample}\NormalTok{(poker}\OperatorTok{$}\NormalTok{winnings))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Plot a histogram of the bootstrap distribution.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{mad,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Mean absolute deviation"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{23-Bootstrap-Solutions_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Report a 95\% confidence interval on the MAD.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{mad,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         lower    upper central.p
## 2.5% 243.9448 636.0925      0.95
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  ADVANCED: Do you think sample MAD is an unbiased estimator of population MAD? Why or why not?
\end{enumerate}

We don't know without doing some math. We do know that the sample standard deviation is biased and part of that is because we have to use the sample mean in its calculation. We are doing the same thing here, so our estimate might also be biased for the same reason.

\hypertarget{problem-2-22}{%
\subsection{Problem 2}\label{problem-2-22}}

\indent 2. Bootstrap hypothesis testing

Bootstrap hypothesis testing is relatively undeveloped, and is generally not as accurate as permutation testing. Therefore in general avoid it. But for our problem in the notes, it may work. We will sample in a way that is consistent with the null hypothesis, then calculate a P-value as a tail probability like we do in permutation tests. This example does not generalize well to other applications like relative risk, correlation, regression, or categorical data.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Using the \texttt{HELPrct} data set, store the observed value of the difference of means for male and female.
\end{enumerate}

I am going to just select the two columns I need.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{HELP_sub <-}\StringTok{ }\NormalTok{HELPrct }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(age,sex)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs <-}\StringTok{ }\KeywordTok{diffmean}\NormalTok{(age}\OperatorTok{~}\NormalTok{sex,}\DataTypeTok{data=}\NormalTok{HELP_sub)}
\NormalTok{obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   diffmean 
## -0.7841284
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The null hypothesis requires the means of each group to be equal. Pick one group to adjust, either \texttt{male} or \texttt{female}. First zero the mean of the selected group by subtracting the sample mean of this group from data points only in this group. Then add the sample mean of the other group to each data point in the selected group. Store in a new object called \texttt{HELP\_null}.
\end{enumerate}

This is tricky, we are doing some data wrangling here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{means<-}\KeywordTok{mean}\NormalTok{(age}\OperatorTok{~}\NormalTok{sex,}\DataTypeTok{data=}\NormalTok{HELP_sub)}
\NormalTok{means}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   female     male 
## 36.25234 35.46821
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{means[}\StringTok{'female'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   female 
## 36.25234
\end{verbatim}

Let's get all the female observations and adjust the mean to equal that of the males.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{H_female <-}\StringTok{ }\NormalTok{HELP_sub }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(sex}\OperatorTok{==}\StringTok{"female"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{age=}\NormalTok{age}\OperatorTok{-}\NormalTok{means[}\StringTok{'female'}\NormalTok{]}\OperatorTok{+}\NormalTok{means[}\StringTok{'male'}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(}\OperatorTok{~}\NormalTok{age,}\DataTypeTok{data=}\NormalTok{H_female)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 35.46821
\end{verbatim}

Combine back into one data set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{HELP_sub_new<-HELP_sub }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(sex}\OperatorTok{==}\StringTok{"male"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rbind}\NormalTok{(H_female)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Run \texttt{favstats()} to check that the means are equal.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(age}\OperatorTok{~}\NormalTok{sex,}\DataTypeTok{data=}\NormalTok{HELP_sub_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      sex      min       Q1   median       Q3      max     mean       sd   n
## 1 female 20.21587 30.21587 34.21587 39.71587 57.21587 35.46821 7.584858 107
## 2   male 19.00000 30.00000 35.00000 40.00000 60.00000 35.46821 7.750110 346
##   missing
## 1       0
## 2       0
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  On this new adjusted data set, generate a bootstrap distribution of the difference in sample means.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1159}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{diffmean}\NormalTok{(age}\OperatorTok{~}\NormalTok{sex,}\DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(HELP_sub_new))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Plot the bootstrap distribution and a line at the observed difference in sample means.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{diffmean,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept=}\NormalTok{obs) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Difference in means"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: geom_vline(): Ignoring `mapping` because `xintercept` was provided.
\end{verbatim}

\includegraphics{23-Bootstrap-Solutions_files/figure-latex/unnamed-chunk-18-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Find a p-value.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\KeywordTok{prop1}\NormalTok{(}\OperatorTok{~}\NormalTok{(diffmean}\OperatorTok{<=}\NormalTok{obs),}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## prop_TRUE 
## 0.3476523
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  How does the p-value compare with those in the notes.
\end{enumerate}

This is a similar p-value.

\hypertarget{problem-3-16}{%
\subsection{Problem 3}\label{problem-3-16}}

\indent 3. Paired data

Are textbooks actually cheaper online? Here we compare the price of textbooks at the University of California, Los Angeles' (UCLA's) bookstore and prices at Amazon.com. Seventy-three UCLA courses were randomly sampled in Spring 2010, representing less than 10\% of all UCLA courses. When a class had multiple books, only the most expensive text was considered.

The data is in the file \texttt{textbooks.csv} under the data folder.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{textbooks<-}\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/textbooks.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   dept_abbr = col_character(),
##   course = col_character(),
##   isbn = col_character(),
##   ucla_new = col_double(),
##   amaz_new = col_double(),
##   more = col_character(),
##   diff = col_double()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(textbooks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 7
##   dept_abbr course isbn           ucla_new amaz_new more   diff
##   <chr>     <chr>  <chr>             <dbl>    <dbl> <chr> <dbl>
## 1 Am Ind    C170   978-0803272620     27.7     28.0 Y     -0.28
## 2 Anthro    9      978-0030119194     40.6     31.1 Y      9.45
## 3 Anthro    135T   978-0300080643     31.7     32   Y     -0.32
## 4 Anthro    191HB  978-0226206813     16       11.5 Y      4.48
## 5 Art His   M102K  978-0892365999     19.0     14.2 Y      4.74
## 6 Art His   118E   978-0394723693     15.0     10.2 Y      4.78
\end{verbatim}

Each textbook has two corresponding prices in the data set: one for the UCLA bookstore and one for Amazon. Therefore, each textbook price from the UCLA bookstore has a natural correspondence with a textbook price from Amazon. When two sets of observations have this special correspondence, they are said to be \textbf{paired}.

To analyze paired data, it is often useful to look at the difference in outcomes of each pair of observations. In \texttt{textbooks}, we look at the difference in prices, which is represented as the \texttt{diff} variable. It is important that we always subtract using a consistent order; here Amazon prices are always subtracted from UCLA prices.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Is this data tidy? Explain.
\end{enumerate}

Yes, because each row is a textbook and each column is a variable.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Make a scatterplot of the UCLA price versus the Amazon price. Add a 45 degree line to the plot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{textbooks }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_point}\NormalTok{(ucla_new}\OperatorTok{~}\NormalTok{amaz_new) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_abline}\NormalTok{(}\DataTypeTok{slope=}\DecValTok{1}\NormalTok{,}\DataTypeTok{intercept =} \DecValTok{0}\NormalTok{,}\DataTypeTok{color=}\StringTok{"darkblue"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Amazon"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"UCLA"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{23-Bootstrap-Solutions_files/figure-latex/unnamed-chunk-22-1.pdf}

It appears the books at the UCLA bookstore are more expensive. One way to test this is with a regression model; we will learn about in the next block.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Make a histogram of the differences in price.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{textbooks }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{diff,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Distribution of price differences"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"Price difference between UCLA and Amazon"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{23-Bootstrap-Solutions_files/figure-latex/unnamed-chunk-23-1.pdf}

The distribution is skewed.

The hypotheses are:\\
\(H_0\): \(\mu_{diff}=0\). There is no difference in the average textbook price.\\
\(H_A\): \(\mu_{diff} \neq 0\). There is a difference in average prices.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  To use a \(t\) distribution, the variable \texttt{diff} has to be independent and normally distributed. Since the 73 books represent less than 10\% of the population, the assumption that the random sample is independent is reasonable. Check normality using \texttt{qqnorsim()} from the \texttt{openintro} package. It generates 8 qq plots of simulated normal data that you can use to judge the \texttt{diff} variable.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qqnormsim}\NormalTok{(diff,textbooks)}
\end{Highlighting}
\end{Shaded}

\includegraphics{23-Bootstrap-Solutions_files/figure-latex/unnamed-chunk-24-1.pdf}

The normality assumption is suspect but we have a large sample so it should be acceptable to use the \(t\).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Run a \(t\) test on the \texttt{diff} variable. Report the p-value and conclusion.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t_test}\NormalTok{(}\OperatorTok{~}\NormalTok{diff,textbooks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  diff
## t = 7.6488, df = 72, p-value = 6.928e-11
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##   9.435636 16.087652
## sample estimates:
## mean of x 
##  12.76164
\end{verbatim}

We did not have to use the \texttt{paired} option since we already took the difference. Here is an example of using the \texttt{paired} option.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t_test}\NormalTok{(textbooks}\OperatorTok{$}\NormalTok{ucla_new,textbooks}\OperatorTok{$}\NormalTok{amaz_new,}\DataTypeTok{paired=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Paired t-test
## 
## data:  textbooks$ucla_new and textbooks$amaz_new
## t = 7.6488, df = 72, p-value = 6.928e-11
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   9.435636 16.087652
## sample estimates:
## mean of the differences 
##                12.76164
\end{verbatim}

The p-value is so small that we don't believe the average price of the books from the UCLA bookstore and Amazon are the same.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Create a bootstrap distribution and generate a 95\% confidence interval on the mean of the differences, the \texttt{diff} column.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{textbooks }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{obs_diff=}\KeywordTok{mean}\NormalTok{(diff))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 1
##   obs_diff
##      <dbl>
## 1     12.8
\end{verbatim}

We need to just pull the difference.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs_stat<-}\StringTok{ }\NormalTok{textbooks }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{obs_diff=}\KeywordTok{mean}\NormalTok{(diff)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{(obs_diff)}

\NormalTok{obs_stat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12.76164
\end{verbatim}

Next a bootstrap distribution.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{843}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{mean}\NormalTok{(}\OperatorTok{~}\NormalTok{diff,}\DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(textbooks))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_dhistogram}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_dist}\NormalTok{(}\StringTok{"norm"}\NormalTok{,}\DataTypeTok{mean=}\FloatTok{12.76}\NormalTok{,}\DataTypeTok{sd=}\DecValTok{14}\OperatorTok{/}\KeywordTok{sqrt}\NormalTok{(}\DecValTok{72}\NormalTok{),}\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ obs_stat) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Sampling distribution of the mean of differences in price"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"Mean of differences in price"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{23-Bootstrap-Solutions_files/figure-latex/unnamed-chunk-30-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         lower    upper central.p
## 2.5% 9.583829 16.05705      0.95
\end{verbatim}

Not a bad solution for this problem.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  If there is really no differences between book sources, the variable \texttt{more} is a binomial and under the null the probably of success is \(\pi = 0.5\). Run a hypothesis test using the variable \texttt{more}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(textbooks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## categorical variables:  
##        name     class levels  n missing
## 1 dept_abbr character     41 73       0
## 2    course character     66 73       0
## 3      isbn character     73 73       0
## 4      more character      2 73       0
##                                    distribution
## 1 Mgmt (8.2%), Pol Sci (6.8%) ...              
## 2 10 (4.1%), 101 (2.7%), 180 (2.7%) ...        
## 3 978-0030119194 (1.4%) ...                    
## 4 Y (61.6%), N (38.4%)                         
## 
## quantitative variables:  
##          name   class   min    Q1 median     Q3   max     mean       sd  n
## ...1 ucla_new numeric 10.50 24.70  43.56 116.00 214.5 72.22192 59.65913 73
## ...2 amaz_new numeric  8.60 20.21  34.95  88.09 176.0 59.46027 48.99557 73
## ...3     diff numeric -9.53  3.80   8.23  17.59  66.0 12.76164 14.25530 73
##      missing
## ...1       0
## ...2       0
## ...3       0
\end{verbatim}

We have 45 books that were more expensive out of the total of 73.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop_test}\NormalTok{(}\DecValTok{45}\NormalTok{,}\DecValTok{73}\NormalTok{,}\DataTypeTok{p=}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  1-sample proportions test with continuity correction
## 
## data:  45 out of 73
## X-squared = 3.5068, df = 1, p-value = 0.06112
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.4948968 0.7256421
## sample estimates:
##         p 
## 0.6164384
\end{verbatim}

Notice that this test failed to reject the null hypothesis. In the paired test, the evidence was so strong but in the binomial model it is not. There is a loss of information making a discrete variable out of a continuous one.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Could you use a permutation test on this example? Explain.
\end{enumerate}

Yes, but you have to be careful because you want to keep the pairing so you can't just shuffle the names. You have to shuffle the names within the paired values. This means to simply randomly switch the names within a row. This is easier to do by just multiplying the diff column by a random choice of -1 and 1.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{size=}\DecValTok{73}\NormalTok{,}\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1 -1 -1  1 -1 -1 -1  1 -1 -1  1 -1 -1  1 -1  1  1  1 -1 -1 -1 -1  1 -1 -1
## [26] -1 -1  1  1  1  1  1 -1  1  1  1  1  1  1 -1 -1  1  1 -1  1  1  1  1 -1 -1
## [51] -1 -1 -1  1 -1  1 -1 -1  1  1 -1  1  1 -1 -1 -1  1  1 -1  1 -1  1  1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{406}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{mean}\NormalTok{((}\OperatorTok{~}\NormalTok{diff}\OperatorTok{*}\KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{size=}\DecValTok{73}\NormalTok{,}\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)),}\DataTypeTok{data=}\NormalTok{textbooks)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{mean,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Randomization sampling distribution of mean of differences in price"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"Mean of price difference"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{23-Bootstrap-Solutions_files/figure-latex/unnamed-chunk-36-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{prop1}\NormalTok{((}\OperatorTok{~}\NormalTok{mean}\OperatorTok{>=}\NormalTok{obs_stat),}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   prop_TRUE 
## 0.000999001
\end{verbatim}

None of the permuted values is at or greater that the observed value.

\hypertarget{ADDTESTS}{%
\chapter{Additional Hypothesis Tests}\label{ADDTESTS}}

\hypertarget{objectives-22}{%
\section{Objectives}\label{objectives-22}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Conduct and interpret a hypothesis test for equality of two or more means using both permutation and the \(F\) distribution.\\
\item
  Conduct and interpret a goodness of fit test using both Pearson's chi-squared and randomization to evaluate the independence between two categorical variables.\\
\item
  Conduct and interpret a hypothesis test for the equality of two variances.\\
\item
  Know and check assumptions for the tests in this lesson.
\end{enumerate}

\hypertarget{homework-23}{%
\section{Homework}\label{homework-23}}

\hypertarget{problem-1-23}{%
\subsection{Problem 1}\label{problem-1-23}}

\indent 1. Golf balls

Repeat the analysis of the golf ball problem from earlier this semester.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Load the data and tally the data into a table. The data is in \texttt{golf\_balls.csv}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{golf_balls <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/golf_balls.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(golf_balls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 1
##   number
##    <dbl>
## 1      3
## 2      2
## 3      1
## 4      4
## 5      4
## 6      3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{number,}\DataTypeTok{data=}\NormalTok{golf_balls)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## number
##   1   2   3   4 
## 137 138 107 104
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Using the function \texttt{chisq.test} conduct a hypothesis test of equally likely distribution of balls. You may have to read the help menu.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{chisq.test}\NormalTok{(}\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{number,}\DataTypeTok{data=}\NormalTok{golf_balls),}\DataTypeTok{p=}\KeywordTok{c}\NormalTok{(.}\DecValTok{25}\NormalTok{,.}\DecValTok{25}\NormalTok{,.}\DecValTok{25}\NormalTok{,.}\DecValTok{25}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Chi-squared test for given probabilities
## 
## data:  tally(~number, data = golf_balls)
## X-squared = 8.4691, df = 3, p-value = 0.03725
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Repeat part b. but assume balls with the numbers 1 and 2 occur 30\% of the time and balls with 3 and 4 occur 20\%.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{chisq.test}\NormalTok{(}\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{number,}\DataTypeTok{data=}\NormalTok{golf_balls),}\DataTypeTok{p=}\KeywordTok{c}\NormalTok{(.}\DecValTok{3}\NormalTok{,.}\DecValTok{3}\NormalTok{,.}\DecValTok{2}\NormalTok{,.}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Chi-squared test for given probabilities
## 
## data:  tally(~number, data = golf_balls)
## X-squared = 2.4122, df = 3, p-value = 0.4914
\end{verbatim}

\hypertarget{problem-2-23}{%
\subsection{Problem 2}\label{problem-2-23}}

\indent 2. Bootstrap hypothesis testing

Repeat the analysis of the MLB data from the lesson but this time generate a bootstrap distribution of the \(F\) statistic.

First, read in the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mlb_obp <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/mlb_obp.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Convert \texttt{position} to a factor.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mlb_obp <-}\StringTok{ }\NormalTok{mlb_obp }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{position=}\KeywordTok{as.factor}\NormalTok{(position))}
\end{Highlighting}
\end{Shaded}

Summarize the data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{favstats}\NormalTok{(obp}\OperatorTok{~}\NormalTok{position,}\DataTypeTok{data=}\NormalTok{mlb_obp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   position   min      Q1 median      Q3   max      mean         sd   n missing
## 1        C 0.219 0.30000 0.3180 0.35700 0.405 0.3226154 0.04513175  39       0
## 2       DH 0.287 0.31625 0.3525 0.36950 0.412 0.3477857 0.03603669  14       0
## 3       IF 0.174 0.30800 0.3270 0.35275 0.437 0.3315260 0.03709504 154       0
## 4       OF 0.265 0.31475 0.3345 0.35300 0.411 0.3342500 0.02944394 120       0
\end{verbatim}

We need a function to resample the data, we will use the \texttt{resample()} from the \texttt{mosaic} package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f_boot <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
  \KeywordTok{aov}\NormalTok{(obp}\OperatorTok{~}\NormalTok{position,}\DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(x)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{stat=}\NormalTok{meansq[}\DecValTok{1}\NormalTok{]}\OperatorTok{/}\NormalTok{meansq[}\DecValTok{2}\NormalTok{]) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{541}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{f_boot}\NormalTok{(mlb_obp)}
\end{Highlighting}
\end{Shaded}

Let's plot our sampling distribution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{f_boot,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Bootstrap sampling distribution of F test statistic"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"Test statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{24-Additional-Hypothesis-Tests-Solutions_files/figure-latex/unnamed-chunk-12-1.pdf}

Now the confidence interval for the F-statistic is:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{f_boot,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          lower    upper central.p
## 2.5% 0.3546682 8.724895      0.95
\end{verbatim}

We are 95\% confident that the \(F\) statistic is in the interval \((0.35,8.72)\) which includes 1 so we fail to reject the null hypothesis of equal means. Remember under the null hypothesis the ratio of the variance between means to the pooled variance within categories should be 1.

\hypertarget{problem-3-17}{%
\subsection{Problem 3}\label{problem-3-17}}

\indent 3. Test of variance

We have not performed a test of variance so we will create our own.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Using the MLB from the lesson, subset on \texttt{IF} and \texttt{OF}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mlb_prob3 <-}\StringTok{ }\NormalTok{mlb_obp }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(position}\OperatorTok{==}\StringTok{"IF"}\OperatorTok{|}\NormalTok{position}\OperatorTok{==}\StringTok{"OF"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{droplevels}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(mlb_prob3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  position      obp        
##  IF:154   Min.   :0.1740  
##  OF:120   1st Qu.:0.3100  
##           Median :0.3310  
##           Mean   :0.3327  
##           3rd Qu.:0.3530  
##           Max.   :0.4370
\end{verbatim}

The function \texttt{droplevels()} gets rid of \texttt{C} and \texttt{DH} in the factor levels.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a side-by-side boxplot.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mlb_prob3 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(obp}\OperatorTok{~}\NormalTok{position) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{24-Additional-Hypothesis-Tests-Solutions_files/figure-latex/unnamed-chunk-16-1.pdf}

The hypotheses are:\\
\(H_0\): \(\sigma^2_{IF}=\sigma^2{OF}\). There is no difference in the variance of on base percentage for infielders and outfielders.\\
\(H_A\): \(\sigma^2_{IF}\neq \sigma^2_{OF}\). There is a difference in variances.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use the differences in sample standard deviations as your test statistic. Using a permutation test, find the p-value and discuss your decision.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mlb_prob3 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(position) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{stat=}\KeywordTok{sd}\NormalTok{(obp))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   position   stat
##   <fct>     <dbl>
## 1 IF       0.0371
## 2 OF       0.0294
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{obs <-}\StringTok{ }\NormalTok{mlb_prob3 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{stat=}\KeywordTok{sd}\NormalTok{(obp[position}\OperatorTok{==}\StringTok{"IF"}\NormalTok{])}\OperatorTok{-}\KeywordTok{sd}\NormalTok{(obp[position}\OperatorTok{==}\StringTok{"OF"}\NormalTok{])) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\NormalTok{obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.007651101
\end{verbatim}

Let's write a function to shuffle the position.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perm_stat <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
\NormalTok{  x }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{position=}\KeywordTok{shuffle}\NormalTok{(position)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{stat=}\KeywordTok{sd}\NormalTok{(obp[position}\OperatorTok{==}\StringTok{"IF"}\NormalTok{])}\OperatorTok{-}\KeywordTok{sd}\NormalTok{(obp[position}\OperatorTok{==}\StringTok{"OF"}\NormalTok{])) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{443}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{perm_stat}\NormalTok{(mlb_prob3)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{perm_stat,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept=}\NormalTok{obs,}\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Sampling distribution of difference in variances"}\NormalTok{,}
          \DataTypeTok{subtitle=}\StringTok{"Randomization permutation test"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"Test statistic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{24-Additional-Hypothesis-Tests-Solutions_files/figure-latex/unnamed-chunk-21-1.pdf}

The p-value is

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\KeywordTok{prop1}\NormalTok{(}\OperatorTok{~}\NormalTok{(perm_stat}\OperatorTok{>=}\NormalTok{obs),}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  prop_TRUE 
## 0.04395604
\end{verbatim}

This is a two sided test since we did not know in advance which variance would be larger. We reject the hypothesis of equal variance but the p-value is too close to the significance level. The conclusion is suspect. We need more data.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Create a bootstrap distribution of the differences in sample standard deviations, and report a 95\% confidence interval. Compare with part c.~
\end{enumerate}

Let's write a function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var_stat <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
  \KeywordTok{resample}\NormalTok{(x) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{stat=}\KeywordTok{sd}\NormalTok{(obp[position}\OperatorTok{==}\StringTok{"IF"}\NormalTok{])}\OperatorTok{-}\KeywordTok{sd}\NormalTok{(obp[position}\OperatorTok{==}\StringTok{"OF"}\NormalTok{])) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{()}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{827}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{var_stat}\NormalTok{(mlb_prob3)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{var_stat,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_vline}\NormalTok{(}\DataTypeTok{xintercept=}\NormalTok{obs,}\DataTypeTok{color=}\StringTok{"red"}\NormalTok{)}\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Bootstrap sampling of difference in variances"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"Difference in variances"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{24-Additional-Hypothesis-Tests-Solutions_files/figure-latex/unnamed-chunk-25-1.pdf}

\hypertarget{part-predictive-statistical-modeling}{%
\part{Predictive Statistical Modeling}\label{part-predictive-statistical-modeling}}

\hypertarget{CS4}{%
\chapter{Case Study}\label{CS4}}

\hypertarget{objectives-23}{%
\section{Objectives}\label{objectives-23}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Using \texttt{R}, generate a linear regression model and use it to produce a prediction model.\\
\item
  Using plots, check the assumptions of a linear regression model.
\end{enumerate}

\hypertarget{homework-24}{%
\section{Homework}\label{homework-24}}

\hypertarget{problem-1-24}{%
\subsection{Problem 1}\label{problem-1-24}}

\indent 1. HFI

Choose another freedom variable and a variable you think would strongly correlate with it. Note: even though some of the variables will appear to be quantitative, they don't take on enough different values and thus appear to be categorical. So choose with some caution. The \texttt{openintro} package contains the data set \texttt{hfi}. Type \texttt{?openintro::hfi} in the Console window in \texttt{RStudio} to learn more about the variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hfi<-}\KeywordTok{tibble}\NormalTok{(}\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/hfi.csv"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Produce a scatterplot of the two variables.
\end{enumerate}

We selected \texttt{pf\_expression\_influence} as it is a measure of laws and regulations that influence media content. We kept \texttt{pf\_score} because it is a measure of personal freedom in a country. Our thought is these should be correlated.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gf_lm}\NormalTok{(pf_score}\OperatorTok{~}\NormalTok{pf_expression_influence,}\DataTypeTok{data=}\NormalTok{hfi,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_point}\NormalTok{(}\DataTypeTok{alpha=}\FloatTok{0.3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Personal freedom score versus Control on media"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"Laws and regulations that influence media content"}\NormalTok{,}
          \DataTypeTok{y=}\StringTok{"Personal freedom score"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{25-Linear-Regression-Case-Study-Solutions_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Quantify the strength of the relationship with the correlation coefficient.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{hfi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\KeywordTok{cor}\NormalTok{(pf_expression_influence, pf_score, }\DataTypeTok{use =} \StringTok{"complete.obs"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 1
##   `cor(pf_expression_influence, pf_score, use = "complete.obs")`
##                                                            <dbl>
## 1                                                          0.787
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Fit a linear model. At a glance, does there seem to be a linear relationship?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(pf_score }\OperatorTok{~}\StringTok{ }\NormalTok{pf_expression_influence, }\DataTypeTok{data =}\NormalTok{ hfi)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(m2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = pf_score ~ pf_expression_influence, data = hfi)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9688 -0.5830  0.1681  0.5903  3.6730 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(>|t|)    
## (Intercept)              5.06135    0.05064   99.95   <2e-16 ***
## pf_expression_influence  0.41150    0.00869   47.36   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.8482 on 1376 degrees of freedom
##   (80 observations deleted due to missingness)
## Multiple R-squared:  0.6197, Adjusted R-squared:  0.6195 
## F-statistic:  2243 on 1 and 1376 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\item
  How does this relationship compare to the relationship between
  \texttt{pf\_expression\_control} and \texttt{pf\_score}? Use the \(R^2\) values from the two
  model summaries to compare. Does your independent variable seem to predict
  your dependent one better? Why or why not?

  The adjusted \(R^2\) is a little smaller so the fit is not as good.
\item
  Display the model diagnostics for the regression model analyzing this relationship.
\end{enumerate}

\textbf{Linearity}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m2, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ .fitted, }\DataTypeTok{y =}\NormalTok{ .resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{, }\DataTypeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Fitted values"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Residuals"}\NormalTok{,}\DataTypeTok{title=}\StringTok{"Residual analysis"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{25-Linear-Regression-Case-Study-Solutions_files/figure-latex/residuals-1.pdf}
\caption{\label{fig:residuals}Fitted values versus residuals for diagnostics.}
\end{figure}

There does appear to be some type of fluctuation so the linear model may not be appropriate.

\textbf{Nearly normal residuals}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m2, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ .resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{.4}\NormalTok{,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Residuals"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{25-Linear-Regression-Case-Study-Solutions_files/figure-latex/unnamed-chunk-5-1.pdf}

or a normal probability plot of the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ m2, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ .resid)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{stat_qq}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_abline}\NormalTok{(}\DataTypeTok{slope=}\DecValTok{1}\NormalTok{,}\DataTypeTok{intercept =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{25-Linear-Regression-Case-Study-Solutions_files/figure-latex/unnamed-chunk-6-1.pdf}

No, the sample is small but it appears the residual are skewed to the left.

\textbf{Constant variability}:

Based on Figure \ref{fig:residuals}, the width of the plot seems constant with the exception of some extreme points. The constant variability assumption seems reasonable.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Predict the response from your explanatory variable for a value between the median and third quartile. Is this an overestimate or an underestimate, and by how much?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(hfi}\OperatorTok{$}\NormalTok{pf_expression_influence)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
##   0.000   3.000   5.333   5.200   7.333   9.667      80
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(m2,}\DataTypeTok{newdata=}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{pf_expression_influence=}\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       1 
## 7.53036
\end{verbatim}

We thus predict a value of 7.53 for the \texttt{pf\_score}.

The observed value is 7.96, an average of 42 data points. We tend to underestimate the observed value.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{augment}\NormalTok{(m2) }\OperatorTok{%>%}
\StringTok{   }\KeywordTok{filter}\NormalTok{(pf_expression_influence}\OperatorTok{==}\DecValTok{6}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{ave=}\KeywordTok{mean}\NormalTok{(pf_score),}\DataTypeTok{n=}\KeywordTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##     ave     n
##   <dbl> <int>
## 1  7.96    42
\end{verbatim}

\hypertarget{LRBASICS}{%
\chapter{Linear Regression Basics}\label{LRBASICS}}

\hypertarget{objectives-24}{%
\section{Objectives}\label{objectives-24}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Obtain parameter estimates of a simple linear regression model given a sample of data.\\
\item
  Interpret the coefficients of a simple linear regression.\\
\item
  Create a scatterplot with a regression line.\\
\item
  Explain and check the assumptions of linear regression.\\
\item
  Use and be able to explain all new terms.
\end{enumerate}

\hypertarget{homework-25}{%
\section{Homework}\label{homework-25}}

\hypertarget{problem-1-25}{%
\subsection{Problem 1}\label{problem-1-25}}

\indent 1. Nutrition at Starbucks

In the \texttt{data} folder is a file named \texttt{starbucks.csv}. Use it to answer the questions below.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Create a scatterplot of number of calories and amount of carbohydrates.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{starbucks <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/starbucks.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   item = col_character(),
##   calories = col_double(),
##   fat = col_double(),
##   carb = col_double(),
##   fiber = col_double(),
##   protein = col_double(),
##   type = col_character()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(starbucks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 77
## Columns: 7
## $ item     <chr> "8-Grain Roll", "Apple Bran Muffin", "Apple Fritter", "Ban...
## $ calories <dbl> 350, 350, 420, 490, 130, 370, 460, 370, 310, 420, 380, 320...
## $ fat      <dbl> 8, 9, 20, 19, 6, 14, 22, 14, 18, 25, 17, 12, 17, 21, 5, 18...
## $ carb     <dbl> 67, 64, 59, 75, 17, 47, 61, 55, 32, 39, 51, 53, 34, 57, 52...
## $ fiber    <dbl> 5, 7, 0, 4, 0, 5, 2, 0, 0, 0, 2, 3, 2, 2, 3, 3, 2, 3, 0, 2...
## $ protein  <dbl> 10, 6, 5, 7, 0, 6, 7, 6, 5, 7, 4, 6, 5, 5, 12, 7, 8, 6, 0,...
## $ type     <chr> "bakery", "bakery", "bakery", "bakery", "bakery", "bakery"...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{starbucks }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_point}\NormalTok{(calories}\OperatorTok{~}\NormalTok{carb) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Carbohydrate Content (g)"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Calories"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{26-Linear-Regression-Basics-Solutions_files/figure-latex/unnamed-chunk-3-1.pdf}

We put \texttt{calories} as the response.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Describe the relationship in the graph.
\end{enumerate}

There is a positive, moderate, linear association between number of calories and amount of carbohydrates. In addition, the amount of carbohydrates is more variable for menu items with higher calories, indicating non-constant variance. There also appear to be two clusters of data: a patch of about a dozen observations in the lower left and a
larger patch on the right side. There might be some natural groupings of the these points. For example, the points in the lower left might come from a \emph{light} menu.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  In this scenario, what are the explanatory and response variables?
\end{enumerate}

Response: number of calories. Explanatory: amount of carbohydrates (in grams).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Why might we want to fit a regression line to these data?
\end{enumerate}

With a regression line, we can predict the amount of calories for a given number of carbohydrates. This may be useful if you are concerned about your carb intake and its impact on calorie consumption. Typically you can get both on the menu so this model might not be that valuable.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Create a scatterplot of number of calories and amount of carbohydrates with the regression line included.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{starbucks }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_point}\NormalTok{(calories}\OperatorTok{~}\NormalTok{carb) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Carbohydrate Content (g)"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Calories"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_lm}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{26-Linear-Regression-Basics-Solutions_files/figure-latex/unnamed-chunk-4-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Using 'lm()` fit a least squares line to the data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{star_mod <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(calories}\OperatorTok{~}\NormalTok{carb,}\DataTypeTok{data=}\NormalTok{starbucks)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(star_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = calories ~ carb, data = starbucks)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -151.962  -70.556   -0.636   54.908  179.444 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 146.0204    25.9186   5.634 2.93e-07 ***
## carb          4.2971     0.5424   7.923 1.67e-11 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 78.26 on 75 degrees of freedom
## Multiple R-squared:  0.4556, Adjusted R-squared:  0.4484 
## F-statistic: 62.77 on 1 and 75 DF,  p-value: 1.673e-11
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Report and interpret the slope coefficient.
\end{enumerate}

The estimated slope is 4.297 so one additional gram of carbohydrates results in an average increase in calories of 4.297.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  For a menu item with 51 g of carbs, what is the estimated calorie count?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{146.0204+4.2971}\OperatorTok{*}\DecValTok{51}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 365.1725
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  Could we use the model for a menu item with 100 g of carbs?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(starbucks)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      item              calories          fat             carb      
##  Length:77          Min.   : 80.0   Min.   : 0.00   Min.   :16.00  
##  Class :character   1st Qu.:300.0   1st Qu.: 9.00   1st Qu.:31.00  
##  Mode  :character   Median :350.0   Median :13.00   Median :45.00  
##                     Mean   :338.8   Mean   :13.77   Mean   :44.87  
##                     3rd Qu.:420.0   3rd Qu.:18.00   3rd Qu.:59.00  
##                     Max.   :500.0   Max.   :28.00   Max.   :80.00  
##      fiber          protein           type          
##  Min.   :0.000   Min.   : 0.000   Length:77         
##  1st Qu.:0.000   1st Qu.: 5.000   Class :character  
##  Median :2.000   Median : 7.000   Mode  :character  
##  Mean   :2.221   Mean   : 9.481                     
##  3rd Qu.:4.000   3rd Qu.:15.000                     
##  Max.   :7.000   Max.   :34.000
\end{verbatim}

The maximum carb value is 80 so 100 is outside of the observed data. It would be suspect to extrapolate to that value.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{9}
\tightlist
\item
  Does the assumption of constant variance seem reasonable for this problem?
\end{enumerate}

We are going to use the \texttt{broom} package to get the residuals and corresponding independent variable values. You could also get the residuals from the model object and the independent variable values from the original dataframe.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{augment}\NormalTok{(star_mod) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_point}\NormalTok{(.resid}\OperatorTok{~}\NormalTok{carb) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_hline}\NormalTok{(}\DataTypeTok{yintercept =} \DecValTok{0}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Residual plot"}\NormalTok{,}\DataTypeTok{x=}\StringTok{"Carbohydrates"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Residual"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{26-Linear-Regression-Basics-Solutions_files/figure-latex/unnamed-chunk-10-1.pdf}

It seems that the variance in the second group is larger that the first, so it may not be a reasonable assumption. Also note that the linearity assumption is also questionable.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{10}
\tightlist
\item
  Verify that the line passes through the mean carb and mean calories, do this mathematically.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{146.0204+4.2971}\OperatorTok{*}\FloatTok{44.87}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 338.8313
\end{verbatim}

It checks.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{11}
\tightlist
\item
  What is the estimate of the standard deviation of the residuals? How could you use this information?
\end{enumerate}

The estimate is 78.26. If the normal assumption is accurate, we would expect a majority of observations to be within \(\pm\) 78.26 calories of the line.

\hypertarget{LRINF}{%
\chapter{Linear Regression Inference}\label{LRINF}}

\hypertarget{objectives-25}{%
\section{Objectives}\label{objectives-25}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Given a simple linear regression model, conduct inference on the coefficients \(\beta_0\) and \(\beta_1\).\\
\item
  Given a simple linear regression model, calculate the predicted response for a given value of the predictor.\\
\item
  Build and interpret confidence and prediction intervals for values of the response variable.
\end{enumerate}

\hypertarget{homework-26}{%
\section{Homework}\label{homework-26}}

\hypertarget{problem-1-26}{%
\subsection{Problem 1}\label{problem-1-26}}

\indent 1. We noticed that the 95\% prediction interval was much wider than the 95\% confidence interval. In words, explain why this is.

The two intervals are describing different parameters. A 95\% confidence interval is describing the \emph{mean} value of the response at a particular value of the predictor. On the other hand, a 95\% prediction interval is describing an \emph{individual} value of the response at a particular value of the predictor. There will be more uncertainty around an individual value than the overall mean.

\hypertarget{problem-2-24}{%
\subsection{Problem 2}\label{problem-2-24}}

\indent 2. Beer and blood alcohol content

Many people believe that gender, weight, drinking habits, and many other factors are much more important in predicting blood alcohol content (BAC) than simply considering the number of drinks a person consumed. Here we examine data from sixteen student volunteers at Ohio State University who each drank a randomly assigned number of cans of beer. These students were evenly divided between men and women, and they differed in weight and drinking habits. Thirty minutes later, a police officer measured their blood alcohol content (BAC) in grams of alcohol per deciliter of blood. The data is in the \texttt{bac.csv} file under the \texttt{data} folder.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Create a scatterplot for cans of beer and blood alcohol level.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bac <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/bac.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bac }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_point}\NormalTok{(bac}\OperatorTok{~}\NormalTok{beers) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Number of cans of beer"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"BAC"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_refine}\NormalTok{(}\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{9}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{27-Regression-Inference-Solutions_files/figure-latex/unnamed-chunk-2-1.pdf}

We put BAC as the response since it is more natural to predict BAC from the number of cans of beer consumed. Also notice that the number of cans of beers is really a discrete variable as we can only have whole numbers.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Describe the relationship between the number of cans of beer and BAC.
\end{enumerate}

The relationship appears to be strong, positive and linear. There is one potential outlier, the student who had 9 cans of beer. We will discuss outliers in the next lesson.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write the equation of the regression line. Interpret the slope and intercept in context.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bac_mod <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(bac}\OperatorTok{~}\NormalTok{beers,}\DataTypeTok{data=}\NormalTok{bac)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(bac_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = bac ~ beers, data = bac)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.027118 -0.017350  0.001773  0.008623  0.041027 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -0.012701   0.012638  -1.005    0.332    
## beers        0.017964   0.002402   7.480 2.97e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02044 on 14 degrees of freedom
## Multiple R-squared:  0.7998, Adjusted R-squared:  0.7855 
## F-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06
\end{verbatim}

\[\text{BAC} = -0.0127 + 0.0180 \times \text{beers} \]
Slope: For each additional can of beer consumed, the model predicts an additional 0.0180 grams per deciliter BAC on average.

Intercept: Students who don't have any beer are expected to have a blood alcohol content of -0.0127. This value could be interpreted as how much BAC drops in the time between drinking the beers and when BAC is measured. But it also could be that the intercept is really zero but our estimate is different because of variability in our estimator.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Do the data provide strong evidence that drinking more cans of beer is associated with an increase in blood alcohol? State the null and alternative hypotheses, report the p-value, and state your conclusion.
\end{enumerate}

\(H_0\): The true slope coefficient of number of beers is zero (\(\beta_1 = 0\)).\\
\(H_a\): The true slope coefficient of number of beers is greater than zero (\(\beta_1 > 0\)).

The p-value for the two-sided alternative hypothesis (\(\beta_1 \neq 0\)) is approximately 0. (Note that this output doesn't mean the p-value is exactly zero, only that when rounded to four decimal places it is zero.) Therefore the p-value for the one-sided hypothesis will also be very small, it is one half of the p-value reported in the \texttt{R} output. With such a small p-value, we reject \(H_0\) and conclude that the data provide convincing evidence that number of cans of beer consumed and blood alcohol content are positively correlated and the true slope parameter is indeed greater than 0.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Build a 95\% confidence interval for the slope and interpret it in the context of your hypothesis test from part d.~
\end{enumerate}

We need a lower confidence bound since the alternative is \(\beta_1 > 0\). For a 95\% lower confidence bound, we need at 90\% confidence interval and then just ignore the upper value.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{confint}\NormalTok{(bac_mod,}\DataTypeTok{level=}\FloatTok{0.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     5 %        95 %
## (Intercept) -0.03495916 0.009557957
## beers        0.01373362 0.022193906
\end{verbatim}

We are 95\% confident that the true value of the slope is greater than 0.014. This bound does not contain 0, so it appears that number of beers and BAC are linearly related in a positive direction. Notice the confidence interval for the intercept does include zero as we discussed above.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Suppose we visit a bar, ask people how many drinks they have had, and also take their BAC. Do you think the relationship between number of drinks and BAC would be as strong as the relationship found in the Ohio State study?
\end{enumerate}

It would probably be weaker. This study had people of very similar ages, and they also had identical drinks. In bars and elsewhere, drinks vary widely in the amount of alcohol they contain.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Predict the average BAC after two beers and build a 90\% confidence interval around that prediction.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new_bac <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{beers=}\DecValTok{2}\NormalTok{)}
\KeywordTok{predict}\NormalTok{(bac_mod, }\DataTypeTok{newdata =}\NormalTok{ new_bac, }\DataTypeTok{interval =} \StringTok{'confidence'}\NormalTok{,}\DataTypeTok{level=}\FloatTok{0.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          fit         lwr       upr
## 1 0.02322692 0.008308537 0.0381453
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Repeat except build a 90\% prediction interval and interpret.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(bac_mod, }\DataTypeTok{newdata =}\NormalTok{ new_bac, }\DataTypeTok{interval =} \StringTok{'prediction'}\NormalTok{,}\DataTypeTok{level=}\FloatTok{0.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          fit        lwr        upr
## 1 0.02322692 -0.0157444 0.06219824
\end{verbatim}

We are 90\% confident that the BAC of a student who has two beers will be between -.016 and 0.062. Notice that this interval contains an unrealistic level of BAC for the lower limit. If you were briefing this you would make sure to note this. This is because we are using a model based on the normal distribution. A bootstrap may not have this problem. If you truncate the lower level to 0, you have to be careful about claiming 90\% coverage.

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  Plot the data points with a regression line, confidence band, and prediction band.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bac }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_point}\NormalTok{(bac}\OperatorTok{~}\NormalTok{beers) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Number of cans of beers"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"BAC"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_lm}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"lm"}\NormalTok{,}\DataTypeTok{interval=}\StringTok{"confidence"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_lm}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"lm"}\NormalTok{,}\DataTypeTok{interval=}\StringTok{"prediction"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_refine}\NormalTok{(}\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{9}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{27-Regression-Inference-Solutions_files/figure-latex/unnamed-chunk-8-1.pdf}

\hypertarget{problem-3-18}{%
\subsection{Problem 3}\label{problem-3-18}}

\indent 3. Suppose I build a regression fitting a response variable to one predictor variable. I build a 95\% confidence interval on \(\beta_1\) and find that it contains 0, meaning that a slope of 0 is feasible. Does this mean that the response and the predictor are independent?

No.~It merely means that my best guess is that the two variables are \emph{linearly uncorrelated}. They could be related another way (quadratically, for example), but still result in an estimated slope close to 0.

\hypertarget{LRDIAG}{%
\chapter{Regression Diagnostics}\label{LRDIAG}}

\hypertarget{objectives-26}{%
\section{Objectives}\label{objectives-26}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Obtain and interpret \(R\)-squared and the \(F\)-statistic.\\
\item
  Use \texttt{R} to evaluate the assumptions of a linear model.\\
\item
  Identify and explain outliers and leverage points.
\end{enumerate}

\hypertarget{homework-27}{%
\section{Homework}\label{homework-27}}

\hypertarget{problem-1-27}{%
\subsection{Problem 1}\label{problem-1-27}}

\indent 1. Identify relationships

For each of the six plots, identify the strength of the relationship (e.g.~weak, moderate, or strong) in the data and whether fitting a linear model would be reasonable. When we ask about the strength of the relationship, we mean:

\begin{itemize}
\tightlist
\item
  is there a relationship between \(x\) and \(y\) and
\item
  does that relationship explain most of the variance?
\end{itemize}

\begin{figure}
\includegraphics[width=0.33\linewidth]{figures/association1} \includegraphics[width=0.33\linewidth]{figures/association2} \includegraphics[width=0.33\linewidth]{figures/association3} \includegraphics[width=0.33\linewidth]{figures/association4} \includegraphics[width=0.33\linewidth]{figures/association5} \includegraphics[width=0.33\linewidth]{figures/association6} \caption{Homework problem 1.}\label{fig:hw1}
\end{figure}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  Strong relationship, but a straight line would not fit the data.\\
\item
  Strong relationship, and a linear fit would be reasonable.\\
\item
  Weak relationship, and trying a linear fit would be reasonable.\\
\item
  Moderate relationship, but a straight line would not fit the data.\\
\item
  Strong relationship, and a linear fit would be reasonable.\\
\item
  Weak relationship because a change in \(x\) does not cause a change in \(y\) even though the points would cluster around a horizontal line. Trying a linear fit would be reasonable.
\end{enumerate}

\hypertarget{problem-2-25}{%
\subsection{Problem 2}\label{problem-2-25}}

\indent 2. Beer and blood alcohol content

We will use the blood alcohol content data again. As a reminder this is the description of the data: \emph{Many people believe that gender, weight, drinking habits, and many other factors are much more important in predicting blood alcohol content (BAC) than simply considering the number of drinks a person consumed. Here we examine data from sixteen student volunteers at Ohio State University who each drank a randomly assigned number of cans of beer. These students were evenly divided between men and women, and they differed in weight and drinking habits. Thirty minutes later, a police officer measured their blood alcohol content (BAC) in grams of alcohol per deciliter of blood.}

The data is in the \texttt{bac.csv} file under the \texttt{data} folder.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Obtain and interpret \(R\)-squared for this model.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bac<-}\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/bac.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bac }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_point}\NormalTok{(bac}\OperatorTok{~}\NormalTok{beers) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Number of cans of beer"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"BAC"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_refine}\NormalTok{(}\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{8}\NormalTok{,}\DecValTok{9}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{28-Regression-Diagnostics-Solutions_files/figure-latex/unnamed-chunk-2-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bac_mod <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(bac}\OperatorTok{~}\NormalTok{beers,}\DataTypeTok{data=}\NormalTok{bac)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(bac_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = bac ~ beers, data = bac)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.027118 -0.017350  0.001773  0.008623  0.041027 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -0.012701   0.012638  -1.005    0.332    
## beers        0.017964   0.002402   7.480 2.97e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.02044 on 14 degrees of freedom
## Multiple R-squared:  0.7998, Adjusted R-squared:  0.7855 
## F-statistic: 55.94 on 1 and 14 DF,  p-value: 2.969e-06
\end{verbatim}

The \(R\)-squared is 0.7998, this means that almost 80\% of the variance in blood alcohol content is explained by the number of beers consumed. This is not surprising. The remaining variance may be due to measurement errors, differences in the students, and environmental impacts.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Evaluate the assumptions of this model. Do we have anything to be concerned about?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bac_mod,}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{28-Regression-Diagnostics-Solutions_files/figure-latex/unnamed-chunk-5-1.pdf}

The fit is pretty good, there is one data point that is an outlier, the student that drank 9 beers.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bac_mod,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{28-Regression-Diagnostics-Solutions_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bac}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 16 x 3
##    student beers   bac
##      <int> <int> <dbl>
##  1       1     5 0.1  
##  2       2     2 0.03 
##  3       3     9 0.19 
##  4       4     8 0.12 
##  5       5     3 0.04 
##  6       6     7 0.095
##  7       7     3 0.07 
##  8       8     5 0.06 
##  9       9     3 0.02 
## 10      10     5 0.05 
## 11      11     4 0.07 
## 12      12     6 0.1  
## 13      13     5 0.085
## 14      14     7 0.09 
## 15      15     1 0.01 
## 16      16     4 0.05
\end{verbatim}

The 3rd, 7th, and 10th data points stand out. This data set is too small to make any decisions about normality. It is suspect though.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bac_mod,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{28-Regression-Diagnostics-Solutions_files/figure-latex/unnamed-chunk-8-1.pdf}

We have higher variance at the higher number of beers. Again this appears to be caused by the small number of data points and the influence of observation number 3.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bac_mod,}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{28-Regression-Diagnostics-Solutions_files/figure-latex/unnamed-chunk-9-1.pdf}

The points we're looking for(or not looking for) are values in the upper right or lower right corners, which are outside the red dashed Cook's distance line. These are points that would be influential in the model and removing them would likely noticeably alter the regression results. Now we see that observation 3 has extreme leverage on the model. Removing it would potentially drastically alter the model.

To learn more about measures of influence, see \url{https://cran.r-project.org/web/packages/olsrr/vignettes/influence_measures.html}

\hypertarget{problem-3-19}{%
\subsection{Problem 3}\label{problem-3-19}}

\indent 3. Outliers

Identify the outliers in the scatterplots shown below and determine what type of outliers they are. Explain your reasoning. The labels are off so treat the bottom row as (d), (e), and (f).

\begin{figure}
\includegraphics[width=0.33\linewidth]{figures/outInf1} \includegraphics[width=0.33\linewidth]{figures/outLev1} \includegraphics[width=0.33\linewidth]{figures/outOut1} \includegraphics[width=0.33\linewidth]{figures/outInf2} \includegraphics[width=0.33\linewidth]{figures/outInf3} \includegraphics[width=0.33\linewidth]{figures/outOut2} \caption{Homework problem 3.}\label{fig:hw3}
\end{figure}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  The outlier is located in the bottom right corner of the plot. If we were to exclude this point from the analysis, the slope of the regression line would be notably affected, which means this is a high-leverage and influential point.\\
\item
  The outlier is located in the bottom right corner of the plot. It is a point with high leverage since it is horizontally away from the center of the data, but it is not influential since the regression line would change little if it was removed. It is also an outlier in the response but would have a small residual.\\
\item
  The outlier is located in the center and top of the plot. Though the point is unlike the rest of the data, it is not a high-leverage point since it is not far on the x-axis from the center of the data. This also means it is not an influential point since its presence has little influence on the slope of the regression line.\\
\item
  The outlier is in the upper-left corner. Since it is horizontally far from the center of the data, it is an high leverage point. Additionally, since the fit of the regression line is greatly influenced by this point, it is a influential point.\\
\item
  The outlier is located in the lower-left corner. It is horizontally far from the rest of the data, so it is a high-leverage point. The regression line also would fall relatively far from this point if the fit excluded this point, meaning the outlier is influential.\\
\item
  The outlier is in the upper-middle of the plot. Since it is near the horizontal center of the data, it is not a high-leverage point. This means it also will have little or no influence on the slope of the regression line.
\end{enumerate}

\hypertarget{LRSIM}{%
\chapter{Simulation Based Linear Regression}\label{LRSIM}}

\hypertarget{objectives-27}{%
\section{Objectives}\label{objectives-27}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Using the bootstrap, generate confidence and estimates of standard error for parameter estimates from a linear regression model.\\
\item
  Generate and interpret bootstrap confidence intervals for predicted values.\\
\item
  Generate bootstrap samples from sampling rows of the data or sampling residuals. Explain why you might prefer one over the other.\\
\item
  Interpret regression coefficients for a linear model with a categorical explanatory variable.
\end{enumerate}

\hypertarget{homework-28}{%
\section{Homework}\label{homework-28}}

We will use the loans data set again to create linear models. Remember this data set represents thousands of loans made through the Lending Club platform, which is a platform that allows individuals to lend to other individuals.

\hypertarget{problem-1-28}{%
\subsection{Problem 1}\label{problem-1-28}}

\indent 1. Loans

In this exercise we will examine the relationship between interest rate and loan amount.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Read in the data from \texttt{loans.csv} in the \texttt{data} folder.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loans <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/loans.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a subset of data with 200 with the following three variables \texttt{interest\_rate}, \texttt{loan\_amount}, and \texttt{term}. Change \texttt{term} into a factor and use a stratified sample to keep the proportion of loan term roughly the same as the original data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{term,}\DataTypeTok{data=}\NormalTok{loans,}\DataTypeTok{format=}\StringTok{"percent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## term
##   36   60 
## 69.7 30.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2111}\NormalTok{)}
\NormalTok{loans200 <-}\StringTok{ }\NormalTok{loans }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(interest_rate,loan_amount,term) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{term=}\KeywordTok{factor}\NormalTok{(term)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(term) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{slice_sample}\NormalTok{(}\DataTypeTok{prop=}\FloatTok{0.02}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tally}\NormalTok{(}\OperatorTok{~}\NormalTok{term,}\DataTypeTok{data=}\NormalTok{loans200,}\DataTypeTok{format=}\StringTok{"percent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## term
##       36       60 
## 69.84925 30.15075
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(loans200)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [199 x 3] (S3: tbl_df/tbl/data.frame)
##  $ interest_rate: num [1:199] 13.59 9.92 17.47 10.9 7.34 ...
##  $ loan_amount  : num [1:199] 13000 10000 10000 8400 4800 10000 6000 6300 10000 32000 ...
##  $ term         : Factor w/ 2 levels "36","60": 1 1 1 1 1 1 1 1 1 1 ...
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Plot \texttt{interest\_rate} versus \texttt{loan\_amount}. We think \texttt{interest\_rate} should be the response.
\end{enumerate}

It seems natural that you would want to predict interest rate from loan amount.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(loans200,}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{loan_amount,}\DataTypeTok{y=}\NormalTok{interest_rate)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Lending Club"}\NormalTok{,}\DataTypeTok{subtitle=}\StringTok{"Loan amount versus Interest rate"}\NormalTok{,}
       \DataTypeTok{x=}\StringTok{"Loan Amount"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Interest rate (percent)"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Fit a linear model to the data by regressing \texttt{interest\_rate} on \texttt{loan\_amount}. Is there a significant relationship between \texttt{interest\_rate} and \texttt{loan\_amount}?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{int_rate_mod <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(interest_rate}\OperatorTok{~}\NormalTok{loan_amount,}\DataTypeTok{data=}\NormalTok{loans200)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(int_rate_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = interest_rate ~ loan_amount, data = loans200)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.1611 -4.6842 -0.9666  3.0685 18.6280 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 1.165e+01  7.337e-01  15.874   <2e-16 ***
## loan_amount 2.748e-05  3.722e-05   0.738    0.461    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 5.423 on 197 degrees of freedom
## Multiple R-squared:  0.002759,   Adjusted R-squared:  -0.002303 
## F-statistic: 0.545 on 1 and 197 DF,  p-value: 0.4613
\end{verbatim}

To test if there a significant relationship between \texttt{interest\_rate} and \texttt{loan\_amount}, we test if \(\beta_1 = 0\). The p-value for this is 0.4613, so we fail to reject that there is no relationship between \texttt{interest\_rate} and \texttt{loan\_amount}.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Using the \(t\) distribution:

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    Find a 95\% confidence interval for the slope.\\
  \item
    Find and interpret a 90\% confidence interval for a loan amount of \$20000.
  \end{enumerate}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{confint}\NormalTok{(int_rate_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     2.5 %       97.5 %
## (Intercept)  1.019986e+01 1.309374e+01
## loan_amount -4.592357e-05 1.008748e-04
\end{verbatim}

We are 95\% confident the true slope is between -4.592357e-05 and 1.008748e-04.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(int_rate_mod,}\DataTypeTok{newdata =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{loan_amount=}\DecValTok{20000}\NormalTok{),}
        \DataTypeTok{interval =} \StringTok{"confidence"}\NormalTok{,}\DataTypeTok{level=}\FloatTok{0.90}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr      upr
## 1 12.19631 11.53105 12.86157
\end{verbatim}

We are 90\% confident that the average interest rate for a loan of \$20000 is between 11.5\% and 12.9\%.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Repeat part e using a bootstrap.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{3011}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{lm}\NormalTok{(interest_rate }\OperatorTok{~}\StringTok{ }\NormalTok{loan_amount,}\DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(loans200))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Intercept   loan_amount    sigma    r.squared          F numdf dendf .row
## 1  10.26651  6.837311e-05 4.893962 0.0184148594 3.69578466     1   197    1
## 2  11.63858  2.341492e-05 5.147715 0.0021348812 0.42147139     1   197    1
## 3  12.52116  6.096805e-06 5.138114 0.0001537970 0.03030266     1   197    1
## 4  11.93790 -6.489195e-06 5.284324 0.0001655171 0.03261227     1   197    1
## 5  11.38254  9.000912e-05 5.472851 0.0281911082 5.71475355     1   197    1
## 6  12.35924 -2.568690e-05 5.520788 0.0025489432 0.50342501     1   197    1
##   .index
## 1      1
## 2      2
## 3      3
## 4      4
## 5      5
## 6      6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{loan_amount,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              lower        upper central.p
## 2.5% -4.277717e-05 9.863203e-05      0.95
\end{verbatim}

Or using the \texttt{infer} package:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results2 <-}\StringTok{ }\NormalTok{loans200 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{specify}\NormalTok{(interest_rate}\OperatorTok{~}\NormalTok{loan_amount) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{generate}\NormalTok{(}\DataTypeTok{reps=}\DecValTok{1000}\NormalTok{,}\DataTypeTok{type=}\StringTok{"bootstrap"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{calculate}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"slope"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(results2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   replicate        stat
##       <int>       <dbl>
## 1         1 -0.0000114 
## 2         2  0.0000198 
## 3         3  0.0000207 
## 4         4  0.00000481
## 5         5  0.0000549 
## 6         6  0.0000531
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{get_confidence_interval}\NormalTok{(results2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Using `level = 0.95` to compute confidence interval.
\end{verbatim}

\begin{verbatim}
## # A tibble: 1 x 2
##     lower_ci  upper_ci
##        <dbl>     <dbl>
## 1 -0.0000361 0.0000947
\end{verbatim}

Now the confidence interval for average interest rate at a loan amount of 20000:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred=}\NormalTok{Intercept}\OperatorTok{+}\NormalTok{loan_amount}\OperatorTok{*}\DecValTok{20000}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{pred,}\DataTypeTok{data=}\NormalTok{.)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        lower    upper central.p
## 2.5% 11.4061 13.01508      0.95
\end{verbatim}

Again, close to what we had but slightly different. Maybe some of the assumptions such as normality are not appropriate.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Check the assumptions of linear regression.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(int_rate_mod)}
\end{Highlighting}
\end{Shaded}

\includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-16-1.pdf} \includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-16-2.pdf} \includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-16-3.pdf} \includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-16-4.pdf}

There appears to be a lack of normality as the residuals are skewed to the right, large positive residuals. The bootstrap would probably be more appropriate for this problem.

\hypertarget{problem-2-26}{%
\subsection{Problem 2}\label{problem-2-26}}

\indent 2. Loans II

Using the \texttt{loans} data set of 200 observations from the previous exercise, use the variable \texttt{term} to determine if there is a difference in interest rates for the two different loan lengths.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Build a set of side-by-side boxplots that summarize interest rate by term. Describe the relationship you see. Note: You will have to convert the \texttt{term} variable to a factor prior to continuing.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loans200 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(interest_rate}\OperatorTok{~}\NormalTok{term) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Lending Club"}\NormalTok{,}\DataTypeTok{x=}\StringTok{"Length of Loan"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Interest Rate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-17-1.pdf}

It looks like there is a difference in interest rate based on the length of the loan. It also appears both are skewed to the right, positive skew. Let's plot the density and see what we find.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loans200 }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_dens}\NormalTok{(}\OperatorTok{~}\NormalTok{interest_rate,}\DataTypeTok{group=}\OperatorTok{~}\NormalTok{term,}\DataTypeTok{color=}\OperatorTok{~}\NormalTok{term) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_classic}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Lending Club"}\NormalTok{,}\DataTypeTok{x=}\StringTok{"Interest Rate"}\NormalTok{,}\DataTypeTok{y=}\StringTok{"Density"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-18-1.pdf}

Just as we thought.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Build a linear model fitting interest rate against term. Does there appear to be a significant difference in mean interest rates by term?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{int_rate_mod2 <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(interest_rate}\OperatorTok{~}\NormalTok{term,}\DataTypeTok{data=}\NormalTok{loans200)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(int_rate_mod2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = interest_rate ~ term, data = loans200)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -8.643 -3.993 -1.263  3.132 15.597 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  10.7031     0.4230  25.304  < 2e-16 ***
## term60        4.6601     0.7703   6.049 7.19e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 4.987 on 197 degrees of freedom
## Multiple R-squared:  0.1567, Adjusted R-squared:  0.1524 
## F-statistic:  36.6 on 1 and 197 DF,  p-value: 7.189e-09
\end{verbatim}

There is a significant difference between the average interest rate based on the length of the loan.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write out the estimated linear model. In words, interpret the coefficient estimate.
\end{enumerate}

The intercept \(\beta_\text{Intercept} = \mu_\text{term36}\) is the average interest rate for a 36 month loan. And \(\beta_\text{term60} = \mu_\text{term60} - \mu_\text{term36}\) is the difference in average interest rates between loan length. In this case, a 60 month loan is 4.66 percentage points higher on average than a 36 month loan.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Construct a bootstrap confidence interval on the coefficient.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{331}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{lm}\NormalTok{(interest_rate }\OperatorTok{~}\StringTok{ }\NormalTok{term,}\DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(loans200))}
\KeywordTok{head}\NormalTok{(results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Intercept   term60    sigma  r.squared        F numdf dendf .row .index
## 1  10.11890 4.903166 4.534598 0.20352136 50.33871     1   197    1      1
## 2  10.91695 5.275981 5.220399 0.17564679 41.97523     1   197    1      2
## 3  11.07592 4.064085 5.226607 0.11097921 24.59212     1   197    1      3
## 4  11.14948 3.675445 5.250290 0.09818999 21.44956     1   197    1      4
## 5  10.45978 4.941671 4.960234 0.17698753 42.36454     1   197    1      5
## 6  11.02597 4.232862 4.891180 0.13743012 31.38729     1   197    1      6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{term60,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         lower    upper central.p
## 2.5% 3.029483 6.242261      0.95
\end{verbatim}

We are 95\% confident the difference in average interest rates for loans of 60 month and 36 month is between 3.03\% and 6.24\%.

Let's check using the assumption of normally distributed errors.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{confint}\NormalTok{(int_rate_mod2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                2.5 %    97.5 %
## (Intercept) 9.868936 11.537251
## term60      3.140928  6.179218
\end{verbatim}

Close, but slightly narrower.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Check model assumptions.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(int_rate_mod2)}
\end{Highlighting}
\end{Shaded}

\includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-24-1.pdf} \includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-24-2.pdf} \includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-24-3.pdf} \includegraphics{29-Simulation-Based-Regression-Solutions_files/figure-latex/unnamed-chunk-24-4.pdf}

Because of the discrete nature of the predictor, only the first two plots are of interest. The assumption of constant variable does seem reasonable but the assumption of normally distributed errors is not. We have a positive skewness.

\hypertarget{LRMULTI}{%
\chapter{Multiple Linear Regression}\label{LRMULTI}}

\hypertarget{objectives-28}{%
\section{Objectives}\label{objectives-28}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Create and interpret a model with multiple predictors and check assumptions.\\
\item
  Generate and interpret confidence intervals for estimates.\\
\item
  Explain adjusted \(R^2\) and multi-collinearity.\\
\item
  Interpret regression coefficients for a linear model with multiple predictors.\\
\item
  Build and interpret models with higher order terms.
\end{enumerate}

\hypertarget{homework-29}{%
\section{Homework}\label{homework-29}}

\hypertarget{problem-1-29}{%
\subsection{Problem 1}\label{problem-1-29}}

\indent 1. The \texttt{mtcars} dataset contains average mileage (mpg) and other information about specific makes and models of cars. (This dataset is built-in to \texttt{R}; for more information about this dataset, reference the documentation with \texttt{?mtcars}).

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Build and interpret the coefficients of a model fitting \texttt{mpg} against displacement (\texttt{disp}), horsepower (\texttt{hp}), rear axle ratio (\texttt{drat}), and weight in 1000 lbs (\texttt{wt}).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cars_mod<-}\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{disp}\OperatorTok{+}\NormalTok{hp}\OperatorTok{+}\NormalTok{drat}\OperatorTok{+}\NormalTok{wt,}\DataTypeTok{data=}\NormalTok{mtcars)}
\KeywordTok{summary}\NormalTok{(cars_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = mpg ~ disp + hp + drat + wt, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.5077 -1.9052 -0.5057  0.9821  5.6883 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 29.148738   6.293588   4.631  8.2e-05 ***
## disp         0.003815   0.010805   0.353  0.72675    
## hp          -0.034784   0.011597  -2.999  0.00576 ** 
## drat         1.768049   1.319779   1.340  0.19153    
## wt          -3.479668   1.078371  -3.227  0.00327 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.602 on 27 degrees of freedom
## Multiple R-squared:  0.8376, Adjusted R-squared:  0.8136 
## F-statistic: 34.82 on 4 and 27 DF,  p-value: 2.704e-10
\end{verbatim}

\[
\mbox{E}(\text{mpg})=29.15+0.004*\text{disp}-0.035*\text{hp}+1.768*\text{drat}-3.480*\text{wt}
\]

Each coefficient represents the expected increase in \texttt{mpg} for a unit increase in the respective variable, leaving all other variables constant.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Given your model, what is the expected, average, mpg for a vehicle with a displacement of 170, a horsepower of 100, a \texttt{drat} of 3.80 and a wt of 2,900 lbs. Construct a 95\% confidence interval and prediction interval for that expected mpg.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(cars_mod,}\DataTypeTok{newdata=}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{disp=}\DecValTok{170}\NormalTok{,}\DataTypeTok{hp=}\DecValTok{100}\NormalTok{,}\DataTypeTok{drat=}\FloatTok{3.8}\NormalTok{,}\DataTypeTok{wt=}\FloatTok{2.9}\NormalTok{),}\DataTypeTok{interval=}\StringTok{"confidence"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr      upr
## 1 22.94652 21.76569 24.12735
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(cars_mod,}\DataTypeTok{newdata=}\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{disp=}\DecValTok{170}\NormalTok{,}\DataTypeTok{hp=}\DecValTok{100}\NormalTok{,}\DataTypeTok{drat=}\FloatTok{3.8}\NormalTok{,}\DataTypeTok{wt=}\FloatTok{2.9}\NormalTok{),}\DataTypeTok{interval=}\StringTok{"prediction"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr      upr
## 1 22.94652 17.47811 28.41494
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Repeat part (b) with a bootstrap for the confidence interval.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{732}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{disp}\OperatorTok{+}\NormalTok{hp}\OperatorTok{+}\NormalTok{drat}\OperatorTok{+}\NormalTok{wt,}\DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(mtcars))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Intercept          disp          hp      drat        wt    sigma r.squared
## 1  20.28185 -0.0017783926 -0.02620557 2.8897199 -2.016023 2.300320 0.8210210
## 2  33.66818 -0.0128734640 -0.01960700 0.3309526 -2.862143 2.102123 0.8760470
## 3  25.54583 -0.0001983653 -0.03743247 2.1905290 -2.392723 2.814197 0.7947977
## 4  33.22436  0.0112562822 -0.04151242 1.4796584 -4.557451 2.699223 0.8523512
## 5  25.96975 -0.0002882344 -0.03093247 2.3689688 -2.861715 2.670069 0.8643060
## 6  34.17742  0.0054509451 -0.04085537 0.9019272 -3.975107 2.562486 0.8377108
##          F numdf dendf .row .index
## 1 30.96393     4    27    1      1
## 2 47.70611     4    27    1      2
## 3 26.14436     4    27    1      3
## 4 38.96659     4    27    1      4
## 5 42.99429     4    27    1      5
## 6 34.84241     4    27    1      6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred=}\NormalTok{Intercept}\OperatorTok{+}\NormalTok{disp}\OperatorTok{*}\DecValTok{170}\OperatorTok{+}\NormalTok{hp}\OperatorTok{*}\DecValTok{100}\OperatorTok{+}\NormalTok{drat}\OperatorTok{*}\FloatTok{3.8}\OperatorTok{+}\NormalTok{wt}\OperatorTok{*}\FloatTok{2.9}\NormalTok{) }\OperatorTok{%>%}
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{pred,}\DataTypeTok{data=}\NormalTok{.)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         lower    upper central.p
## 2.5% 21.76703 24.15803      0.95
\end{verbatim}

\hypertarget{problem-2-27}{%
\subsection{Problem 2}\label{problem-2-27}}

\indent 2. Is that the best model for predicting mpg? Try a variety of different models. You could explore higher order terms or even interactions. One place to start is by using the \texttt{pairs()} function on \texttt{mtcars} to plot a large pairwise scatterplot. How high could you get adjusted \(R\)-squared? Keep in mind that is only one measure of fit.

Answers will vary, but we tried this and got 0.8694.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(}\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{disp}\OperatorTok{+}\KeywordTok{I}\NormalTok{(disp}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\NormalTok{hp}\OperatorTok{+}\KeywordTok{I}\NormalTok{(hp}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\NormalTok{wt,}\DataTypeTok{data=}\NormalTok{mtcars))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = mpg ~ disp + I(disp^2) + hp + I(hp^2) + wt, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1591 -1.4907 -0.3903  1.5851  3.7795 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  4.440e+01  2.639e+00  16.823 1.71e-15 ***
## disp        -4.532e-02  2.131e-02  -2.127 0.043100 *  
## I(disp^2)    8.844e-05  3.315e-05   2.668 0.012967 *  
## hp          -8.652e-02  3.813e-02  -2.269 0.031813 *  
## I(hp^2)      1.585e-04  8.932e-05   1.775 0.087666 .  
## wt          -3.517e+00  8.874e-01  -3.963 0.000515 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.178 on 26 degrees of freedom
## Multiple R-squared:  0.8904, Adjusted R-squared:  0.8694 
## F-statistic: 42.26 on 5 and 26 DF,  p-value: 1.129e-11
\end{verbatim}

\hypertarget{LOGREG}{%
\chapter{Logistic Regression}\label{LOGREG}}

\hypertarget{objectives-29}{%
\section{Objectives}\label{objectives-29}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Using \texttt{R}, conduct logistic regression and interpret the output and perform model selection.\\
\item
  Write the logistic regression model and predict outputs for given inputs.\\
\item
  Use the bootstrap to find confidence intervals for parameter estimates and predictions.
\end{enumerate}

\hypertarget{homework-problems}{%
\section{Homework Problems}\label{homework-problems}}

\hypertarget{problem-1-30}{%
\subsection{Problem 1}\label{problem-1-30}}

\indent 1. Possum classification

Let's investigate the \texttt{possum} data set again. This time we want to model a binary outcome variable. As a reminder, the common brushtail possum of the Australia region is a bit cuter than its distant cousin, the American opossum. We consider 104 brushtail possums from two regions in Australia, where the possums may be considered a random sample from the population. The first region is Victoria, which is in the eastern half of Australia and traverses the southern coast. The second region consists of New South Wales and Queensland, which make up eastern and northeastern Australia.

We use logistic regression to differentiate between possums in these two regions. The outcome variable, called \texttt{pop}, takes value \texttt{Vic} when a possum is from Victoria and \texttt{other} when it is from New South Wales or Queensland. We consider five predictors: \texttt{sex}, \texttt{head\_l}, \texttt{skull\_w}, \texttt{total\_l}, and \texttt{tail\_l}.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Explore the data by making histograms of the quantitative variables, and bar charts of the discrete variables. Are there any outliers that are likely to have a very large influence on the logistic regression model?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/possum.csv"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(pop,sex,head_l,skull_w,total_l,tail_l) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pop=}\KeywordTok{factor}\NormalTok{(pop),}\DataTypeTok{sex=}\KeywordTok{factor}\NormalTok{(sex))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inspect}\NormalTok{(possum)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## categorical variables:  
##   name  class levels   n missing                                  distribution
## 1  pop factor      2 104       0 other (55.8%), Vic (44.2%)                   
## 2  sex factor      2 104       0 m (58.7%), f (41.3%)                         
## 
## quantitative variables:  
##         name   class  min     Q1 median     Q3   max     mean       sd   n
## ...1  head_l numeric 82.5 90.675  92.80 94.725 103.1 92.60288 3.573349 104
## ...2 skull_w numeric 50.0 54.975  56.35 58.100  68.6 56.88365 3.113426 104
## ...3 total_l numeric 75.0 84.000  88.00 90.000  96.5 87.08846 4.310549 104
## ...4  tail_l numeric 32.0 35.875  37.00 38.000  43.0 37.00962 1.959518 104
##      missing
## ...1       0
## ...2       0
## ...3       0
## ...4       0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_props}\NormalTok{(}\OperatorTok{~}\NormalTok{pop,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Population"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-3-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_props}\NormalTok{(}\OperatorTok{~}\NormalTok{sex,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color=}\StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{x=}\StringTok{"Gender"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-4-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(}\OperatorTok{~}\NormalTok{head_l) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(}\OperatorTok{~}\NormalTok{skull_w) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(}\OperatorTok{~}\NormalTok{total_l) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_boxplot}\NormalTok{(}\OperatorTok{~}\NormalTok{tail_l) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-8-1.pdf}

There are some potential outliers for skull width but otherwise not much concern.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pairs}\NormalTok{(possum[,}\DecValTok{3}\OperatorTok{:}\DecValTok{6}\NormalTok{],}\DataTypeTok{lower.panel =}\NormalTok{ panel.smooth)}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-9-1.pdf}
We can see that \texttt{head\_l} is correlated with the other three variables. This will cause some multicollinearity problems.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Build a logistic regression model with all the variable. Report a summary of the model.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum_mod <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(pop}\OperatorTok{==}\StringTok{"Vic"}\OperatorTok{~}\NormalTok{.,}\DataTypeTok{data=}\NormalTok{possum,}\DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(possum_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = pop == "Vic" ~ ., family = "binomial", data = possum)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6430  -0.5514  -0.1182   0.3760   2.8501  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  39.2349    11.5368   3.401 0.000672 ***
## sexm         -1.2376     0.6662  -1.858 0.063195 .  
## head_l       -0.1601     0.1386  -1.155 0.248002    
## skull_w      -0.2012     0.1327  -1.517 0.129380    
## total_l       0.6488     0.1531   4.236 2.27e-05 ***
## tail_l       -1.8708     0.3741  -5.001 5.71e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 142.787  on 103  degrees of freedom
## Residual deviance:  72.155  on  98  degrees of freedom
## AIC: 84.155
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{confint}\NormalTok{(possum_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Waiting for profiling to be done...
\end{verbatim}

\begin{verbatim}
##                  2.5 %      97.5 %
## (Intercept) 18.8530781 64.66444839
## sexm        -2.6227018  0.02472167
## head_l      -0.4428559  0.10865739
## skull_w     -0.4933140  0.04479826
## total_l      0.3768179  0.98455786
## tail_l      -2.7170468 -1.23231969
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Using the p-values decide if you want to remove a variable(S) and if so build that model.
\end{enumerate}

Let's remove \texttt{head\_l} first.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{possum_mod_red <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(pop}\OperatorTok{==}\StringTok{"Vic"}\OperatorTok{~}\NormalTok{sex}\OperatorTok{+}\NormalTok{skull_w}\OperatorTok{+}\NormalTok{total_l}\OperatorTok{+}\NormalTok{tail_l,}\DataTypeTok{data=}\NormalTok{possum,}\DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(possum_mod_red)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = pop == "Vic" ~ sex + skull_w + total_l + tail_l, 
##     family = "binomial", data = possum)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8102  -0.5683  -0.1222   0.4153   2.7599  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  33.5095     9.9053   3.383 0.000717 ***
## sexm         -1.4207     0.6457  -2.200 0.027790 *  
## skull_w      -0.2787     0.1226  -2.273 0.023053 *  
## total_l       0.5687     0.1322   4.302 1.69e-05 ***
## tail_l       -1.8057     0.3599  -5.016 5.26e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 142.787  on 103  degrees of freedom
## Residual deviance:  73.516  on  99  degrees of freedom
## AIC: 83.516
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

Since \texttt{head\_l} was correlated with the other variables, removing it has increased the precision, decreased the standard error, of the other predictors. There p-values are all now less than 0.05.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  For any variable you decide to remove, build a 95\% confidence interval for the parameter.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{confint}\NormalTok{(possum_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Waiting for profiling to be done...
\end{verbatim}

\begin{verbatim}
##                  2.5 %      97.5 %
## (Intercept) 18.8530781 64.66444839
## sexm        -2.6227018  0.02472167
## head_l      -0.4428559  0.10865739
## skull_w     -0.4933140  0.04479826
## total_l      0.3768179  0.98455786
## tail_l      -2.7170468 -1.23231969
\end{verbatim}

We are 95\% confident that the true slope coefficient for \texttt{head\_l} is between -0.44 and 0.108.

The bootstrap is not working for this problem. It may be that we have convergence issues when we resample the data. This is a reminder that we need to be careful and not just run methods without checking results. Here is the code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{952}\NormalTok{)}
\NormalTok{results<-}\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{glm}\NormalTok{(pop}\OperatorTok{==}\StringTok{"Vic"}\OperatorTok{~}\NormalTok{.,}\DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(possum),}\DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(results[,}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     Intercept          sexm        head_l       skull_w       total_l
## 1 -1184.61875  2.122389e+01  3.861561e+00  2.749263e+00  7.274005e+00
## 2  6371.55550 -1.301514e+02  1.023732e+01 -2.738816e+01 -1.076913e+01
## 3 -9612.61941 -2.392900e+03 -1.875252e+02  5.782027e+02 -2.820691e+02
## 4   -25.18662 -1.852185e+01  2.097593e+01 -1.353619e+01  1.483815e+01
## 5   -26.56607 -1.398995e-14 -2.258909e-14  6.528545e-15  2.388756e-14
## 6 -1025.00035  6.159665e+01  2.526181e+01 -2.032143e+01  1.438639e+01
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{head_l,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color =} \StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Bootstrap sampling distribtuion"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"sex paramater estimate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-18-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{head_l,}\DataTypeTok{data=}\NormalTok{results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          lower    upper central.p
## 2.5% -122.7029 63.61867      0.95
\end{verbatim}

This interval is too large. The resampling process has too much variation in it. This could be due to the small sample size and the multicollinearity.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Explain why the remaining parameter estimates change between the two models.
\end{enumerate}

When coefficient estimates are sensitive to which variables are included in the model, this typically indicates that some variables are collinear. For example, a possum's gender may be related to its head length, which would explain why the coefficient (and p-value) for sex male changed when we removed the head length variable. Likewise, a possum's skull width is likely to be related to its head length, probably even much more closely related than the head length was to gender.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Write out the form of the model. Also identify which of the following variables are positively associated (when controlling for other variables) with a possum being from Victoria: \texttt{head\_l}, \texttt{skull\_w}, \texttt{total\_l}, and \texttt{tail\_l}.
\end{enumerate}

We dropped \texttt{head\_l} from the model. Here is the equation:

\[
\log_{e}\left( \frac{p_i}{1-p_i} \right)
    = 33.5 - 1.42 \text{ sex} -0.28 \text{ skull width}  + 0.57 \text{ total length} - 1.81 \text{ tail length}
\]

Only \texttt{total\_l} is positively association with the probability of being from Victoria.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Suppose we see a brushtail possum at a zoo in the US, and a sign says the possum had been captured in the wild in Australia, but it doesn't say which part of Australia. However, the sign does indicate that the possum is male, its skull is about 63 mm wide, its tail is 37 cm long, and its total length is 83 cm. What is the reduced model's computed probability that this possum is from Victoria? How confident are you in the model's accuracy of this probability calculation?
\end{enumerate}

Let's predict the outcome. We use \texttt{response} for the type to put the answer in the form of a probability. See the help menu on \texttt{predict.glm} for more information.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(possum_mod_red,}\DataTypeTok{newdata =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{sex=}\StringTok{"m"}\NormalTok{,}\DataTypeTok{skull_w=}\DecValTok{63}\NormalTok{,}\DataTypeTok{tail_l=}\DecValTok{37}\NormalTok{,}\DataTypeTok{total_l=}\DecValTok{83}\NormalTok{),}
        \DataTypeTok{type=}\StringTok{"response"}\NormalTok{,}\DataTypeTok{se.fit =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $fit
##           1 
## 0.006205055 
## 
## $se.fit
##           1 
## 0.008011468 
## 
## $residual.scale
## [1] 1
\end{verbatim}

While the probability, 0.006, is very near zero, we have not run diagnostics on the model. We should also have a little skepticism that the model will hold for a possum found in a US zoo. However, it is encouraging that the possum was caught in the wild.

As a rough sense of the accuracy, we will use the standard error. The errors are really binomial but we are trying to use a normal approximation. If you remember back to our block on probability, with such a low probability, this assumption of normality is suspect. However, we will use it to give us an upper bound.

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.0062}\OperatorTok{+}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\FloatTok{1.96}\OperatorTok{*}\NormalTok{.}\DecValTok{008}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.00948  0.02188
\end{verbatim}

So at most, the probability of the possum being from Victoria is 2\%.

\hypertarget{problem-2-28}{%
\subsection{Problem 2}\label{problem-2-28}}

\indent 2. Medical school admission

The file \texttt{MedGPA.csv} in the \texttt{data} folder has information on medical school admission status and GPA and standardized test scores gathered on 55 medical school applicants from a liberal arts college in the Midwest.

The variables are:

\texttt{Accept\ Status}: A=accepted to medical school or D=denied admission
\texttt{Acceptance}: Indicator for Accept: 1=accepted or 0=denied\\
\texttt{Sex}: F=female or M=male\\
\texttt{BCPM}: Bio/Chem/Physics/Math grade point average\\
\texttt{GPA}: College grade point average\\
\texttt{VR}: Verbal reasoning (subscore)\\
\texttt{PS}: Physical sciences (subscore)\\
\texttt{WS}: Writing sample (subcore)\\
\texttt{BS}: Biological sciences (subscore)\\
\texttt{MCAT}: Score on the MCAT exam (sum of CR+PS+WS+BS)\\
\texttt{Apps}: Number of medical schools applied to

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Build a logistic regression model to predict \texttt{Acceptance} from \texttt{GPA} and `Sex.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MedGPA <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/MedGPA.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(MedGPA)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 55
## Columns: 11
## $ Accept     <chr> "D", "A", "A", "A", "A", "A", "A", "D", "A", "A", "A", "...
## $ Acceptance <dbl> 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,...
## $ Sex        <chr> "F", "M", "F", "F", "F", "M", "M", "M", "F", "F", "F", "...
## $ BCPM       <dbl> 3.59, 3.75, 3.24, 3.74, 3.53, 3.59, 3.85, 3.26, 3.74, 3....
## $ GPA        <dbl> 3.62, 3.84, 3.23, 3.69, 3.38, 3.72, 3.89, 3.34, 3.71, 3....
## $ VR         <dbl> 11, 12, 9, 12, 9, 10, 11, 11, 8, 9, 11, 11, 8, 9, 11, 12...
## $ PS         <dbl> 9, 13, 10, 11, 11, 9, 12, 11, 10, 9, 9, 8, 10, 9, 8, 8, ...
## $ WS         <dbl> 9, 8, 5, 7, 4, 7, 6, 8, 6, 6, 8, 4, 7, 4, 6, 8, 8, 9, 5,...
## $ BS         <dbl> 9, 12, 9, 10, 11, 10, 11, 9, 11, 10, 11, 8, 10, 10, 7, 1...
## $ MCAT       <dbl> 38, 45, 33, 40, 35, 36, 40, 39, 35, 34, 39, 31, 35, 32, ...
## $ Apps       <dbl> 5, 3, 19, 5, 11, 5, 5, 7, 5, 11, 6, 9, 5, 8, 15, 6, 6, 1...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{med_mod<-}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{GPA}\OperatorTok{+}\NormalTok{Sex,}\DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(med_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = Accept == "D" ~ GPA + Sex, family = binomial, data = MedGPA)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.4623  -0.7194  -0.2978   0.9753   1.8171  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  21.0680     6.4025   3.291 0.001000 ***
## GPA          -6.1324     1.8283  -3.354 0.000796 ***
## SexM          1.1697     0.7178   1.629 0.103210    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 75.791  on 54  degrees of freedom
## Residual deviance: 53.945  on 52  degrees of freedom
## AIC: 59.945
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Generate a 95\% confidence interval for the coefficient associated with \texttt{GPA}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{confint}\NormalTok{(med_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Waiting for profiling to be done...
\end{verbatim}

\begin{verbatim}
##                   2.5 %    97.5 %
## (Intercept)  10.0651173 35.579760
## GPA         -10.2977983 -3.007544
## SexM         -0.1720454  2.697436
\end{verbatim}

Let's try the bootstrap for this problem.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{819}\NormalTok{)}
\NormalTok{results_med <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{GPA}\OperatorTok{+}\NormalTok{Sex,}\DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(MedGPA),}\DataTypeTok{family=}\NormalTok{binomial)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results_med }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_histogram}\NormalTok{(}\OperatorTok{~}\NormalTok{GPA,}\DataTypeTok{fill=}\StringTok{"cyan"}\NormalTok{,}\DataTypeTok{color =} \StringTok{"black"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_theme}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gf_labs}\NormalTok{(}\DataTypeTok{title=}\StringTok{"Bootstrap sampling distribtuion"}\NormalTok{,}
          \DataTypeTok{x=}\StringTok{"GPA paramater estimate"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{31-Logistic-Regression-Solutions_files/figure-latex/unnamed-chunk-28-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{GPA,}\DataTypeTok{data=}\NormalTok{results_med)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         lower     upper central.p
## 2.5% -14.2047 -3.213036      0.95
\end{verbatim}

This is not so bad. It appears that the distribution of \texttt{GPA} is skewed to the left.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Fit a model with a polynomial of degree 2 in the \texttt{GPA}. Drop \texttt{Sex} from the model. Does a quadratic fit improve the model?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{med_mod2<-}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(GPA,}\DecValTok{2}\NormalTok{),}\DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(med_mod2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = Accept == "D" ~ poly(GPA, 2), family = binomial, 
##     data = MedGPA)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.9553  -0.7830  -0.3207   0.8020   1.8363  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(>|z|)    
## (Intercept)    -0.3301     0.3582  -0.921 0.356822    
## poly(GPA, 2)1 -10.7293     3.0664  -3.499 0.000467 ***
## poly(GPA, 2)2  -3.4967     3.0987  -1.128 0.259133    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 75.791  on 54  degrees of freedom
## Residual deviance: 55.800  on 52  degrees of freedom
## AIC: 61.8
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

The quadratic term did not improve the model.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Fit a model with just \texttt{GPA} and interpret the coefficient.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{GPA,}\DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   term        estimate std.error statistic  p.value
##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)    19.2       5.63      3.41 0.000644
## 2 GPA            -5.45      1.58     -3.45 0.000553
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\FloatTok{5.454166}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.004278444
\end{verbatim}

An increase of 1 in a student's GPA decreases the odds of being denied acceptance by 0.00428. Remember that this is not a probability. As a reminder an odds of \(\frac{1}{2}\) means the probability of success is \(\frac{1}{3}\). An odds of 1 means a probability of success of \(\frac{1}{2}\). Assume the initial odds are 1 if the odds are now 0.00428 smaller, then the probability of success is \(\frac{428}{10428}\) or 0.04. The probability decreased by an order of magnitude.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Try to add different predictors to come up with your best model. Do not use Acceptance and MCAT in the model.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{.}\OperatorTok{-}\NormalTok{Acceptance}\OperatorTok{-}\NormalTok{MCAT,}\DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{p.adj=}\KeywordTok{p.adjust}\NormalTok{(p.value)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(term,p.value,p.adj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 3
##   term        p.value  p.adj
##   <chr>         <dbl>  <dbl>
## 1 (Intercept) 0.00279 0.0251
## 2 SexM        0.110   0.551 
## 3 BCPM        0.376   1     
## 4 GPA         0.150   0.600 
## 5 VR          0.799   1     
## 6 PS          0.0305  0.213 
## 7 WS          0.0491  0.295 
## 8 BS          0.00490 0.0392
## 9 Apps        0.728   1
\end{verbatim}

Let's take out \texttt{VR}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{.}\OperatorTok{-}\NormalTok{Acceptance}\OperatorTok{-}\NormalTok{MCAT}\OperatorTok{-}\NormalTok{VR,}\DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{p.adj=}\KeywordTok{p.adjust}\NormalTok{(p.value)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(term,p.value,p.adj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8 x 3
##   term        p.value  p.adj
##   <chr>         <dbl>  <dbl>
## 1 (Intercept) 0.00239 0.0191
## 2 SexM        0.0681  0.272 
## 3 BCPM        0.362   0.723 
## 4 GPA         0.143   0.430 
## 5 PS          0.0280  0.168 
## 6 WS          0.0452  0.226 
## 7 BS          0.00476 0.0333
## 8 Apps        0.742   0.742
\end{verbatim}

Now let's take out \texttt{Apps}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{.}\OperatorTok{-}\NormalTok{Acceptance}\OperatorTok{-}\NormalTok{MCAT}\OperatorTok{-}\NormalTok{VR}\OperatorTok{-}\NormalTok{Apps,}\DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{p.adj=}\KeywordTok{p.adjust}\NormalTok{(p.value)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(term,p.value,p.adj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 3
##   term        p.value  p.adj
##   <chr>         <dbl>  <dbl>
## 1 (Intercept) 0.00147 0.0103
## 2 SexM        0.0272  0.133 
## 3 BCPM        0.379   0.379 
## 4 GPA         0.120   0.240 
## 5 PS          0.0266  0.133 
## 6 WS          0.0385  0.133 
## 7 BS          0.00477 0.0286
\end{verbatim}

Next, let's remove \texttt{BCPM}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{.}\OperatorTok{-}\NormalTok{Acceptance}\OperatorTok{-}\NormalTok{MCAT}\OperatorTok{-}\NormalTok{VR}\OperatorTok{-}\NormalTok{Apps}\OperatorTok{-}\NormalTok{BCPM,}
         \DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{p.adj=}\KeywordTok{p.adjust}\NormalTok{(p.value)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(term,p.value,p.adj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   term        p.value   p.adj
##   <chr>         <dbl>   <dbl>
## 1 (Intercept) 0.00123 0.00739
## 2 SexM        0.0142  0.0567 
## 3 GPA         0.0315  0.0901 
## 4 PS          0.0300  0.0901 
## 5 WS          0.0401  0.0901 
## 6 BS          0.00537 0.0269
\end{verbatim}

Now \texttt{WS}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{.}\OperatorTok{-}\NormalTok{Acceptance}\OperatorTok{-}\NormalTok{MCAT}\OperatorTok{-}\NormalTok{VR}\OperatorTok{-}\NormalTok{Apps}\OperatorTok{-}\NormalTok{BCPM}\OperatorTok{-}\NormalTok{WS,}
         \DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{p.adj=}\KeywordTok{p.adjust}\NormalTok{(p.value)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(term,p.value,p.adj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 3
##   term         p.value   p.adj
##   <chr>          <dbl>   <dbl>
## 1 (Intercept) 0.000584 0.00292
## 2 SexM        0.0168   0.0504 
## 3 GPA         0.0366   0.0732 
## 4 PS          0.0634   0.0732 
## 5 BS          0.0100   0.0401
\end{verbatim}

Maybe \texttt{PS}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tidy}\NormalTok{(}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{.}\OperatorTok{-}\NormalTok{Acceptance}\OperatorTok{-}\NormalTok{MCAT}\OperatorTok{-}\NormalTok{VR}\OperatorTok{-}\NormalTok{Apps}\OperatorTok{-}\NormalTok{BCPM}\OperatorTok{-}\NormalTok{WS}\OperatorTok{-}\NormalTok{PS,}
         \DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{p.adj=}\KeywordTok{p.adjust}\NormalTok{(p.value)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(term,p.value,p.adj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 3
##   term         p.value   p.adj
##   <chr>          <dbl>   <dbl>
## 1 (Intercept) 0.000574 0.00230
## 2 SexM        0.0306   0.0611 
## 3 GPA         0.0325   0.0611 
## 4 BS          0.00448  0.0134
\end{verbatim}

I will stop there. There has to be a better way. Math 378 will explore how to select predictors and improve a model.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Generate a confusion matrix for the best model you have developed.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{med_mod2<-}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{Sex}\OperatorTok{+}\NormalTok{GPA}\OperatorTok{+}\NormalTok{BS,}
         \DataTypeTok{data=}\NormalTok{MedGPA,}\DataTypeTok{family=}\NormalTok{binomial)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(med_mod2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = Accept == "D" ~ Sex + GPA + BS, family = binomial, 
##     data = MedGPA)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8388  -0.4707  -0.1347   0.5535   2.6411  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  27.4608     7.9721   3.445 0.000572 ***
## SexM          1.9885     0.9193   2.163 0.030543 *  
## GPA          -4.2900     2.0062  -2.138 0.032484 *  
## BS           -1.3752     0.4838  -2.843 0.004471 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 75.791  on 54  degrees of freedom
## Residual deviance: 40.835  on 51  degrees of freedom
## AIC: 48.835
## 
## Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{augment}\NormalTok{(med_mod2,}\DataTypeTok{type.predict =} \StringTok{"response"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{actual=}\KeywordTok{starts_with}\NormalTok{(}\StringTok{'Accept =='}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{transmute}\NormalTok{(}\DataTypeTok{result=}\KeywordTok{as.integer}\NormalTok{(.fitted}\OperatorTok{>}\FloatTok{0.5}\NormalTok{),}
            \DataTypeTok{actual=}\KeywordTok{as.integer}\NormalTok{(actual)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{table}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       actual
## result  0  1
##      0 26  4
##      1  4 21
\end{verbatim}

This model has an accuracy of \(\frac{47}{55}\) or 85.5\%.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Find a 95\% confidence interval for the probability a female student with a 3.5 GPA, a \texttt{BCPM} of 3.8, a verbal reasoning score of 10, a physical sciences score of 9, a writing sample score of 8, a biological score of 10, a MCAT score of 40, and who applied to 5 medical schools.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(med_mod2,}\DataTypeTok{newdata =} \KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{Sex=}\StringTok{"F"}\NormalTok{,}
                                      \DataTypeTok{GPA=}\FloatTok{3.5}\NormalTok{,}
                                      \DataTypeTok{BS=}\DecValTok{10}\NormalTok{),}
        \DataTypeTok{type=}\StringTok{"response"}\NormalTok{,}\DataTypeTok{se.fit =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $fit
##         1 
## 0.2130332 
## 
## $se.fit
##         1 
## 0.1122277 
## 
## $residual.scale
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{0.2130332}\OperatorTok{+}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\FloatTok{1.96}\OperatorTok{*}\NormalTok{.}\DecValTok{1122277}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.006933092  0.432999492
\end{verbatim}

For a female students with a GPA of 3.5 and a biological score of 10, we are 95\% confident that the probability of being denied acceptance to medical school is between 0 and .433.

Let's try a bootstrap.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{729}\NormalTok{)}
\NormalTok{results <-}\StringTok{ }\KeywordTok{do}\NormalTok{(}\DecValTok{1000}\NormalTok{)}\OperatorTok{*}\KeywordTok{glm}\NormalTok{(Accept}\OperatorTok{==}\StringTok{"D"}\OperatorTok{~}\NormalTok{Sex}\OperatorTok{+}\NormalTok{GPA}\OperatorTok{+}\NormalTok{BS,}
                      \DataTypeTok{data=}\KeywordTok{resample}\NormalTok{(MedGPA),}
                      \DataTypeTok{family=}\NormalTok{binomial)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Intercept       SexM        GPA         BS .row .index
## 1  204.23984  20.701630  -4.547781 -20.801516    1      1
## 2   16.78193   1.373795  -2.508340  -0.908112    1      2
## 3   36.09536   4.170571  -7.479463  -1.219088    1      3
## 4 1104.42269 105.236280 -90.461857 -86.132398    1      4
## 5   25.37989   1.139262  -3.729948  -1.331750    1      5
## 6   26.58307   3.197072  -3.426165  -1.772581    1      6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results_pred <-}\StringTok{ }\NormalTok{results }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred=}\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\OperatorTok{*}\NormalTok{(Intercept}\FloatTok{+3.5}\OperatorTok{*}\NormalTok{GPA}\OperatorTok{+}\DecValTok{10}\OperatorTok{*}\NormalTok{BS))))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cdata}\NormalTok{(}\OperatorTok{~}\NormalTok{pred,}\DataTypeTok{data=}\NormalTok{results_pred)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            lower     upper central.p
## 2.5% 7.77316e-10 0.5032905      0.95
\end{verbatim}

This is close to what we found and does not make the assumption the probability of success is normally distributed.

  \bibliography{book.bib,packages.bib}

\end{document}
